<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="312-B3｜3D重建系列, ZejunCao&#39;Blogs">
    <meta name="description" content="312-B3｜3D重建系列

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

AIGCResearch主编｜庄才林（CailinZhuang）技术支持｜胡耀淇（YaoqiHu）｜编辑支持｜张奇佳（QijiaZhang）发">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>312-B3｜3D重建系列 | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000000348_2247527322_8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">312-B3｜3D重建系列</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/AIGC-Research/">
                                <span class="chip bg-color">AIGC Research</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-17
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/4giQ78xnHT63-keOSNCnfg">312-B3｜3D重建系列</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>AIGCResearch<br>主编｜庄才林（CailinZhuang）技术支持｜胡耀淇（YaoqiHu）｜编辑支持｜张奇佳（QijiaZhang）发布日期｜2025年3月4日｜周二<br>2025-03-03｜NAVERLE｜CVPR2025<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01661v1https :&#x2F;&#x2F;europe.naverlabs.com<br>MUSt3R（Multi-viewNetworkforStereo3DReconstruction）是一种新型的多视角立体三维重建网络，旨在解决现有DUSt3R模型在处理大规模图像集合时的局限性。DUSt3R通过对图像对进行回归，生成局部三维重建，但这种成对处理的方式在图像数量增加时会导致计算复杂度呈平方增长，从而影响优化速度和鲁棒性。MUSt3R通过对DUSt3R架构的改进，采用对称结构和多层记忆机制，能够直接在统一坐标框架下为所有视角预测三维结构。这一创新不仅提高了重建的效率，还使得模型能够在离线和在线场景中无缝应用，展现出在无校准视觉里程计、相对相机姿态估计、三维重建等多项任务中的优越性能。<br>MUSt3R的方法主要包括几个关键组成部分。首先，模型基于DUSt3R的架构，进行了对称化处理，使其能够处理N视图的输入，而无需为每个视图单独设计解码器。这一设计不仅简化了网络结构，还减少了训练参数。其次，MUSt3R引入了一个多层记忆机制，使得模型可以高效处理任意数量的图像，并通过迭代更新记忆来保持对先前图像的上下文理解。此外，模型的解码器通过跨注意力机制在每一层之间共享信息，以便更好地理解视角之间的空间关系。最后，MUSt3R支持在线和离线重建，能够在动态场景中实时生成高质量的三维点图，显著提高了推理速度和准确性。<br>在实验部分，MUSt3R的性能在多个无校准视觉里程计和三维重建任务中得到了验证。通过在TUMRGB-D和ETH3D数据集上进行评估，MUSt3R展示了其在处理动态场景和复杂环境中的优越性。实验结果表明，MUSt3R在相机轨迹的平均误差、垂直视场角误差和规模估计等指标上均超过了现有的最先进方法。尤其是在处理长序列图像时，MUSt3R的计算效率和重建精度得到了显著提升。此外，MUSt3R还在多个三维重建任务中展现出卓越的性能，证明了其在实际应用中的广泛适用性和灵活性。<br>MUSt3R的工作原理可以简单理解为一个智能的三维重建助手。首先，它通过分析多张图片来构建一个三维模型，而不是仅仅依赖于两张图片的组合。这样可以处理更多的视角，让模型更全面地理解场景。其次，MUSt3R使用一种记忆机制，可以记住之前处理过的信息，这样在遇到新图像时，它可以快速做出反应，而不需要重新开始。最后，这个系统不仅可以在实验室环境中使用，还能在实际的动态场景中运行，比如在街道上行驶的汽车或机器人中，实时生成三维地图。这种灵活性使得MUSt3R在各种应用中都表现出色。<br>2025-03-03｜UBuffalo,UCSD｜CVPR2025<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01130v1https :&#x2F;&#x2F;sairlab.org&#x2F;airroom&#x2F;<br>房间重识别（ReID）是一个复杂但至关重要的任务，广泛应用于增强现实（AR）和家庭护理机器人等领域。现有的视觉场所识别（VPR）方法通常依赖于全局描述符或局部特征的聚合，但在物体密集的室内环境中，这些方法往往表现不佳，难以捕捉到重要的物体信息。为了解决这一问题，本文提出了AirRoom，一个基于物体意识的重识别管道，它集成了多层次的物体信息，包括全局上下文、物体补丁、物体分割和关键点，采用粗到细的检索方法。通过在四个新构建的数据集（MPReID、HMReID、GibsonReID和ReplicaReID）上进行广泛实验，结果表明AirRoom在几乎所有评估指标上均优于现有的最先进模型，性能提升范围在6%到80%之间。<br>AirRoom的设计分为三个主要阶段：全局阶段、局部阶段和细粒度阶段。<br>全局阶段：使用全局特征提取器捕捉全局上下文特征，帮助粗略选择五个功能相似的候选房间。全局上下文特征提供了重要的语义信息。<br>局部阶段：通过实例分割识别个体物体，并使用感受野扩展器提取物体补丁。接着，使用物体特征提取器获取物体和补丁特征，并通过物体意识评分进一步细化候选列表。<br>细粒度阶段：在这一阶段，进行特征匹配以精确识别最终的房间。通过整合多层次的物体信息，AirRoom在处理视角变化时展现出显著的鲁棒性和准确性。<br>在实验部分，研究者构建了四个新数据集，专门用于房间重识别，确保每个数据集都能提供多样化的基准测试。实验包括总体性能比较、组内性能比较、管道灵活性评估、消融研究和运行时分析。结果表明，AirRoom在所有数据集上均优于基线方法，准确性、精确度、召回率和F1分数均显著提高。具体来说，AirRoom在房间重识别任务中展示了卓越的性能，尤其是在处理相似和重复物体的复杂室内场景时，能够有效区分微小的特征差异。此外，实验还验证了AirRoom的灵活性，表明其能够适应不同的模型配置和特征提取方法。<br>AirRoom的工作流程可以简单理解为三个步骤：首先，系统会分析整个房间的布局和物体，找出五个最可能的候选房间。接着，它会仔细观察这些候选房间中的每一个物体，提取出更多细节信息，比如桌子、椅子等。最后，通过比对这些细节，系统能够准确地识别出与用户查询相匹配的房间。这种方法不仅考虑了房间的整体布局，还关注了每个物体的具体特征，使得在复杂和相似的室内环境中也能保持高效的识别能力。<br>2025-03-03｜Unknown<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01114v1<br>本研究提出了一种新颖的半监督360度布局估计方法，称为SemiLayout360，旨在解决传统方法在处理全景图像时的局限性。现有的全景布局估计方法大多依赖于监督学习，且通常需要大量的标注数据。为了缓解这一需求，SemiLayout360结合了全景布局先验和失真先验，通过协同扰动的方式，增强模型对潜在布局边界的关注，同时提高其对图像失真的感知能力。该方法的核心在于通过引入多种扰动策略，利用未标注数据的丰富信息，从而在标注数据有限的情况下，提升模型的整体性能。实验结果显示，SemiLayout360在多个主流数据集上均显著优于现有的最先进方法，展示了其在全景布局估计任务中的有效性和优势。<br>SemiLayout360方法的设计包含几个关键步骤。首先，采用Mean-Teacher框架，该框架通过学生模型和教师模型的协同学习来提升模型性能。具体步骤如下：<br>输入图像扰动：对标注和未标注的图像进行扰动，分为弱增强（如随机翻转和旋转）和强增强（如直方图均衡化和傅里叶变换），以提高模型对边界的感知。<br>特征扰动：在特征提取后，对特征图应用空间掩模，强调边缘区域的扰动，帮助模型更好地学习布局结构。<br>网络扰动：通过教师模型生成伪标签，确保学生模型的预测与教师模型一致，利用一致性正则化增强模型的鲁棒性。<br>全景协同扰动：将上述扰动结合，形成全景协同扰动，以平衡不同扰动的效果，提升模型的泛化能力而不影响收敛性。<br>在实验部分，研究团队在三个广泛使用的全景布局数据集上验证了SemiLayout360的有效性，包括PanoContext、Stanford2D3D和MatterportLayout。通过严格的实验设置，模型的性能通过多个标准评估指标进行评估，如3D和2D交并比、角点误差和像素误差等。结果表明，SemiLayout360在所有评估指标上均优于现有的最先进方法。具体而言，在标注样本有限的情况下，SemiLayout360通过充分利用未标注数据和先验知识，显著提高了布局估计的准确性。实验还包括对不同组件的消融研究，验证了各项扰动策略在整体性能提升中的贡献。<br>SemiLayout360方法可以想象成一个学生和老师的学习过程。学生模型通过学习已有的标注数据来理解如何识别房间的布局，但因为标注的数据不够多，学习效果有限。于是，老师模型通过观察学生的学习过程，给出一些未标注数据的预测，帮助学生更好地学习。为了让学生在学习时更加灵活，我们会对输入的图像进行一些“变形”，比如翻转、旋转或改变亮度，这样学生就能适应不同的情况。我们还会特别关注图像的边缘部分，因为那里通常包含重要的布局信息。通过这些方法，SemiLayout360能更好地理解和预测房间的布局，即使只有少量的标注数据。<br>2025-03-02｜ANU<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00726v1https :&#x2F;&#x2F;github.com&#x2F;CharlieSong1999&#x2F;FlashDreamer&#x2F;tree&#x2F;main<br>在虚拟现实、机器人和自动驾驶等应用中，三维场景重建是一项至关重要的技术，能够帮助机器理解和与复杂环境进行交互。传统的三维高斯点云技术通常依赖于多个视角的图像进行重建，这限制了其在仅有单一图像输入场景中的应用。为了解决这一问题，本文提出了一种新颖的方法——FlashDreamer，该方法能够从单一图像中重建完整的三维场景，显著降低了对多视角输入的依赖。FlashDreamer利用预训练的视觉语言模型生成描述性提示，指导扩散模型从不同视角生成图像，最终将这些图像融合为一个连贯的三维重建。通过大量实验，结果表明该方法在没有额外训练的情况下，有效且稳健地扩展了单图像输入的三维重建能力。<br>FlashDreamer的核心在于其管道设计，该设计分为几个关键步骤：首先，输入图像通过Flash3D模型生成初始的三维高斯表示；接着，利用视觉语言模型生成描述性文本提示，这些提示将用于指导扩散模型的图像生成过程；然后，扩散模型根据这些提示对初始图像进行修复和扩展，生成新的视角图像；最后，将这些新生成的视角图像与初步的三维表示进行融合和对齐，形成完整的三维场景。具体来说，方法的步骤包括：1)从输入图像生成初步的三维场景表示；2)通过预定义的几何变换生成不同视角的图像；3)使用扩散模型对新视角图像进行修复；4)将所有生成的图像进行合并和对齐，最终输出一个完整的三维场景。<br>为了验证FlashDreamer的有效性，本文进行了定性和定量的实验分析。实验设置中使用了Flash3D结合预训练的StableDiffusion模型，以提升生成的准确性。我们在Replica数据集上进行了实验，选择了20张图像，并针对每张图像生成了6个不同的视角。通过调整旋转角度、扩散模型的类型和提示的多样性，我们评估了不同因素对场景生成质量的影响。定量评估使用了FrechetInceptionDistance(FID)和CLIPScore等指标，比较了FlashDreamer与基线模型PixelSynth的性能。结果显示，FlashDreamer在大多数评估角度上均优于基线模型，证明了其在单图像三维重建任务中的优势。<br>FlashDreamer的工作方式可以简单理解为一个四步流程。首先，它接收一张图片，并用一个叫Flash3D的工具生成一个初步的三维模型。接下来，FlashDreamer会利用一个智能语言模型来生成一段描述这张图片的文字，这段文字会帮助后续的图像生成。然后，使用扩散模型，FlashDreamer会根据这段描述，创造出不同角度的新图像，以填补原始图片中缺失的部分。最后，所有生成的图像会被合并在一起，形成一个完整的三维场景。这个过程使得FlashDreamer能够从一张单独的图片中，创造出一个丰富的三维世界，而不需要多张不同角度的图片。<br>2025-03-01｜UIUC<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00308v2<br>本文介绍了一种新的抽象渲染方法，旨在通过从一系列连续变化的相机位置渲染场景来计算一组图像。生成的抽象图像编码了无限可能的渲染集合，并通过对图像矩阵的约束进行表示，从而实现了在渲染过程中严格的不确定性传播。这种能力对于视觉基础的自主系统的形式验证及其他安全关键应用尤其重要。该方法主要针对高效的高斯斑点场景进行操作，利用分段线性界限传播来抽象基本渲染操作，解决了矩阵求逆和深度排序等关键挑战。我们的实现，AbstractSplat，能够处理高达75万个高斯斑点的场景，并允许用户通过基于块和批处理的计算在内存和运行时间之间进行平衡。<br>我们的抽象渲染算法AbstractSplat接收场景和相机的线性集合作为输入，并通过高斯斑点的渲染过程逐步推导出每个中间变量与输入之间的分段线性关系。该方法的关键步骤包括：<br>将每个3D高斯从世界坐标转换为相机坐标，并进一步转换为2D像素坐标。<br>计算每个高斯在像素位置的有效不透明度，评估其概率密度。<br>使用泰勒展开法来处理矩阵求逆，以减小不确定性带来的误差。<br>替换深度排序为基于指标的混合方法，直接通过对比深度来处理遮挡关系，确保每个高斯的贡献独立界定。通过这些步骤，AbstractSplat能够输出每个像素的可能颜色集，并通过线性关系确保输出的准确性和可用性。<br>我们对AbstractSplat进行了多种场景的实验评估，涵盖了不同规模和复杂度的高斯斑点场景，包括LEGO推土机、机场等。通过对相机位置进行不同程度的扰动，我们记录了每个场景的像素颜色界限，并与随机采样结果进行比较。实验结果表明，AbstractSplat在处理复杂场景时表现出良好的运行时间和准确性，能够在200×200的分辨率下有效处理数十万个高斯斑点。我们还定义了两个度量标准来评估抽象图像的精度：平均像素间隙（MPG）和最大像素间隙（XPG），结果显示我们的算法在大多数测试中优于现有方法，尤其是在小扰动情况下，提供了更紧凑的界限。<br>在我们的研究中，我们开发了一种名为AbstractSplat的渲染方法，旨在帮助我们更好地理解和预测在不同相机位置下看到的图像。我们首先将场景中的每个三维对象转换为适合相机的二维表示。接着，我们计算每个对象在特定像素位置的透明度和颜色。为了确保计算的准确性，我们使用了一种数学技巧（泰勒展开）来处理复杂的计算，比如矩阵求逆，这样可以减少错误。最后，我们通过一种新方法来处理对象之间的遮挡关系，避免了传统方法中可能出现的重复计算。通过这些步骤，AbstractSplat能够输出每个像素的可能颜色范围，从而为我们提供了更可靠的图像渲染结果。<br>2025-03-03｜Meta,ETHZurich,UToronto<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01610v1https :&#x2F;&#x2F;moygcc.github.io&#x2F;vid2avatar-pro&#x2F;<br>Vid2Avatar-Pro是一种新颖的方法，旨在通过单目视频生成高保真且可动画的3D人类头像。该方法克服了传统多视角捕捉系统的局限性，能够从在野外拍摄的单一视频中提取丰富的细节和姿势变化。通过使用预训练的通用先验模型（UniversalPriorModel,UPM），Vid2Avatar-Pro不仅能够生成真实感极强的头像，还能够在不同的姿势下进行动画展示。这一技术的应用前景广泛，包括游戏、电影中的数字人类合成，以及增强现实和虚拟现实中的虚拟沟通。该方法的创新性在于其能够实现从单一视角视频中生成多样化的姿态，显著提升了数字人类的可用性和可访问性。<br>Vid2Avatar-Pro的方法分为两个主要步骤：构建衣着人类的通用先验模型和在野外视频中的个性化处理。具体而言：<br>通用先验模型构建：<br>利用来自多视角动态人类性能捕捉的数据，训练一个通用先验模型，使用3D高斯分布表示衣着人类的几何和纹理特征。<br>通过正则化和归一化处理，确保模型在不同身份间具有良好的泛化能力，并能支持多种服装拓扑结构。<br>在野外个性化处理：<br>从单目视频中重建标准化的纹理模板，并通过逆渲染技术提取个性化的细节。<br>采用扩散模型进行纹理补全，以处理拍摄过程中可能缺失的细节，确保生成的头像在各种姿势下都能保持真实感。<br>在实验部分，研究团队首先介绍了用于训练和测试的多视角数据集与单目视频数据集。通过与现有技术的比较，Vid2Avatar-Pro在插值合成和外推合成任务中均表现出色，展示了其在生成高质量头像方面的优势。实验结果表明，该方法在多个评估指标上均优于基线模型，尤其是在细节恢复和真实感表现上。此外，消融实验验证了通用先验模型和个性化处理的有效性，进一步证明了该方法在生成可动画头像方面的潜力。<br>Vid2Avatar-Pro的工作原理可以简单理解为两个步骤。首先，它从大量不同人的视频中学习如何制作一个“通用”的3D人类模型，这个模型能表现出各种姿势和动作。想象一下，如果你有一个非常聪明的机器人，它能从不同人的视频中学习如何走路、跑步或做其他动作。这个机器人会记住每个人的特点，并能把这些特点组合成一个新的、独特的人物。第二个步骤是，当你给这个机器人一个新的单一视频时，它会根据之前学到的知识，快速调整和个性化这个模型，使其看起来像视频中的人。这样，不论是游戏还是虚拟现实，大家都能看到非常真实和生动的数字人类。<br>2025-03-03｜UBonn,MPI-INF｜CVPR2025<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01845v1https :&#x2F;&#x2F;alekseizhuravlev.github.io&#x2F;denoising-functional-maps&#x2F;<br>在计算机图形学和视觉领域，3D形状的对应点匹配一直是一个长期存在的挑战。尽管已有相当大的进展，但现有方法在广泛适用性和类别特定训练数据的需求上仍存在局限。为了解决这些问题，本文提出了一种新的形状对应方法——DenoisingFunctionalMaps（DenoisFM），该方法利用去噪扩散模型直接预测功能映射。功能映射是一种低维表示，能够有效地映射出不同形状之间的点对应关系。通过使用合成的人体网格数据集进行训练，DenoisFM在处理具有各异拓扑结构和几何特征的形状时显示出了出色的性能，能够在多个标准数据集上与现有方法相媲美。<br>DenoisFM的核心方法包括两个主要组件：去噪扩散模型和信号校正网络。具体步骤如下：<br>功能映射预测：通过去噪扩散模型，首先对每个输入形状计算其拉普拉斯特征向量，并使用这些特征向量进行功能映射的预测。<br>信号校正：由于拉普拉斯特征向量存在符号歧义，本文提出了一种无监督的信号校正方法。该方法通过提取形状的局部特征，选择合适的特征向量符号组合，从而减少预测的复杂性。<br>训练数据生成：使用大规模的合成数据集（如SURREAL）进行训练，训练过程中采用模板映射而非成对映射的方法，以降低训练和推理的复杂度。<br>后处理：在推理阶段，通过多次去噪处理生成多个功能映射，并利用Dirichlet能量选择最佳的映射结果，以提高匹配的准确性。<br>在实验部分，DenoisFM在多个标准数据集上进行了评估，包括FAUST、SCAPE和SHREC’19。实验结果表明，相较于其他大规模和基于描述符的方法，DenoisFM能够在不同形状类别上保持较高的匹配精度。具体来说，DenoisFM在处理具有不同连通性和几何特征的形状时表现出更好的鲁棒性。此外，在零样本匹配和动物形状匹配的实验中，DenoisFM同样显示出良好的泛化能力，能够在未见过的形状上进行有效匹配。通过与现有的最先进技术进行比较，DenoisFM在多个测试集上均取得了竞争性的表现，充分展示了其在形状对应任务中的有效性。<br>DenoisFM的方法可以简单理解为一个两步过程。首先，研究人员使用一种叫做去噪扩散模型的技术来预测形状之间的对应关系。这个模型就像一个聪明的助手，它通过观察形状的特征，逐渐去除噪声，最终得出两个形状之间的最佳匹配。其次，由于在处理这些特征时可能会出现符号问题（即相同特征的正负号不一致），研究人员设计了一个信号校正网络，能够自动调整这些特征的符号，确保它们是正确的。通过这种方式，DenoisFM不仅能处理常见的人体形状，还能适应不同的形状类型，甚至是动物形状，从而展示出其强大的适应能力和准确性。<br>2025-03-03｜BIT<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01646v1https :&#x2F;&#x2F;young-bit.github.io&#x2F;opengs-github.github.io&#x2F;<br>OpenGS-SLAM是一种新颖的框架，旨在解决传统稠密语义SLAM在开放集场景下的局限性。以3D高斯表示为基础，该系统通过集成来自2D基础模型的显式语义标签，实现了对环境的高效理解和重建。与以往依赖于有限类别预训练分类器的方法不同，OpenGS-SLAM能够处理开放集场景，提升了3D物体级场景理解的能力。引入的高斯投票法（GaussianVotingSplatting）加速了2D标签图的渲染和场景更新，并通过基于信心的2D标签共识方法确保多视角下标签的一致性。此外，采用的分割计数修剪策略提高了场景语义表示的准确性。大量实验结果表明，该方法在跟踪、映射和场景理解方面表现出色，显著提升了渲染速度和存储效率。<br>OpenGS-SLAM的核心方法包括三个主要部分：语义信息生成器、语义高斯映射和基于信心的2D标签共识。首先，语义信息生成器结合多个专家模型，处理输入的RGB图像，生成开放集类别信息和语义边界框。然后，语义高斯映射通过高斯投票法将3D高斯与2D标签图结合，实现高保真的RGB-D图像渲染和语义映射。每个高斯包含3D中心位置、协方差、透明度、颜色和标签信息。最后，基于信心的2D标签共识方法通过比较不同视角的标签，确保标签的一致性，避免由于视角变化导致的标签不一致问题。通过这些方法，OpenGS-SLAM实现了高效的3D物体级场景理解，支持实时在线语义映射。<br>在实验部分，OpenGS-SLAM在多个合成和真实世界的数据集上进行了评估，重点考察场景理解和SLAM性能。实验结果显示，该方法在语义分割精度、跟踪精度和重建质量方面均优于现有的语义SLAM方法。具体而言，采用的多视角2D分割评估了不同视角下的分割一致性和准确性，3D物体级理解则考察了语义3D高斯场景表示的有效性。通过与其他视觉SLAM方法的比较，OpenGS-SLAM在相机跟踪精度和重建质量上也取得了显著进展。实验还包括消融研究，以验证各个模块对整体性能的贡献，确保方法的有效性和实用性。<br>OpenGS-SLAM方法的核心是将2D图像中的信息转化为3D场景的理解。首先，它使用一些智能模型来分析输入的图像，提取出物体的类别和位置。接下来，这些信息会被转化为3D高斯模型，这些高斯模型就像是3D空间中的小点，每个点都有自己的位置和颜色。然后，OpenGS-SLAM会将这些点投影到2D图像上，生成一个清晰的图像，并确保不同视角下的物体标签一致。最后，当有新的视角或信息出现时，它会快速更新这些3D点，保持信息的准确性。这种方法让机器能够更好地理解和交互复杂的环境，适用于实时场景重建和导航。<br>2025-03-03｜ULuxembourg<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01582v2<br>在3D物体映射领域，类别级先验知识的使用可以显著提高物体重建和标准姿态估计的效率，只需为每个语义类别（如椅子、书籍、笔记本电脑）提供一个先验。尽管DeepSDF在这一领域表现突出，但其在重建精细几何时存在困难，并且计算成本较高。与之相比，NeRF（神经辐射场）能够捕捉细节，但在实时多物体映射框架中尚未有效整合类别级先验。为了解决这一问题，本文提出了PRENOM（基于先验的高效神经物体映射器），它将类别级先验与物体级NeRF结合，以提高重建效率并实现标准物体姿态估计。通过在合成重建任务上进行元学习，PRENOM能够快速适应不同类别的物体，并通过多目标遗传算法优化NeRF架构，以平衡重建质量和训练时间。此外，基于先验的概率光线采样方法可以加速收敛，提高在资源受限情况下的重建质量。<br>PRENOM的方法主要分为两个模块：离线先验训练和在线物体映射。离线先验训练模块首先定义感兴趣的类别集合，并为每个类别训练一个先验，以优化NeRF模型的架构和初始参数。训练任务包括生成用于重建单个物体的数据集，使用公开的3D模型库。通过元学习算法Reptile，优化初始参数，使其能够快速适应未见物体实例。在线物体映射模块则基于RO-MAP框架，利用ORB-SLAM2的跟踪模块获取相机姿态。物体关联策略通过计算边界框的交并比来判断物体是否相同。物体状态的粗略估计包括位置、朝向和大小的计算，并通过基于先验的概率光线采样来提高重建精度。通过使用多线程并行训练，PRENOM能够在观察到物体后快速进行重建。<br>在实验部分，PRENOM在低端GPU上进行评估，重点比较其与其他无先验方法的重建性能。实验结果显示，PRENOM在多个场景中实现了显著的性能提升，平均Chamfer距离降低了21%，显示出更好的重建质量。此外，PRENOM在与其他使用形状先验的方法的比较中，平均提升了13%的重建指标，同时保持了相似的姿态和大小估计精度。实验还表明，PRENOM的训练时间比其他方法少5倍，且所需的先验大小减少了30%。这些结果表明，PRENOM在资源受限的设置中有效地提高了重建的准确性和效率。<br>PRENOM的工作原理可以简单理解为：它首先学习如何识别和重建不同类别的物体，比如椅子或书本。这个过程分为两个阶段。第一阶段是“学习阶段”，在这个阶段，系统会使用很多不同的物体图像来训练自己，了解每个物体的基本形状和特征。第二阶段是“应用阶段”，在这个阶段，当系统看到一个新物体时，它会快速利用之前学习到的知识来进行重建。为了加快这个过程，PRENOM会使用一种叫做“概率光线采样”的技术，这种技术可以让系统更聪明地选择哪些部分需要更多的注意，从而更快地完成重建任务。通过这种方式，PRENOM不仅能在较短的时间内完成工作，还能在资源有限的情况下保持高质量的结果。<br>2025-03-03｜NUDT,PKU,SYSU<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01309v1<br>本文提出了一种名为OnlineAnySeg的在线零-shot3D分割方法，旨在处理逐步重建场景中的3D实例分割问题。随着视觉基础模型（VFM）在图像领域的成功，利用2D先验信息来解决3D在线分割成为了一个重要的研究方向。传统方法在实时性上存在限制，往往需要离线处理。为了克服这一瓶颈，本文提出了一种高效的方法，通过哈希技术将VFM生成的2D掩膜提升为统一的3D实例，从而实现实时的空间重叠查询和掩膜合并。该方法在ScanNet和SceneNN基准测试上表现出色，显示出在实时、开放词汇的3D实例分割任务中具有领先的效率和准确性。<br>本研究的方法分为几个关键步骤：首先，通过RGB-D帧流生成2D掩膜，并将其提升为3D掩膜。具体步骤如下：<br>数据结构设计：使用哈希表来组织和维护2D掩膜的空间关联，从而实现高效查询。<br>掩膜提升：将每个2D掩膜通过反投影转换为3D掩膜，并记录其在哈希表中的重叠信息。<br>特征提取：从VFM中提取掩膜的语义和几何特征，以便后续的合并过程。<br>掩膜合并：基于掩膜的重叠比例、语义相似性和几何相似性进行合并，确保合并后的3D实例具有一致性和准确性。<br>在线更新：随着新掩膜的生成，动态更新哈希表和掩膜库，以维持实时处理能力。<br>在实验部分，本文通过在ScanNet200和SceneNN数据集上进行的广泛评估，验证了所提方法的有效性。具体包括：<br>实验设置：使用标准的平均精度（AP）度量，评估在线和离线分割方法的表现。<br>定量结果：与现有的在线和离线方法进行对比，展示了在不同场景下的分割性能。<br>中间序列评估：在不同的扫描进度下评估方法的实时性能，显示出在处理部分扫描场景时的优势。<br>消融研究：分析不同设计决策对整体性能的影响，强调掩膜合并策略的重要性。<br>本研究的方法可以简单理解为一个高效的在线3D分割系统。首先，它从相机捕捉的图片中提取出物体的2D轮廓，然后通过一种特殊的技术将这些2D轮廓“投影”到三维空间中。为了确保这些轮廓在3D环境中能够准确合并，系统会记录每个轮廓之间的重叠情况，并根据这些信息来判断哪些轮廓属于同一个物体。这样，即使在实时处理过程中，系统也能灵活地更新和合并这些信息，最终生成准确的3D物体实例。这种方法不仅提高了分割的速度，还能在处理不完整或有噪声的数据时保持较高的准确性。<br>2025-03-03｜Unknown<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.01199v1<br>Gaussiansplatting是一种在计算机图形学和视觉领域中用于重建3D场景的强大技术。然而，传统实现方式存在效率低下、灵活性不足和高计算开销的问题，限制了其在多种应用中的适应性。为了解决这些问题，本文提出了LiteGS，这是一个高性能的模块化框架，旨在提高Gaussiansplatting的效率和可用性。LiteGS相较于原始3DGS实现实现了3.4倍的速度提升，并将GPU内存使用量降低了约30%。其模块化设计将splatting过程分解为多个高度优化的操作，并通过脚本接口和CUDA接口提供双重API支持，满足快速原型开发和性能关键应用的需求。LiteGS保留了3DGS的核心算法，确保了兼容性。通过在Mip-NeRF360数据集上的全面实验，LiteGS证明了其在加速训练的同时不损失准确性，成为快速原型开发和生产环境的理想解决方案。<br>LiteGS框架通过一系列技术创新克服了原始Gaussiansplatting框架的局限性，主要包括以下几个方面：首先，模块化设计将渲染过程分解为多个可定制的阶段，允许用户在不修改C++或CUDA代码的情况下调整特定步骤。其次，采用Morton编码方法来维护高效的空间局部性，并通过集群剔除和紧凑化来优化内存访问模式，减少GPU的计算负担。第三，LiteGS引入稀疏梯度，以确保在反向传播中剔除不必要的参数计算，提升计算效率。此外，改进的2D轴对齐边界框（AABB）减少了冗余计算，同时引入多批次归约算法优化梯度求和，降低了内存访问冲突。最终，通过这些技术的结合，LiteGS显著提高了整体计算性能，减少了训练过程中的冗余计算。<br>在实验部分，LiteGS的性能通过与原始3DGS实现进行比较来评估。实验在NVIDIAA100和RTX3090GPU上进行，使用Mip-NeRF360数据集进行训练。评估指标包括训练速度和渲染质量，采用PSNR、SSIM和LPIPS等质量指标，确保LiteGS在加速的同时不损失场景质量。结果显示，LiteGS在所有场景中均实现了显著的训练时间缩短，与原始3DGS相比，LiteGS的速度提升达到了3.4倍，甚至在集成了TamingGS的3DGS版本上仍然保持了1.4倍的速度优势。此外，质量指标方面，LiteGS在大多数场景中与3DGS表现相当或略有提升，证明了其在性能和质量上的双重优势。<br>LiteGS的工作原理可以简单理解为将复杂的3D图像处理过程分成多个小步骤，每个步骤都可以单独优化和调整。首先，它通过将图像中的点分组来提高处理效率，这样可以快速剔除不在视野中的部分，节省计算资源。然后，它会将可见的点重新组织到内存中，使得计算时能更快地访问这些数据。此外，LiteGS采用了一种聪明的方式来只计算那些真正需要更新的参数，避免了不必要的计算。通过这些方法，LiteGS不仅加快了训练速度，而且在处理图像质量上也没有妥协。总的来说，LiteGS就像是给传统的3D图像处理加装了一个高效的引擎，让它在保持质量的同时，速度飞快。<br>2025-03-02｜XMU<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00881v1<br>在计算机视觉和图形学领域，从多视图图像中表示三维场景是一项核心挑战，涉及高质量渲染和准确重建。近年来，3D高斯点云（3DGS）因其高质量渲染和快速推理速度而受到广泛关注。然而，由于高斯点云的无结构和不规则特性，确保几何重建的准确性仍然存在困难。现有方法主要集中在几何正则化上，常见的做法包括基于原始体的和双模型框架。然而，前者在渲染和重建之间存在固有冲突，而后者在计算和存储上则非常消耗资源。为了解决这些问题，本文提出了一种名为CarGS的统一模型，利用贡献自适应正则化技术实现高质量渲染和表面重建的同步。该框架的核心在于通过压缩几何正则化的知识，学习高斯原语的自适应贡献，从而提高模型的效率和效果。<br>CarGS的设计基于几个关键组件。首先，提出了一个轻量级的残差模块Lite-Geo，用于自适应调整高斯原语在渲染和重建中的贡献。该模块通过将几何正则化知识融入到一个紧凑的多层感知器（MLP）中，来优化每个高斯原语的贡献。其次，采用了一种几何引导的稠密化策略，该策略结合了法向量和符号距离场（SDF）信息，以提高捕捉高频细节的能力。此外，CarGS的统一结构避免了双模型方法所需的单独模型训练，从而显著降低了存储和计算成本。最后，通过引入几何正则化来指导模块的优化，进一步提升了几何重建的质量。整体而言，该方法在高效性和效果上均优于现有的基于原始体和双模型的方法。<br>为验证CarGS的有效性，研究团队在多个真实世界数据集上进行了实验，包括室内和室外场景。通过使用TanksandTemples（TnT）数据集，评估了表面重建的质量，并利用Mip-NeRF360数据集测试新视图合成的性能。实验结果显示，CarGS在表面重建和图像合成方面均达到了当前的最先进水平（SOTA），同时保持了实时速度和最小的存储需求。具体来说，CarGS在渲染质量和重建精度上超越了多种现有方法，并且在存储和训练时间方面表现出显著的优势。通过对比分析，CarGS显示出其在高频细节捕捉和几何一致性方面的强大能力，为未来的统一渲染和重建方法奠定了坚实基础。<br>在这项研究中，科学家们提出了一种新方法，旨在同时提高三维场景的渲染效果和重建精度。首先，他们设计了一个智能系统，可以根据每个高斯点的特性，灵活调整其在渲染和重建中的作用，就像给每个点分配不同的任务。其次，他们引入了一种新的策略，利用场景的形状和深度信息来帮助这些点更好地适应真实世界的细节。这样，系统不仅能快速生成高质量的图像，还能准确重建场景的几何形状。与传统方法相比，这种新方法大大减少了所需的计算资源和存储空间，确保了更快的处理速度和更佳的效果。总之，CarGS是一种高效且强大的工具，能够在虚拟现实、机器人和自动驾驶等领域发挥重要作用。<br>2025-03-02｜BIT,UCAS,RIC<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00848v1<br>本文提出了一种名为PSRGS（渐进式谱残差的3D高斯重建）的方法，旨在解决3D高斯点云重建在大规模遥感场景中的高频细节恢复问题。传统的3D高斯点云重建方法（3DGS）在处理小规模、单对象场景时表现良好，但在大规模场景中，生成的点云往往稀疏，导致细节丢失和伪影产生。PSRGS通过引入谱残差图，分离低频和高频区域，采用不同的优化策略，以提高高频细节的恢复能力。研究表明，该方法能够有效管理几何结构，减少伪影的生成，并在多个数据集上展示了优越的渲染质量，尤其是在恢复高频纹理细节方面。<br>PSRGS方法的核心在于其渐进式优化框架，主要包括三个模块。首先，低频和高频区域分离模块通过谱残差显著性图实现，利用傅里叶变换提取图像频域信息，分离出高频成分。其次，低频几何约束模块通过结合Huber损失和深度感知损失，确保低频区域的几何结构准确，避免高频细节的损失。最后，高频纹理恢复模块通过提取渲染图像的梯度特征，分析其与总变差损失的相关性，优化高频区域的恢复，确保高频细节的精确重建。此外，预训练网络用于计算多视角的纹理感知损失，进一步提升细节质量，确保几何和纹理的独立优化。<br>为验证PSRGS的有效性，研究团队在多个数据集上进行了实验，包括mip-NeRF360数据集和Lund大学的数据集。实验结果显示，PSRGS在高频细节恢复和生成高斯椭球体的几何精度方面，均显著优于传统的3DGS及其变体。通过与现有方法的比较，PSRGS在PSNR、SSIM等指标上表现出更高的值，而在LPIPS指标上则更低，表明其在渲染质量和细节恢复方面的进步。此外，定性结果也显示，PSRGS能够有效去除伪影，提升大规模场景的重建效果，展示了其在复杂3D场景应用中的潜力。<br>PSRGS是一种新方法，用于改善3D图像重建，特别是在处理大场景时，它能更好地恢复细节。这个方法分为三个主要步骤。首先，它会分析图像，找出哪些部分是低频的（比如大的形状）和高频的（比如细节和纹理）。然后，对于低频部分，它会使用一些数学技巧来确保这些大的形状被准确地重建。接着，对于高频部分，它会提取图像的边缘信息，确保细节得到精确恢复。最后，PSRGS还会利用一个预先训练的网络来进一步提升细节的质量。通过这样的分步骤处理，PSRGS能够有效地减少错误和伪影，让大场景的重建效果更好。<br>2025-03-02｜HunanU,KIT,ETHZurich<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00747v1https :&#x2F;&#x2F;github.com&#x2F;warriordby&#x2F;LFX<br>在现代计算机视觉领域，光场（LightField,LF）技术因其能够捕捉空间和角度信息而备受关注。然而，现有的LF任务因其独特的角度偏好，往往需要特定的架构调整，导致任务间协作的困难。为了解决这一问题，本文首次提出了“视差场”（FieldofParallax,FoP）的概念，旨在提取不同LF表示中的共同特征，以支持多任务学习。FoP由三大核心特征构成：投影差异、相邻差异和上下文一致性。通过FoP的统一表示，本文还引入了LFX框架，能够无缝处理多种LF视觉任务，显著提升了在语义分割、显著目标检测和物体检测等任务上的表现，展示了其在LF感知领域的强大潜力。<br>本研究提出的LFX框架旨在提取不同LF表示中的共同特征，采用了两步角度适配器。具体方法如下：<br>特征提取：首先，通过嵌入操作从输入图像中提取关键特征，生成多个图像补丁的特征表示。<br>角度适配：在第二步中，利用共享权重的方式，提取投影差异和相邻差异，确保跨视图的一致性。这一过程通过动态分配策略和共享权重方法来实现，旨在保持全局上下文的一致性，同时捕捉局部角度特征。<br>通过这种方式，LFX框架能够有效整合不同LF表示中的特征，克服任务间的适应性障碍，提升多任务学习的性能。<br>为了验证所提出方法的有效性，本文在三个数据集上进行了广泛的实验，分别针对语义分割、显著目标检测和物体检测任务。实验结果表明，LFX框架在UrbanLF、PKU和Duftv2数据集上均取得了显著的性能提升。例如，在UrbanLF数据集上，LFX的平均交并比（mIoU）达到了84.74%，在PKU数据集上，LFX在显著目标检测任务上也表现出色。通过与多种现有模型的对比，LFX展现了其在处理多种LF任务时的优越性和通用性，证明了其作为光场感知任务统一框架的潜力。<br>在这项研究中，我们提出了一种新的方法来处理光场图像，使得不同类型的视觉任务能够更好地协同工作。首先，我们从输入的光场图像中提取出重要特征，就像从一张复杂的拼图中找出关键的拼块。然后，我们设计了一个角度适配器，这个适配器可以帮助我们理解不同视角之间的关系，确保在不同的视角下，图像的上下文信息保持一致。通过这种方式，我们的模型能够更好地处理多种任务，比如识别物体、分割图像等。最终的实验结果显示，这种方法在多个任务上都取得了很好的效果，证明了它在光场图像处理中的有效性。<br>2025-03-01｜ZJU,NUAA,Udeer｜CVPR2025<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00513v1https :&#x2F;&#x2F;github.com&#x2F;hanxunyu&#x2F;Inst3D-LMM<br>在3D场景理解领域，传统的方法通常针对单一任务进行优化，如3D视觉定位、问答和密集标注。然而，这些方法在处理复杂3D环境时存在局限性，无法有效整合2D语义信息与3D几何特征之间的关系。为了解决这一问题，本文提出了一种新的实例感知3D大型多模态模型（Inst3D-LMM），旨在同时处理多种3D场景理解任务。该模型通过引入多视角跨模态融合模块（MCMF）和3D实例空间关系模块（3D-ISR），实现了2D和3D特征的高效融合，从而生成细粒度的实例级和场景级表示。通过多任务指令调优，Inst3D-LMM能够在多种下游任务中展现出优越的性能，尤其在3D视觉定位、推理和场景理解方面。<br>Inst3D-LMM的核心方法包括以下几个关键模块：<br>实例级特征提取：首先使用预训练的3D实例分割模型对3D点云进行分割，得到每个实例的几何特征。随后，利用2D视觉基础模型（VFM）提取对应的2D语义特征。<br>多视角跨模态融合（MCMF）：该模块通过将3D几何特征和2D语义特征进行融合，生成丰富的实例级表示。具体过程包括使用自注意力机制来增强特征的语义信息。<br>3D实例空间关系（3D-ISR）：该模块用于捕捉3D场景中对象之间的复杂空间关系，通过计算实例中心坐标的欧几里得距离和角度，生成空间关系特征。<br>端到端多任务指令调优：最后，模型通过多任务指令调优，能够同时处理多个3D语言任务，而无需针对特定任务进行微调。<br>在实验部分，研究团队在ScanNetv2数据集上进行了大量测试，验证了Inst3D-LMM在多个3D理解任务上的有效性。通过与现有最先进的方法进行比较，Inst3D-LMM在3D视觉定位、问答和密集标注任务中均表现出色。例如，在3D视觉定位任务中，Inst3D-LMM的准确率和F1分数均超越了其他主流模型。此外，研究还进行了消融实验，分析了MCMF和3D-ISR模块对模型性能的贡献。结果表明，整合这两个模块显著提升了模型在空间关系理解和语义融合方面的能力，进而提高了整体的任务表现。<br>在Inst3D-LMM的工作原理中，首先，我们需要从3D场景中提取每个物体的特征。这就像在一个房间里找到每个家具的位置和颜色。接下来，我们会用不同的视角拍摄这些物体的照片，以获取它们的外观信息。然后，MCMF模块会将这些3D特征和2D照片特征结合起来，形成一个更完整的物体描述。接着，3D-ISR模块会帮助我们理解这些物体之间的空间关系，比如哪个物体在另一个物体的上方或旁边。最后，通过多任务指令调优，Inst3D-LMM能够同时处理多个问题，比如问“这个房间里有多少个椅子？”或“这个桌子旁边有什么？”这样一来，模型就能更智能地理解3D场景中的信息。<br>2025-03-01｜KeioU,TokyoUniversityofScience,NTT<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00389v1<br>本文提出了一种新颖的3D人类姿态估计方法，称为BGM2Pose，利用背景音乐（BGM）作为主动感知信号。这种方法不同于传统依赖于刺耳的脉冲信号的技术，BGM2Pose采用自然音乐，最大限度地减少了对人类的干扰。背景音乐的动态特性带来了挑战，因为其音量和音调会随着时间变化，导致人类动作引起的信号变化与音乐变化混合在一起。为了克服这些挑战，BGM2Pose引入了对比姿态提取模块（CPE）和频率注意模块（FA），前者通过对比学习从音频数据中提取姿态信息，而后者则动态关注与人类动作相关的细微声学变化。实验表明，该方法在多种条件下均表现出色，展示了其在实际应用中的潜力。<br>BGM2Pose的核心是通过三个主要模块实现3D人类姿态估计。首先，音频特征提取模块负责从录制的声音信号中提取强度向量和对数梅尔频谱特征。这些特征用于捕捉声学信号中的人类动作信息。其次，频率注意模块（FA）通过动态计算声学特征中的相关频率，识别出对姿态估计有意义的频段。FA模块的设计确保了对背景音乐中变化的有效响应。最后，对比姿态提取模块（CPE）利用对比学习的方式，鼓励模型从音频数据中提取出姿态信息，同时排除音乐成分的干扰。通过这些模块的协同工作，BGM2Pose能够在复杂的声学环境中准确估计人类的3D姿态。<br>为了验证BGM2Pose的有效性，研究者们进行了多项实验，比较了该方法与现有技术的性能。实验设置包括单音乐和跨音乐场景，评估了模型在不同音乐类型下的表现。结果表明，BGM2Pose在各项指标上均优于其他基线方法，如均方根误差（RMSE）和关键点正确率（PCK）。此外，研究者还进行了消融实验，分析了各个模块对整体性能的贡献，结果显示，CPE模块和FA模块的引入显著提高了姿态估计的准确性。为了评估模型对噪声的鲁棒性，实验还在背景噪声的条件下进行，BGM2Pose在这种情况下也表现出较强的稳定性。<br>BGM2Pose的工作原理可以简单理解为使用背景音乐来帮助识别和估计人的动作。首先，系统通过麦克风收集周围的声音，包括播放的音乐和人们的动作产生的声音。然后，系统会提取这些声音的特征，就像从一首歌中找出旋律一样。接着，系统会特别关注那些与人类动作相关的声音变化，确保能够识别出人的姿态。最后，系统会通过对比学习的方式，确保提取到的姿态信息是准确的，而不是被音乐的变化所干扰。通过这样的方式，BGM2Pose能够在不使用传统监控设备的情况下，准确捕捉到人类的3D姿态。<br>2025-03-01｜NYCU,NCCU<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00357v1<br>3DGaussianSplatting（3DGS）作为一种新兴的3D表示方法，近年来受到广泛关注，尤其是在减少存储需求和内存占用方面。然而，现有研究往往忽视了3DGS表示的压缩及远程传输需求。为此，本文提出了一种名为CAT-3DGS的框架，旨在实现基于率失真优化的3DGS压缩。此方法通过量化和熵编码稀疏的高斯原语，充分利用其内部和外部相关性。CAT-3DGS基于ScaffoldGS，采用上下文自适应三平面方法，利用多尺度三平面捕捉空间相关性，从而实现高效的自回归编码。此外，CAT-3DGS还引入了一种视频率感知的掩蔽机制，以跳过对渲染质量影响较小的高斯原语，从而优化编码效率。<br>CAT-3DGS的方法主要包括以下几个关键点：<br>三平面基础的超先验：通过主成分分析（PCA）将高斯原语投影到多尺度的三平面上，捕捉它们之间的空间相关性。这种超先验用于编码高斯原语的属性。<br>空间自回归模型（SARM）：为三平面编码引入了空间自回归模型，以充分利用高斯原语之间的相关性，从而提高熵编码的效率。<br>通道自回归模型（CARM）：首次在3DGS压缩中引入通道自回归模型，探索单个高斯原语内部的相关性。每个特征被分成多个切片进行编码，从而进一步提升编码效率。<br>视频率感知掩蔽机制：该机制根据高斯原语对渲染质量的贡献度进行优先级排序，跳过对渲染质量影响较小的高斯原语，减少编码负担。<br>在实验中，CAT-3DGS在多个真实世界数据集上进行了验证，包括Mip-NeRF360、Tanks&amp;Temples等。实验结果表明，CAT-3DGS在压缩性能上达到了最先进的水平，尤其是在率失真性能方面，显著优于现有的压缩方法。通过对比，CAT-3DGS在压缩比和渲染质量上均表现出色，例如在Mip-NeRF360数据集中，相较于传统3DGS和ScaffoldGS，CAT-3DGS实现了更高的PSNR，同时减少了压缩所需的比特率。此外，消融实验进一步验证了三平面超先验、空间自回归模型和视频率感知掩蔽机制在提升压缩性能中的重要性。<br>CAT-3DGS的工作原理可以简单理解为通过“聪明的编码”来压缩3D图像。首先，它使用一种叫做三平面的技术，将复杂的3D数据转化为多个简单的2D平面，这样更容易处理。接下来，通过一种叫做空间自回归模型的方法，它能够识别这些平面之间的关系，从而更有效地存储信息。同时，CAT-3DGS还引入了通道自回归模型，进一步分析每个数据点内部的关系，使得压缩更加高效。最后，它使用一种智能的掩蔽机制，自动忽略那些对最终图像质量影响不大的数据，从而减少需要处理的信息量。通过这些方法，CAT-3DGS能够在保持高质量图像的同时，大幅度减少数据存储和传输的需求。<br>2025-03-02｜UTAustin,Stanford,WestlakeU<br>http :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.00807v1<br>本文提出了一种新颖的形状分析框架，命名为GenAnalysis。该框架通过学习隐式形状生成器，旨在实现对人造形状的联合分析，包括形状匹配和分割。核心思想是通过设计一种正则化损失，强制在潜在空间中相近的合成形状之间保持尽可能的仿射变形（AAAP）。这一方法使得研究人员能够在相邻形状的上下文中理解形状的变异，并在输入形状之间提供结构保持的插值。通过恢复每个形状切线空间中的分段仿射向量场，研究团队能够提取形状变异并为单个形状分割提供线索。接着，通过迭代传播AAAP变形，生成形状对应关系，并利用这些对应关系整合单个形状的分割线索，最终实现一致的形状匹配分割。实验结果表明，GenAnalysis在ShapeNet数据集上的形状匹配和联合分割任务中，优于现有的多种方法。<br>GenAnalysis的实现分为四个主要阶段。首先，在形状生成器学习阶段，框架通过引入正则化损失，强制相邻合成形状之间保持分段仿射变形。该损失基于L2范数，确保生成的合成形状在潜在空间中紧密相连。其次，在形状变异分析阶段，分析每个形状的切线空间，提取表示形状变异的向量场，并使用谱方法来分析其结构特征。第三阶段是形状匹配，通过在生成的中间形状之间传播AAAP变形来计算形状之间的对应关系，确保得到的对应关系在形状间保持一致。最后，在一致分割阶段，利用前面阶段得到的单个形状分割线索，整合成一致的形状分割结果，采用谱方法进行优化。整个过程的设计旨在克服传统模板方法在处理复杂形状变异时的局限性。<br>为了验证GenAnalysis的有效性，研究团队在ShapeNet数据集上进行了多项实验，重点评估其在形状匹配和一致性分割任务上的表现。实验结果表明，GenAnalysis在多个指标上超越了现有的最先进方法，尤其是在形状匹配任务中，其平均交并比（mIoU）比DAE-Net高出3.2%。此外，研究团队通过消融实验分析了每个组件对整体性能的贡献，验证了正则化损失和形状生成器设计的重要性。这些实验结果不仅证明了GenAnalysis的优势，也为形状分析领域提供了新的思路和方法，展示了学习生成模型在处理复杂形状变异时的潜力。<br>在GenAnalysis的方法部分，研究者们采用了一个分阶段的策略来分析形状。首先，他们训练一个形状生成器，这个生成器能够根据输入的形状生成相似的形状，并在这些形状之间保持一种“平滑”的变形方式。接着，他们分析这些生成的形状，提取出每个形状的细微变化，通过计算形状表面上不同点之间的距离来判断哪些点属于同一部分。然后，他们通过对中间形状的变形进行传播，找到不同形状之间的对应关系。最后，他们整合这些信息，以确保每个形状的分割结果是一致的，形成一个整体的分割方案。这个过程类似于在不同的拼图中寻找相同的图案，帮助我们更好地理解和处理复杂的人造形状。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/03/17/1000000348-2247527322-8/">https://zejuncao.github.io/2025/03/17/1000000348-2247527322-8/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/AIGC-Research/">
                                    <span class="chip bg-color">AIGC Research</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/03/17/1000000348-2247527322-6/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000000348_2247527322_6.jpg" class="responsive-img" alt="312-B1｜多模态系列">
                        
                        <span class="card-title">312-B1｜多模态系列</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/AIGC-Research/">
                        <span class="chip bg-color">AIGC Research</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/03/17/1000000168-2247487420-1/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000000168_2247487420_1.jpg" class="responsive-img" alt="deepseek v3 生成答案的速度为什么可以这么快？">
                        
                        <span class="card-title">deepseek v3 生成答案的速度为什么可以这么快？</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/AIGC%E5%B0%8F%E7%99%BD%E5%85%A5%E9%97%A8%E8%AE%B0/">
                        <span class="chip bg-color">AIGC小白入门记</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/Garfusion/posts" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/Garfusion/posts" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
