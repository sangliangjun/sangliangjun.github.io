<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="必知！大模型时代超常用的训练、微调、推理、部署框架（1）, ZejunCao&#39;Blogs">
    <meta name="description" content="必知！大模型时代超常用的训练、微调、推理、部署框架（1）

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

在人工智能和机器学习领域，选择合适的工具和框架是构建高效、可扩展解决方案的关键。随着模型规模的不断扩大和应用场景">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>必知！大模型时代超常用的训练、微调、推理、部署框架（1） | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000001496_2247588466_1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">必知！大模型时代超常用的训练、微调、推理、部署框架（1）</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%95%B0%E6%8D%AESTUDIO/">
                                <span class="chip bg-color">数据STUDIO</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-17
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/TMZPBAj6EFqw4usGXDLyaA">必知！大模型时代超常用的训练、微调、推理、部署框架（1）</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>在人工智能和机器学习领域，选择合适的工具和框架是构建高效、可扩展解决方案的关键。随着模型规模的不断扩大和应用场景的日益复杂，开发者需要依赖一系列强大的框架来满足从模型训练到推理部署的全流程需求。本文将深入探讨几款在AI开发中备受瞩目的框架，包括PyTorch、NVIDIATriton、ONNXRuntime、Transformers、DeepSpeed、Megatron和PEFT。这些框架各具特色，分别专注于训练优化、推理加速、跨平台部署、高效微调等不同领域。通过对比它们的核心功能、特点、优缺点以及适用场景，我们将帮助开发者更好地理解如何根据实际需求选择最合适的工具，从而提升开发效率并优化模型性能。<br>pytorch.org[1]。PyTorch的官方网站提供了丰富的资源，包括文档、教程、API参考、社区论坛以及最新的版本下载。官网还提供了详细的安装指南，支持多种操作系统（Windows、Linux、macOS）和多种安装方式（pip、conda、源码编译）。<br>PyTorch是一个动态图优先的深度学习框架，以灵活性和研究友好性著称。PyTorch的设计理念是“动态计算图优先”，这意味着它允许用户在运行时动态地构建和修改计算图。这种设计使得PyTorch在研究和实验阶段非常受欢迎，因为它允许研究人员快速迭代和调试模型。与静态图框架（如TensorFlow1.x）相比，PyTorch的动态图机制使得代码更直观、更易于理解。<br>动态计算图（即时执行）:<br>PyTorch使用动态计算图（也称为即时执行模式），这意味着计算图是在代码执行时动态构建的。这种机制使得调试更加方便，因为用户可以使用标准的Python调试工具（如pdb）来逐步执行代码并检查中间结果。<br>动态计算图还允许用户在每次前向传播时修改模型结构，这在某些研究场景中非常有用，例如在循环神经网络（RNN）中根据输入序列的长度动态调整网络结构。<br>张量计算:<br>PyTorch的核心数据结构是torch.Tensor，它是一个多维数组，类似于NumPy的ndarray，但支持GPU加速。PyTorch提供了丰富的张量操作，包括数学运算、线性代数、随机数生成等。<br>张量操作是PyTorch的基础，几乎所有深度学习模型的实现都依赖于张量操作。PyTorch的张量操作接口设计得非常直观，与NumPy的接口高度兼容，因此熟悉NumPy的用户可以很容易地上手PyTorch。<br>自动求导:<br>PyTorch的torch.autograd模块提供了自动求导功能，允许用户自动计算梯度。通过requires_grad&#x3D;True标记张量，PyTorch会自动跟踪所有涉及该张量的操作，并在反向传播时自动计算梯度。<br>自动求导是深度学习模型训练的核心功能之一，PyTorch的自动求导机制非常灵活，支持复杂的计算图结构，并且可以轻松地处理高阶导数。<br>分布式训练:<br>PyTorch提供了多种分布式训练的支持，包括数据并行、模型并行和混合并行。通过torch.distributed模块，用户可以在多个GPU或多个节点上进行分布式训练，以加速大规模模型的训练过程。<br>PyTorch还支持多种分布式训练后端，如NCCL、Gloo和MPI，用户可以根据自己的硬件环境选择合适的后端。<br>与Python深度集成，调试便捷:<br>PyTorch与Python深度集成，几乎所有的PyTorch代码都可以直接使用Python的标准工具进行调试。例如，用户可以使用print语句、pdb调试器或IDE的调试功能来检查和调试PyTorch代码。<br>这种深度集成使得PyTorch在研究和实验阶段非常受欢迎，因为研究人员可以快速迭代和调试模型，而不需要额外的学习成本。<br>支持GPU加速和混合精度训练:<br>PyTorch支持GPU加速，用户可以通过torch.cuda模块将张量和模型移动到GPU上进行计算。PyTorch还支持多GPU训练，用户可以通过简单的代码修改将模型分布到多个GPU上进行并行计算。</p>
<p>生产部署需依赖TorchScript&#x2F;ONNX:<br>虽然PyTorch在研究阶段非常灵活，但在生产环境中部署PyTorch模型时，通常需要将模型转换为TorchScript或ONNX格式。TorchScript是PyTorch提供的一种中间表示，可以将PyTorch模型转换为静态图，以便在生产环境中高效执行。<br>ONNX（OpenNeuralNetworkExchange）是一种开放的模型交换格式，PyTorch支持将模型导出为ONNX格式，以便在其他深度学习框架或推理引擎中使用。虽然这些工具提供了部署的灵活性，但也增加了部署的复杂性。<br>训练速度较静态图框架（如TensorFlow）略慢:<br>由于PyTorch使用动态计算图，每次前向传播时都需要重新构建计算图，这会导致一定的性能开销。相比之下，静态图框架（如TensorFlow）在训练前会先构建并优化计算图，因此在某些情况下训练速度可能会更快。<br>不过，PyTorch社区一直在努力优化性能，通过引入JIT（Just-In-Time）编译等技术，PyTorch的训练速度已经得到了显著提升。<br>⭐️⭐️⭐️⭐️⭐️（适合快速原型开发）<br>PyTorch以其简洁直观的API设计和与Python的深度集成而著称，使得用户可以快速上手并进行模型开发。PyTorch的文档和教程非常丰富，社区活跃，用户可以在遇到问题时很容易找到解决方案。<br>对于研究人员和开发者来说，PyTorch是一个非常适合快速原型开发的工具，因为它允许用户在短时间内实现和验证新的想法。<br>学术研究、模型实验、小规模训练<br>PyTorch在学术研究中非常受欢迎，许多最新的深度学习论文都使用PyTorch实现。由于其灵活性和易用性，PyTorch也非常适合进行模型实验和快速迭代。<br>对于小规模训练任务，PyTorch提供了足够的灵活性和性能，但对于大规模训练任务，用户可能需要依赖分布式训练或其他优化技术。<br>PyTorch主要用于模型的训练和验证阶段。由于其动态计算图的特性，PyTorch在模型开发阶段非常灵活，允许用户快速调整模型结构和参数。<br>在模型验证阶段，PyTorch提供了丰富的工具和库（如torchvision、torchtext等）来帮助用户进行数据预处理、模型评估和可视化。<br>与HuggingFace、ONNX、TensorBoard集成，社区庞大<br>PyTorch拥有庞大的生态系统，与许多流行的工具和库集成。例如，HuggingFace的transformers库提供了大量预训练模型，用户可以轻松地在PyTorch中使用这些模型。<br>PyTorch还支持将模型导出为ONNX格式，以便在其他框架中使用。此外，PyTorch与TensorBoard集成，用户可以使用TensorBoard来可视化训练过程和模型性能。<br>PyTorch的社区非常活跃，用户可以在论坛、GitHub和社交媒体上找到大量的资源和支持。</p>
<p>PyTorch是一个功能强大且灵活的深度学习框架，特别适合研究和实验阶段的使用。其动态计算图机制、与Python的深度集成以及丰富的生态系统使得PyTorch成为许多研究人员和开发者的首选工具。尽管在生产部署和训练速度方面存在一些挑战，但PyTorch社区一直在积极改进和优化，未来有望在这些方面取得更大的进展。</p>
<p>高性能AI推理服务器，支持多框架、多硬件部署。NVIDIATriton是一个专为生产环境设计的推理服务器，支持多种深度学习框架（如TensorFlow、PyTorch、ONNX等）和多种硬件（如GPU、CPU、TPU）。它的目标是提供高吞吐量、低延迟的推理服务，适用于云、数据中心和边缘计算场景。<br>动态批处理:<br>Triton支持动态批处理（DynamicBatching），能够根据请求的负载动态调整批处理大小，从而最大化硬件利用率并减少推理延迟。这对于处理实时请求和高吞吐量的场景尤为重要。<br>动态批处理还支持自定义批处理策略，用户可以根据业务需求调整批处理逻辑。<br>并发模型执行:<br>Triton允许在同一服务器上并发执行多个模型，甚至可以在同一GPU上同时运行多个模型的实例。这种并发执行机制使得Triton能够高效地利用硬件资源，满足高并发的推理需求。<br>通过并发模型执行，Triton可以同时为多个客户端提供服务，而不会因为单一模型的负载过高而影响整体性能。<br>多框架支持:<br>Triton支持多种深度学习框架的模型，包括TensorFlow、PyTorch、ONNX、TensorRT等。用户无需将模型转换为特定格式，可以直接部署原始模型文件。<br>这种多框架支持使得Triton成为一个通用的推理平台，适用于各种深度学习工作流。<br>跨框架和硬件兼容:</p>
<p>用户可以在同一服务器上部署不同框架的模型，并根据硬件资源动态分配计算任务。<br>集成Kubernetes和Prometheus:<br>Triton与Kubernetes深度集成，支持在容器化环境中部署和管理推理服务。用户可以通过Kubernetes实现自动扩缩容、负载均衡和高可用性。<br>Triton还集成了Prometheus，提供实时的性能监控和指标收集功能。用户可以通过Prometheus监控推理服务的吞吐量、延迟和资源利用率。<br>配置复杂:<br>Triton的配置相对复杂，用户需要管理模型仓库（ModelRepository）和YAML配置文件。模型仓库需要按照特定的目录结构组织模型文件，而YAML文件则用于定义模型的配置参数（如批处理大小、硬件资源分配等）。<br>对于初学者来说，配置Triton可能需要一定的学习成本，尤其是在多模型、多硬件的复杂场景中。<br>依赖NVIDIA生态:<br>Triton深度依赖NVIDIA的硬件和软件生态（如TensorRT、CUDA），虽然它也支持CPU和其他硬件，但在GPU上的性能优化主要依赖于NVIDIA的技术。对于非NVIDIA硬件的用户，Triton的优势可能无法完全发挥。<br>⭐️⭐️⭐️（适合生产环境专家）<br>Triton的功能强大且灵活，但其配置和管理相对复杂，更适合有经验的开发者和运维人员。对于初学者来说，可能需要花费一定时间学习Triton的配置和部署流程。<br>对于生产环境中的专家团队，Triton提供了丰富的功能和高度可定制性，能够满足复杂的推理需求。<br>云&#x2F;边缘推理服务:<br>Triton适用于云和边缘计算场景，能够高效地处理大规模的推理请求。在云环境中，Triton可以通过Kubernetes实现自动扩缩容和负载均衡；在边缘计算场景中，Triton可以在资源受限的设备上运行，提供低延迟的推理服务。<br>高吞吐在线服务:<br>Triton的动态批处理和并发模型执行功能使其非常适合高吞吐量的在线服务场景，例如推荐系统、自然语言处理和计算机视觉应用。<br>Triton主要用于模型的部署和推理阶段。它提供了一个高性能的推理引擎，能够将训练好的模型快速部署到生产环境中，并提供高效的推理服务。<br>与训练框架（如PyTorch、TensorFlow）不同，Triton专注于推理阶段的优化，旨在最大化硬件的利用率和推理性能。</p>
<p>此外，Triton还支持NVIDIA的Multi-InstanceGPU（MIG）技术，可以在单个GPU上运行多个模型的实例，从而提高资源利用率。<br>安装Triton:<br>准备模型仓库:<br>创建一个模型仓库目录，并按照Triton的要求组织模型文件。例如：<br>启动Triton服务器:<br>发送推理请求:<br>使用Triton的HTTP或gRPCAPI发送推理请求。例如，使用Python客户端：<br>NVIDIATritonInferenceServer是一个功能强大且灵活的推理服务器，适用于云、数据中心和边缘计算场景。它支持多框架、多硬件部署，并提供了动态批处理、并发模型执行等高级功能，能够满足高吞吐量、低延迟的推理需求。<br>尽管Triton的配置和管理相对复杂，但其强大的功能和与NVIDIA生态的深度集成使其成为生产环境中推理服务的理想选择。对于需要高性能推理服务的团队，Triton提供了全面的解决方案。</p>
<p>跨平台推理加速引擎，支持ONNX格式模型。ONNXRuntime是一个轻量级、高性能的推理引擎，旨在为ONNX格式的模型提供跨平台的推理加速。它支持多种硬件后端（如CPU、GPU、FPGA）和多种操作系统（如Windows、Linux、macOS），适用于从云端到边缘设备的多种部署场景。<br>高性能推理:<br>ONNXRuntime提供了高效的推理引擎，能够在多种硬件（如CPU、GPU、FPGA）上加速ONNX模型的推理。通过优化计算图和执行计划，ONNXRuntime能够显著提升推理性能。<br>它还支持多种硬件后端，包括CUDA（NVIDIAGPU）、DirectML（WindowsGPU）、OpenVINO（IntelCPU&#x2F;GPU）等，用户可以根据硬件环境选择合适的后端。<br>训练加速（ORTModule）:<br>ONNXRuntime不仅支持推理加速，还提供了训练加速功能。通过ORTModule，用户可以将PyTorch模型转换为ONNX格式，并在训练过程中使用ONNXRuntime进行加速。<br>ORTModule能够自动优化训练过程中的计算图，减少显存占用并提升训练速度，特别适合大规模模型的训练任务。<br>轻量级，适合嵌入式设备:<br>ONNXRuntime是一个轻量级的推理引擎，适合在资源受限的嵌入式设备上运行。它支持多种操作系统和硬件平台，能够在边缘设备上提供高效的推理服务。<br>通过优化模型的计算图和内存占用，ONNXRuntime能够在嵌入式设备上实现低延迟、高效率的推理。<br>与PyTorch&#x2F;TensorFlow无缝转换:</p>
<p>这种无缝转换使得ONNXRuntime成为一个通用的推理平台，适用于多种深度学习框架的工作流。<br>部分硬件加速器支持有限:<br>虽然ONNXRuntime支持多种硬件后端，但对于某些特定的硬件加速器（如TPU、FPGA），支持可能有限。用户需要根据硬件环境选择合适的后端，并可能需要额外的配置和优化。<br>此外，ONNXRuntime的性能优化主要依赖于硬件厂商提供的库（如CUDA、OpenVINO），对于非主流硬件的支持可能不如主流硬件完善。<br>⭐️⭐️⭐️（需熟悉模型转换）<br>ONNXRuntime的使用需要一定的学习成本，特别是对于模型转换和硬件后端的配置。用户需要熟悉如何将PyTorch或TensorFlow模型导出为ONNX格式，并根据硬件环境选择合适的后端。<br>对于有经验的开发者来说，ONNXRuntime提供了丰富的功能和高度可定制性，能够满足复杂的推理需求。<br>跨平台部署:<br>ONNXRuntime支持多种操作系统和硬件平台，适用于跨平台的模型部署。用户可以在Windows、Linux、macOS等操作系统上部署ONNX模型，并在CPU、GPU、FPGA等硬件上运行。<br>边缘设备推理:<br>ONNXRuntime的轻量级设计使其非常适合在边缘设备上运行。它能够在资源受限的设备上提供高效的推理服务，适用于物联网（IoT）、移动设备等边缘计算场景。<br>模型推理与轻量化训练。ONNXRuntime主要用于模型的推理阶段，能够为ONNX格式的模型提供高效的推理加速。此外，它还支持训练加速功能，通过ORTModule可以在训练过程中优化计算图和显存占用。<br>微软主导，与Azure云服务集成:<br>ONNXRuntime由微软主导开发，并与Azure云服务深度集成。用户可以通过AzureMachineLearning服务轻松部署和管理ONNX模型。<br>此外，ONNXRuntime还与多种硬件厂商（如NVIDIA、Intel）合作，提供了丰富的硬件后端支持。<br>安装ONNXRuntime:<br>加载ONNX模型:<br>运行推理:<br>ONNXRuntime是一个高性能、跨平台的推理引擎，专注于加速ONNX格式模型的推理。它支持多种硬件后端和操作系统，适用于从云端到边缘设备的多种部署场景。<br>尽管ONNXRuntime的使用需要一定的学习成本，但其强大的功能和与多种深度学习框架的无缝集成使其成为跨平台模型部署的理想选择。对于需要高性能推理服务的团队，ONNXRuntime提供了全面的解决方案。<br>huggingface.co&#x2F;transformers[4]HuggingFace的Transformers库是一个开源的NLP工具库，专注于提供预训练模型和简洁的API，支持多种自然语言处理任务。官网提供了详细的文档、教程、模型库以及社区支持，用户可以通过官网快速上手并获取最新的模型和工具。<br>NLP预训练模型库，覆盖文本生成、分类等任务。<br>Transformers库旨在为自然语言处理（NLP）任务提供开箱即用的预训练模型和工具。它涵盖了从文本分类、命名实体识别到文本生成、问答系统等多种任务，支持多种流行的预训练模型（如BERT、GPT、T5等），并提供了简洁的API供用户快速实现任务。<br>提供BERT、GPT等模型的微调接口:<br>Transformers库提供了丰富的预训练模型（如BERT、GPT、RoBERTa、T5等），用户可以通过简单的API调用加载这些模型，并在自己的数据集上进行微调（Fine-tuning）。<br>微调接口支持多种任务，包括文本分类、序列标注、文本生成等。用户只需定义数据集和任务类型，即可快速完成模型微调。<br>支持PyTorch、TensorFlow、JAX:<br>Transformers库支持多种深度学习框架，包括PyTorch、TensorFlow和JAX。用户可以根据自己的偏好选择合适的框架，并使用统一的API进行模型加载和训练。<br>这种多框架支持使得Transformers库能够灵活地适应不同的开发环境和工作流。<br>API设计简洁，模型库丰富:<br>Transformers库的API设计非常简洁，用户只需几行代码即可加载预训练模型并进行推理或微调。例如，加载BERT模型并生成文本嵌入只需以下代码：<br>模型库涵盖了数百种预训练模型，用户可以根据任务需求选择合适的模型。<br>支持快速迁移学习和部署:<br>Transformers库支持迁移学习，用户可以通过微调预训练模型快速适应新的任务。此外，库还提供了模型导出和部署工具，支持将模型部署到生产环境中。<br>通过HuggingFace的PipelineAPI，用户可以快速实现端到端的NLP任务，例如文本分类、情感分析等。<br>大模型显存占用高：Transformers库中的大模型（如GPT-3、T5）在推理和训练时需要占用大量显存，这对硬件资源提出了较高要求。对于资源受限的环境，用户可能需要使用模型压缩技术（如量化、剪枝）来减少显存占用。<br>⭐️⭐️⭐️⭐️⭐️（开箱即用）Transformers库以其简洁的API设计和丰富的模型库著称，用户无需深入了解模型细节即可快速实现NLP任务。对于初学者和研究人员来说，Transformers库是一个非常友好的工具。<br>NLP任务开发:<br>Transformers库适用于各种NLP任务的开发，包括文本分类、命名实体识别、文本生成、问答系统等。用户可以通过微调预训练模型快速实现这些任务。<br>快速原型验证:<br>Transformers库的简洁API和丰富模型库使其非常适合快速原型验证。用户可以在短时间内构建和测试NLP模型，验证想法的可行性。<br>Transformers库主要用于模型的微调和推理阶段。用户可以通过加载预训练模型并在自己的数据集上进行微调，以适应特定任务。此外，库还提供了高效的推理接口，支持在生产环境中部署模型。<br>HuggingFaceHub（数千预训练模型）:<br>HuggingFaceHub是一个开放的模型共享平台，提供了数千种预训练模型和数据集。用户可以通过Hub快速查找和下载适合自己任务的模型。<br>Hub还支持模型上传和分享，用户可以将自己训练的模型上传到Hub，供其他用户使用。<br>安装Transformers库:<br>加载预训练模型并进行推理:<br>微调预训练模型:<br>HuggingFace的Transformers库是一个功能强大且易用的NLP工具库，专注于提供预训练模型和简洁的API。它支持多种NLP任务和深度学习框架，适用于从研究到生产的多种场景。<br>尽管大模型的显存占用较高，但Transformers库通过丰富的模型库和简洁的API设计，为用户提供了快速实现NLP任务的便利。对于需要快速原型验证和生产部署的团队，Transformers库是一个理想的选择。<br>huggingface.co&#x2F;docs&#x2F;accelerate[5]。HuggingFace的Accelerate库是一个专注于简化分布式训练的工具库，旨在帮助用户轻松实现多GPU、多节点训练，而无需大幅修改代码。官网提供了详细的文档、教程和示例代码，用户可以通过官网快速上手并了解其功能。<br>简化分布式训练的工具库。Accelerate的目标是降低分布式训练的复杂性，让用户能够专注于模型开发，而不必花费大量时间配置多GPU或多节点环境。它支持多种硬件（如GPU、TPU）和多种训练场景（如单机多卡、多节点），适用于从研究到生产的多种需求。<br>自动化多GPU&#x2F;TPU配置:<br>Accelerate提供了自动化的多GPU和TPU配置功能，用户只需通过简单的命令行工具或配置文件即可完成分布式训练的配置。例如，使用以下命令初始化配置：<br>配置完成后，Accelerate会自动处理数据并行、模型并行等分布式训练细节，用户无需手动编写复杂的分布式训练代码。<br>混合精度训练支持:<br>Accelerate支持混合精度训练（MixedPrecisionTraining），通过使用半精度（FP16）和单精度（FP32）混合计算，可以减少显存占用并加速训练过程。<br>用户只需在配置文件中启用混合精度选项，即可轻松实现混合精度训练。<br>无需修改代码即可扩展训练规模:<br>Accelerate的最大特点是用户无需大幅修改现有代码即可将训练任务扩展到多GPU或多节点环境。通过简单的API调用，Accelerate可以自动处理分布式训练的细节。<br>例如，以下代码展示了如何使用Accelerate将普通训练代码转换为分布式训练代码：<br>与DeepSpeed兼容:<br>Accelerate与DeepSpeed深度集成，用户可以通过Accelerate的配置文件启用DeepSpeed的功能（如ZeRO优化、梯度检查点等），从而进一步优化大规模模型的训练。<br>功能较基础，复杂场景需结合其他工具：Accelerate的核心功能主要集中在简化分布式训练的配置和执行上，对于更复杂的场景（如大规模模型并行、自定义优化策略），用户可能需要结合其他工具（如DeepSpeed、PyTorchDistributed）来实现。此外，Accelerate的高级功能（如DeepSpeed集成）需要用户具备一定的分布式训练知识。<br>⭐️⭐️⭐️⭐️（快速上手）<br>Accelerate的API设计简洁，用户只需几行代码即可将现有训练任务扩展到多GPU或多节点环境。对于初学者和研究人员来说，Accelerate是一个非常友好的工具。<br>Accelerate适用于单机多卡和多节点训练场景。用户可以通过简单的配置将训练任务扩展到多个GPU或多个节点，从而加速大规模模型的训练。<br>Accelerate主要用于模型的训练阶段，特别是分布式训练场景。它通过简化分布式训练的配置和执行，帮助用户高效地完成大规模模型的训练。</p>
<p>安装Accelerate:<br>初始化配置:<br>修改训练代码:<br>启动分布式训练:<br>HuggingFace的Accelerate库是一个专注于简化分布式训练的工具库，旨在帮助用户轻松实现多GPU、多节点训练。它通过自动化配置和简洁的API设计，降低了分布式训练的复杂性。<br>尽管Accelerate的功能相对基础，但其与HuggingFace生态的深度集成和易用性使其成为快速实现分布式训练的理想选择。对于需要扩展训练规模的团队，Accelerate提供了高效的解决方案。<br>deepspeed.ai[6]。DeepSpeed是由微软开发的开源深度学习优化库，专注于大规模模型训练和推理优化。官网提供了详细的文档、教程、API参考以及社区支持，用户可以通过官网获取最新版本和参与社区贡献。<br>大规模模型训练与推理优化库。DeepSpeed的目标是通过显存优化、计算加速和分布式训练技术，支持千亿级参数模型的训练和推理。它特别适合需要处理超大规模模型的场景，例如GPT-3、Turing-NLG等。<br>ZeRO内存优化:</p>
<p>例如，ZeRO-3可以将模型参数分片存储在不同的GPU上，从而支持训练万亿级参数的模型。<br>梯度累积:<br>DeepSpeed支持梯度累积（GradientAccumulation），通过将多个小批次的梯度累积后再更新模型参数，可以在有限的显存下模拟更大的批次大小，从而提升训练效果。<br>支持万亿参数模型训练:<br>DeepSpeed通过ZeRO技术和分布式训练优化，支持训练万亿级参数的模型。它已经在多个超大规模模型（如GPT-3）的训练中得到验证。<br>显存优化显著，适合超大模型:DeepSpeed的显存优化技术（如ZeRO）使其能够训练远超单GPU显存容量的模型。例如，使用ZeRO-3技术，用户可以在多个GPU上分布式存储和计算模型参数，从而支持超大规模模型的训练。</p>
<p>配置复杂，学习曲线陡峭:DeepSpeed的功能强大，但配置相对复杂，用户需要熟悉分布式训练和显存优化的相关知识。对于初学者来说，可能需要花费一定时间学习DeepSpeed的配置和使用方法。<br>⭐️⭐️⭐️（需分布式知识）。DeepSpeed的使用需要一定的分布式训练和显存优化知识，适合有经验的开发者和研究人员。对于初学者来说，可能需要参考文档和教程逐步学习。<br>DeepSpeed特别适合千亿级参数模型的训练，例如GPT-3、Turing-NLG等。它通过显存优化和分布式训练技术，支持超大规模模型的训练。<br>DeepSpeed主要用于模型的训练和推理优化阶段。它通过显存优化、计算加速和分布式训练技术，显著提升大规模模型的训练效率和推理速度。</p>
<p>安装DeepSpeed:<br>配置DeepSpeed:<br>创建一个配置文件（如ds_config.json），定义DeepSpeed的参数：<br>修改训练代码:<br>启动分布式训练:<br>DeepSpeed是一个功能强大的深度学习优化库，专注于大规模模型的训练和推理优化。它通过显存优化、计算加速和分布式训练技术，支持千亿级参数模型的训练。<br>尽管DeepSpeed的配置和使用相对复杂，但其强大的功能和与PyTorch、HuggingFace的深度集成使其成为超大规模模型训练的理想选择。对于需要处理超大规模模型的团队，DeepSpeed提供了高效的解决方案。</p>
<p>超大规模语言模型训练框架。Megatron-LM的目标是通过高效的模型并行和流水线并行技术，支持千亿级参数的语言模型训练。它专为NVIDIAGPU集群设计，适用于需要处理超大规模模型的场景。<br>模型并行:<br>Megatron-LM支持模型并行（ModelParallelism），将模型参数分布到多个GPU上，从而突破单GPU显存限制。例如，可以将Transformer层的参数拆分到多个GPU上进行计算。<br>模型并行技术使得Megatron-LM能够训练远超单GPU显存容量的模型。<br>流水线并行:<br>Megatron-LM还支持流水线并行（PipelineParallelism），将模型的不同层分布到多个GPU上，并通过流水线机制提高计算效率。流水线并行可以减少GPU之间的通信开销，提升训练速度。<br>Transformer架构极致优化:<br>Megatron-LM对Transformer架构进行了深度优化，包括高效的注意力机制实现、混合精度训练和梯度检查点技术。这些优化使得Megatron-LM在训练大规模语言模型时具有显著的性能优势。<br>专为NVIDIAGPU集群设计:<br>Megatron-LM充分利用NVIDIAGPU的计算能力，支持最新的GPU架构（如A100、H100）。它深度依赖NVIDIA的CUDA和NCCL库，能够高效地利用GPU集群的资源。<br>支持混合精度和梯度检查点:<br>Megatron-LM支持混合精度训练（MixedPrecisionTraining），通过使用半精度（FP16）和单精度（FP32）混合计算，可以减少显存占用并加速训练过程。<br>此外，Megatron-LM还支持梯度检查点（GradientCheckpointing）技术，通过牺牲部分计算时间来减少显存占用，从而支持更大规模的模型训练。<br>仅支持NVIDIA硬件，封闭性强:<br>Megatron-LM仅支持NVIDIAGPU，无法在其他硬件（如AMDGPU、TPU）上运行。此外，它的优化技术主要针对NVIDIA的硬件和软件生态，封闭性较强。<br>⭐️⭐️（需定制开发）。Megatron-LM的使用需要一定的定制开发能力，用户需要根据具体的硬件环境和任务需求调整配置和代码。对于初学者来说，可能需要花费一定时间学习Megatron-LM的使用方法。<br>千亿参数级模型训练:Megatron-LM特别适合千亿级参数的语言模型训练，例如GPT-3、Turing-NLG等。它通过模型并行和流水线并行技术，支持超大规模模型的训练。<br>Megatron-LM主要用于模型的训练阶段，特别是超大规模语言模型的训练。它通过高效的并行技术和显存优化，显著提升大规模模型的训练效率。</p>
<p>安装Megatron-LM:<br>配置训练任务:<br>创建一个配置文件（如config.json），定义模型参数和训练任务：<br>启动训练:<br>NVIDIA的Megatron-LM是一个专注于超大规模语言模型训练的开源框架，通过高效的模型并行和流水线并行技术，支持千亿级参数模型的训练。它专为NVIDIAGPU集群设计，具有显著的性能优势。<br>尽管Megatron-LM的使用需要一定的定制开发能力，但其强大的功能和与NVIDIA生态的深度集成使其成为超大规模模型训练的理想选择。对于需要处理超大规模模型的团队，Megatron-LM提供了高效的解决方案。<br>github.com&#x2F;huggingface&#x2F;peft[8]<br>PEFT是一个专注于大模型高效微调的工具库，旨在通过减少可训练参数的数量，显著降低微调大型预训练模型所需的计算资源和时间。<br>LoRA（Low-RankAdaptation）:LoRA是一种通过低秩分解来减少模型参数的技术。它通过在预训练模型的权重矩阵中引入低秩矩阵，从而在微调过程中只更新这些低秩矩阵，而不是整个权重矩阵。这种方法可以显著减少需要训练的参数数量，同时保持模型的性能。<br>PrefixTuning:PrefixTuning是一种在输入序列前添加可训练的前缀向量的技术。这些前缀向量可以引导模型在微调过程中适应特定任务，而不需要修改整个模型的参数。这种方法特别适用于生成任务，如文本生成和对话系统。<br>资源需求低:PEFT的设计目标之一是降低微调大型模型所需的计算资源。通过减少可训练参数的数量，PEFT使得在单张GPU上进行微调成为可能，这对于资源有限的研究者和开发者来说是一个巨大的优势。</p>
<p>部分技术可能影响模型性能:尽管PEFT通过减少参数数量来降低资源需求，但在某些情况下，这可能会导致模型性能的轻微下降。特别是在需要高度精确的任务中，如医疗诊断或金融预测，这种性能下降可能会对结果产生显著影响。<br>⭐️⭐️⭐️⭐️（API简洁）PEFT提供了简洁易用的API，用户可以快速上手并应用到自己的项目中。文档和示例代码也非常丰富，帮助用户理解和使用各种微调技术。<br>大模型领域适配:PEFT特别适用于需要在大模型上进行微调的领域，如医疗、金融等。这些领域通常需要处理大量复杂的数据，并且对模型的性能要求极高。通过PEFT，研究者可以在不牺牲性能的情况下，高效地微调大型模型以适应特定任务。<br>PEFT主要用于模型的微调阶段，即在预训练模型的基础上，通过少量数据的训练来适应特定任务。这一阶段通常需要大量的计算资源，而PEFT通过减少可训练参数的数量，显著降低了这一需求。<br>HuggingFace生态扩展</p>
<p>通过以上代码，用户可以轻松地将LoRA技术应用到现有的Transformers模型中，从而在微调过程中显著减少可训练参数的数量。<br>框架定位核心功能特点缺点易用性使用场景应用阶段生态支持PyTorch训练框架动态图、分布式训练灵活调试，社区强大部署依赖其他工具⭐️⭐️⭐️⭐️⭐️研究&#x2F;原型开发训练&#x2F;验证庞大NVIDIATriton推理服务器多框架&#x2F;硬件支持、动态批处理高吞吐，生产级部署配置复杂⭐️⭐️⭐️云&#x2F;边缘推理服务部署&#x2F;推理NVIDIA生态ONNXRuntime跨平台推理ONNX模型加速、训练优化轻量级，跨平台硬件支持有限⭐️⭐️⭐️边缘设备&#x2F;跨平台部署推理&#x2F;轻量化训练微软主导TransformersNLP模型库预训练模型微调与推理任务覆盖广，API友好大模型资源消耗高⭐️⭐️⭐️⭐️⭐️NLP任务开发微调&#x2F;推理HuggingFace生态DeepSpeed训练优化ZeRO内存优化、万亿模型训练显存效率极致配置复杂⭐️⭐️⭐️大规模分布式训练训练&#x2F;推理优化微软&#x2F;PyTorchMegatron超大规模训练模型并行、流水线并行NVIDIAGPU集群优化封闭性强⭐️⭐️千亿级模型训练训练NVIDIA专用PEFT高效微调LoRA、PrefixTuning低资源适配大模型可能影响模型性能⭐️⭐️⭐️⭐️大模型领域适配微调HuggingFace扩展<br>pytorch.org:https :&#x2F;&#x2F;pytorch.org&#x2F;<br>github.com&#x2F;triton-inference-server:https :&#x2F;&#x2F;github.com&#x2F;triton-inference-server<br>onnxruntime.ai:https :&#x2F;&#x2F;onnxruntime.ai&#x2F;<br>huggingface.co&#x2F;transformers:https :&#x2F;&#x2F;huggingface.co&#x2F;transformers<br>huggingface.co&#x2F;docs&#x2F;accelerate:https :&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;accelerate<br>deepspeed.ai:https :&#x2F;&#x2F;<a target="_blank" rel="noopener" href="http://www.deepspeed.ai/">www.deepspeed.ai/</a><br>github.com&#x2F;NVIDIA&#x2F;Megatron-LM:https :&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;Megatron-LM<br>github.com&#x2F;huggingface&#x2F;peft:https :&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;peft1<br>长按👇关注-数据STUDIO-设为星标，干货速递</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/03/17/1000001496-2247588466-1/">https://zejuncao.github.io/2025/03/17/1000001496-2247588466-1/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%95%B0%E6%8D%AESTUDIO/">
                                    <span class="chip bg-color">数据STUDIO</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/03/17/1000000168-2247487420-1/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000000168_2247487420_1.jpg" class="responsive-img" alt="deepseek v3 生成答案的速度为什么可以这么快？">
                        
                        <span class="card-title">deepseek v3 生成答案的速度为什么可以这么快？</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/AIGC%E5%B0%8F%E7%99%BD%E5%85%A5%E9%97%A8%E8%AE%B0/">
                        <span class="chip bg-color">AIGC小白入门记</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/03/17/1000000616-2247493165-1/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000000616_2247493165_1.jpg" class="responsive-img" alt="推理大模型的后训练增强技术-Reasoning模型也进化到2.0了，这次居然学会用工具了">
                        
                        <span class="card-title">推理大模型的后训练增强技术-Reasoning模型也进化到2.0了，这次居然学会用工具了</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/ChallengeHub/">
                        <span class="chip bg-color">ChallengeHub</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/Garfusion/posts" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/Garfusion/posts" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
