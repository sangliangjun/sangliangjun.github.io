<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="构建像人一样学习思考的机器（4万字）, ZejunCao&#39;Blogs">
    <meta name="description" content="构建像人一样学习思考的机器（4万字）

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

来源：CreateAMindBuildingMachinesThatLearnandThinkLikePeople构建像人类一样学习">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>构建像人一样学习思考的机器（4万字） | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000003051_2650031860_2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">构建像人一样学习思考的机器（4万字）</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                                <span class="chip bg-color">人工智能学家</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-25
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/SYnFxz7fafEj_dW18RA7mg">构建像人一样学习思考的机器（4万字）</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>来源：CreateAMind<br>BuildingMachinesThatLearnandThinkLikePeople<br>构建像人类一样学习和思考的机器<br>https :&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1604.00289<br>摘要<br>人工智能（AI）的最新进展重新唤起了人们构建像人类一样学习和思考的系统的兴趣。许多进步来自于深度神经网络在诸如物体识别、视频游戏和棋类游戏等任务中的端到端训练，其性能在某些方面达到了甚至超越人类的水平。尽管这些系统受到生物学启发并取得了性能上的成就，但它们在关键方面与人类智能不同。我们回顾了认知科学的进展，认为真正像人类一样学习和思考的机器需要在学习的内容和方式上超越当前的工程趋势。具体而言，我们认为这些机器应该：（a）构建能够支持解释和理解的因果模型，而不仅仅是解决模式识别问题；（b）基于直觉的物理和心理理论来构建学习基础，以支持和丰富所学到的知识；（c）利用组合性和学会学习的能力，快速获取并泛化知识到新任务和情境中。我们提出了实现这些目标的具体挑战和有希望的途径，这些途径可以结合近期神经网络的进步与更结构化的认知模型的优势。<br>1引言<br>人工智能（AI）一直是一个起起落落的故事，但从任何传统成功的衡量标准来看，过去几年都取得了非凡的进步。其中大部分进步来自于“深度学习”的最新进展，其特征是学习具有多层表示的大型神经网络风格模型。这些模型在许多领域取得了显著的进展，包括物体识别、语音识别和控制（LeCun，Bengio&amp;Hinton，2015；Schmidhuber，2015）。在物体识别方面，Krizhevsky、Sutskever和Hinton（2012）训练了一个深度卷积神经网络（convnets；LeCun等人，1989），几乎将当时最具挑战性的基准测试的错误率减半。自那以后，卷积神经网络继续占据主导地位，最近在某些物体识别基准测试中接近人类水平的表现（He，Zhang，Ren&amp;Sun，2015；Russakovsky等人，2015；Szegedy等人，2014）。在自动语音识别方面，自20世纪80年代末以来，隐马尔可夫模型（HMMs）一直是领先方法（Juang&amp;Rabiner，1990），然而这一框架逐渐被深度学习组件取代（Hinton等人，2012）。如今，领先的语音识别方法是完全基于神经网络的系统（Graves，Mohamed&amp;Hinton，2013；Weng，Yu，Watanabe&amp;Juang，2014）。深度学习的思想也被应用于学习复杂的控制问题。V.Mnih等人（2015）将深度学习和强化学习的思想结合起来，开发出一种“深度强化学习”算法，该算法仅通过像素帧和游戏得分就能学会玩大量简单的视频游戏，并在许多这些游戏中达到人类或超人类水平的表现（另见Guo，Singh，Lee，Lewis&amp;Wang，2014；Schaul，Quan，Antonoglou&amp;Silver，2016；Stadie，Levine&amp;Abbeel，2016）。<br>这些成就帮助神经网络重新确立了其在机器学习中的领先地位，就像它们在20世纪80年代末和90年代初一样。神经网络的近期成功引起了学术界之外的关注。在工业界，像谷歌和Facebook这样的公司都有积极的研究部门探索这些技术，并且基于深度学习的物体和语音识别系统已经被部署在智能手机和网络的核心产品中。媒体也广泛报道了神经网络的许多近期成就，通常认为神经网络之所以取得近期的成功，是因为其类似大脑的计算方式，从而能够模拟人类学习和人类认知。<br>在本文中，我们将这种兴奋视为一个机会，来审视机器像人类一样学习或思考的含义。我们首先回顾了认知科学家、发展心理学家和人工智能研究人员之前提出的一些标准。其次，我们阐述了我们认为构建像人类一样学习或思考的机器所必需的要素，综合了认知科学研究中的理论思想和实验数据。第三，我们从这些要素的角度来考虑当代人工智能（特别是深度学习），发现深度学习模型尚未纳入其中许多要素，因此可能以与人类不同的方式解决一些问题。最后，我们讨论了我们认为构建像人类一样学习和思考的机器的最有可能的路径。这包括将深度学习与我们识别的核心认知要素相结合的前景，部分灵感来自于最近将神经网络与经典心理学和计算机科学中的低级构建块（注意力、工作记忆、堆栈、队列）融合的工作，这些构建块传统上被认为与神经网络不兼容。除了我们提议中的具体要素外，我们还从更广泛的层面上区分了两种不同的智能计算方法。统计模式识别方法将预测视为主要目标，通常是在特定的分类、回归或控制任务的背景下。在这种观点中，学习是关于发现具有共同高价值状态的特征——在分类设置中是一个共同的标签，或在强化学习设置中的一个共同值——在一个庞大且多样化的训练数据集中。另一种方法将世界的模型视为首要，其中学习是模型构建的过程。认知是关于使用这些模型来理解世界，解释我们所看到的，想象可能发生但未发生的事情，或者可能是真实但尚未实现的事情，然后规划行动以使其成为现实。模式识别与模型构建、预测与解释之间的区别，是我们对人类智能的看法的核心。正如科学家寻求解释自然而非仅仅预测它一样，我们认为人类思维本质上是一种模型构建活动。我们在下面通过许多例子详细阐述了这一关键观点。我们还讨论了模式识别如何支持模型构建，即使它不是智能的核心，也可以通过“无模型”的算法来实现，这些算法通过经验学习如何使基本推理更具计算效率。<br>在继续之前，我们先对本文的目标提供一些注意事项，并简要概述一下关键思想。<br>1.1本文不是什么<br>自从有了神经网络，几乎就有对神经网络的批评（Crick，1989；Fodor&amp;Pylyshyn，1988；Marcus，1998，2001；Minsky&amp;Papert，1969；Pinker&amp;Prince，1988）。尽管我们在本文中对神经网络持批判态度，但我们的目标是基于它们的成功进行拓展，而不是纠结于它们的不足。我们认为神经网络在开发更像人类的学习机器方面有其价值：它们被应用于许多类型的机器学习问题中，展示了基于梯度的学习和深度潜在变量层次结构的强大能力。神经网络也有着作为认知计算模型的丰富历史（McClelland，Rumelhart&amp;thePDPResearchGroup，1986；Rumelhart，McClelland&amp;thePDPResearchGroup，1986）——我们在下一节中将更详细地描述这一历史。在更根本的层面上，任何学习的计算模型最终都必须基于大脑的生物神经网络。<br>我们也相信，未来的神经网络将与当前的前沿技术大不相同。它们可能会被赋予直觉物理、心理理论、因果推理以及其他我们在接下来的章节中描述的能力。更多的结构和归纳偏差可能会被内置到网络中，或者从相关任务的先前经验中学习而来，从而导致更像人类的学习和发展模式。网络可能会学会有效地搜索和发现新的心理模型或直觉理论，而这些改进的模型反过来又将促进后续的学习，使系统能够学会学习——利用先前的知识从极少的训练数据中做出更丰富的推断。<br>区分声称模仿或从人类认知中汲取灵感的人工智能（AI）和不这样做的AI也很重要。本文关注前者。后者是一种完全合理且有用的方法来开发AI算法——避免从认知或神经角度获得启发，以及避免声称认知或神经上的合理性。事实上，许多研究人员就是这样做的，而本文与这种研究策略下进行的工作几乎没有相关性。另一方面，我们认为，逆向工程人类智能可以为AI和机器学习提供有益的指导（并且已经做到了），特别是对于人类擅长的领域和任务类型。尽管最近在计算上取得了成就，但人类在解决一系列复杂的计算问题方面仍然优于机器，包括概念学习、场景理解、语言习得、语言理解、语音识别等。其他人类认知能力在计算上仍然难以理解，包括创造力、常识和通用推理。只要自然智能仍然是智能的最佳范例，我们就相信，逆向工程人类解决复杂计算问题的方案将继续为AI提供指导并推动其发展。</p>
<p>1.2关键思想概述<br>本文的核心目标是提出一套构建更像人类的学习和思考机器的核心要素。我们将在第4节中详细阐述这些要素和主题，但在这里我们先简要概述关键思想。<br>第一组要素关注于发展的“启动软件”，即在发展早期就出现的认知能力。关注发展的原因有多个。如果一个要素在发展早期就出现，那么无论它是通过经验学习得来的还是天生就有的，它肯定在儿童或成人尝试学习本文讨论的任务类型之前就已经活跃且可用。此外，一个要素出现得越早，它就越有可能成为后续发展和学习的基础。<br>我们关注两种发展早期的启动软件（参见Wellman&amp;Gelman，1992，对两者的综述）。首先是直觉物理（第4.1.1节）：婴儿具有原始的物体概念，使他们能够跨时间追踪物体，并排除物理上不可能的轨迹。例如，婴儿知道物体会在时间中持续存在，它们是固体且连贯的。凭借这些一般性原则，人们能够更快地学习并做出更准确的预测。尽管任务可能是新的，但物理规律仍然不变。第二种在早期发展中出现的软件是直觉心理学（第4.1.2节）：婴儿理解其他人具有目标和信念等心理状态，这种理解强烈地约束了他们的学习和预测。一个孩子观看专家玩一款新视频游戏时，可以推断出游戏角色具有自主性，并试图寻求奖励而避免惩罚。这种推断立即约束了其他推断，使孩子能够推断出哪些物体是好的，哪些是坏的。这些类型的推断进一步加速了新任务的学习。<br>第二组要素关注于学习。尽管学习有多种视角，但我们认为模型构建是人类水平学习的标志，即通过构建世界的因果模型来解释观察到的数据（第4.2.2节）。从这个角度来看，早期出现的直觉物理和心理学能力也是世界的因果模型。学习的主要任务之一是扩展和丰富这些模型，并构建其他领域的类似因果结构理论。<br>与机器学习中的最新算法相比，人类学习的特点是丰富性和高效性。儿童天生具有发现稀疏观察事件背后原因的能力和愿望，并利用这些知识远远超出数据的匮乏。人们能够从非常有限的经验中学习这些结构丰富的模型，这似乎有些矛盾。我们认为组合性和学会学习是使这种快速模型学习成为可能的要素（分别见第4.2.1节和第4.2.3节）。<br>最后一组要素涉及我们大脑构建的丰富模型如何在实时中付诸行动（第4.3节）。人们能够以惊人的速度感知和行动。人们可以在一秒钟内理解一个新场景，或者在说出和听到一个新话语的时间内理解它。在机器视觉和语音系统中使用神经网络的一个重要动机是像大脑一样快速地做出反应。尽管神经网络通常旨在进行模式识别而非模型构建，但我们将讨论这些“无模型”的方法如何加速感知和认知中的缓慢基于模型的推理（第4.3.1节）。通过学习这些推理中的模式，可以在不经过代价高昂的中间步骤的情况下预测推理的输出。将“学会推理”的神经网络与丰富的模型构建学习机制相结合，为解释人类大脑如何如此快速地理解世界提供了一种有希望的方式。<br>我们还将讨论强化学习中基于模型和无模型方法的整合（第4.3.2节），这是一个最近取得快速进展的领域。一旦学习了任务的因果模型，人类就可以利用该模型规划最大化未来奖励的动作序列；当奖励被用作模型构建成功的度量时，这被称为基于模型的强化学习。然而，在复杂模型中进行规划既繁琐又缓慢，使得实时控制的速度-准确性权衡变得不利。相比之下，无模型的强化学习算法（如当前的深度强化学习实现）支持快速控制，但以灵活性和可能的准确性为代价。我们将回顾证据表明，人类以竞争性和合作性的方式结合了基于模型和无模型的学习算法，并且这些互动受到元认知过程的监督。人类水平的强化学习的复杂性尚未在AI系统中实现，但这是一个认知方法和工程方法之间特别有希望交叉的领域。<br>2人工智能中的认知与神经启发<br>关于人工智能（AI）是否以及如何与人类认知心理学相关的问题，比“人工智能”和“认知心理学”这两个术语本身还要古老。艾伦·图灵怀疑，建造并教育一台“儿童机器”比试图完全捕捉成人的认知能力要容易（图灵，1950）。图灵将儿童的心智比作一个笔记本，有“很少的机制和大量的空白页”，而儿童机器的心智则是通过响应奖励和惩罚来填充笔记本，类似于强化学习。这种对表征和学习的看法呼应了图灵时代占主导地位的行为主义心理学传统。它也呼应了现代连接主义模型的强经验主义，即我们可以通过感官输入的统计模式学习我们所知道的几乎所有内容。<br>认知科学摒弃了过于简化的行为主义观点，并在早期的人工智能研究中发挥了核心作用（博登，2006）。纽厄尔和西蒙（1961）开发了他们的“通用问题求解器”，既是人工智能算法，也是人类问题求解的模型，他们随后对其进行了实验测试（纽厄尔和西蒙，1972）。其他研究领域的AI先驱也明确引用了人类认知，甚至在认知心理学期刊上发表了论文（例如，鲍勃罗和温诺格拉德，1977；海耶斯-罗思和海耶斯-罗思，1979；温诺格拉德，1972）。例如，沙克（1972）在《认知心理学》杂志上写道：<br>我们希望能够构建一个程序，像孩子一样学习如何做我们在本文中所描述的事情，而不是被强行灌输必要的大量信息。<br>明斯基（1974）也表达了类似的观点：<br>我不在人类思维理论和制造智能机器的方案之间划清界限；今天将这两个领域分开没有任何意义，因为这两个领域都没有足够的理论来解释——或者产生——足够的思维能力。<br>这些研究大多假设人类知识表征是符号化的，并且推理、语言、规划和视觉可以用符号操作来理解。与此同时，一种截然不同的方法正在被探索，基于类似神经元的“子符号”计算（例如，福岛，1980；格罗斯伯格，1976；罗森布拉特，1958）。这种方法的表征和算法更多地受到神经科学的启发，而不是认知心理学，尽管最终它会发展成为一个有影响力的关于认知本质的思想流派——平行分布式处理（PDP）（麦克莱兰等人，1986；鲁梅尔哈特，麦克莱兰和PDP研究小组，1986）。顾名思义，PDP强调通过组合简单单元来并行计算，以集体实现复杂的计算。这些神经网络所学到的知识因此分布在单元的集合中，而不是像大多数符号数据结构那样局部化。最近对神经网络的兴趣重新兴起，更常被称为“深度学习”，它们在表征承诺上与早期的PDP模型相同，甚至经常使用相同的算法（见勒昆等人，2015；施密德胡伯，2015，近期综述），“深度”指的是可以通过组合多层表征来构建更强大的模型（仍然非常符合PDP风格），同时利用最近在硬件和计算能力方面的进步，以及大规模数据集，来学习更深层的模型。<br>还需要澄清的是，PDP视角与“模型构建”兼容，而不仅仅是“模式识别”。一些最初以PDP名义进行的工作（鲁梅尔哈特，麦克莱兰和PDP研究小组，1986）更接近模型构建而非模式识别，而最近的大型判别式深度学习系统则更纯粹地体现了模式识别（见博图，2014，相关讨论）。然而，正如所讨论的，还有关于模型内所学表征的性质的问题——它们的形式、组合性和可转移性——以及用于到达那里的发展启动软件。本文聚焦于这些问题。<br>神经网络模型和PDP方法提供了一种关于心智（以及更广泛的智能）的子符号视角，通常以最小的约束和归纳偏差来引导学习。这种方法的支持者认为，许多经典的结构化知识类型，如图、语法、规则、对象、结构描述、程序等，可以是有用的，但也是误导性的隐喻，用于描述思维。这些结构更多是派生现象而非真实存在，是更基本的子符号认知过程的涌现属性（麦克莱兰等人，2010）。与其他研究认知的范式相比，这种对表征本质的立场通常伴随着一种相对“白板”的初始知识和表征愿景，就像图灵的空白笔记本一样。<br>在这个范式中，尝试理解特定的认知能力或现象时，一种常见的科学策略是训练一个相对通用的神经网络来执行该任务，只有在必要时才添加额外的成分。这种方法表明，神经网络可以表现得好像它们学到了明确结构化的知识，例如生成单词过去时的规则（鲁梅尔哈特和麦克莱兰，1986），解决简单平衡梁物理问题的规则（麦克莱兰，1988），或者表示生物类型（植物和动物）及其属性分布的树（罗杰斯和麦克莱兰，2004）。训练大规模相对通用的网络也是当前物体识别的最佳方法（赫等人，2015；克里日夫斯基等人，2012；鲁萨科夫斯基等人，2015；塞格迪等人，2014），这些卷积网络的高级特征表征也被用于预测人类和猕猴IT皮层的神经反应模式（卡利赫-拉扎维和克里格斯科特，2014；克里格斯科特，2015；亚明等人，2014），以及人类对常见物体图像的典型性评分（莱克，扎伦巴，费尔格斯和古雷基斯，2015）和相似性评分（彼得森，阿博特和格里菲斯，2016）。此外，研究人员还训练通用网络执行结构化甚至战略性任务，例如最近使用深度Q学习网络（DQN）玩简单视频游戏的工作（V.Mnih等人，2015）。<br>如果神经网络在机器视觉、语言和控制方面有如此广泛的应用，并且如果它们可以被训练来模拟表征认知特征的规则性和结构化行为，那么我们是否还需要更多来开发真正像人类一样学习和思考的机器呢？相对通用的神经网络能带我们离这个目标有多远？<br>3构建更像人类的机器的挑战<br>尽管认知科学尚未对心智或智能达成统一的解释，但“心智是一组几乎没有初始约束的通用神经网络的集合”这一说法在当代认知科学中显得相当极端。一个不同的图景已经浮现，它强调了早期归纳偏差的重要性，包括诸如数字、空间、主体性和物体等核心概念，以及依赖先验知识从少量训练数据中提取知识的强大学习算法。这些知识通常以丰富的理论结构组织起来，具备人类思维所特有的渐进式推理和生成能力。<br>在这里，我们提出了两个机器学习和人工智能的挑战性问题：学习简单的视觉概念（莱克、萨拉赫丁诺夫和特嫩鲍姆，2015）以及学习玩Atari游戏《冰封王座》（V.Mnih等人，2015）。我们还用这些问题作为贯穿始终的例子，来说明以下各节中核心认知要素的重要性。<br>3.1字符挑战<br>第一个挑战涉及手写字符识别，这是比较不同类型机器学习算法的经典问题。霍夫斯塔特（Hofstadter）在1985年认为，以人们所做的一切方式（包括手写和印刷）识别字符的问题，几乎包含了人工智能的所有基本挑战，如果不是全部的话。无论这一说法是否正确，它都突显了即使是像字母这样“简单”的人类水平概念背后所隐藏的惊人复杂性。更实际地说，手写字符识别是一个儿童和成人都必须学会解决的真实问题，其实际应用范围从阅读信封地址到自动取款机中的支票识别等。与更一般的物体识别形式相比，手写字符识别也更为简单——感兴趣的物体是二维的，与背景分离，且通常不受遮挡。与人们学习和观察其他类型物体的方式相比，似乎在短期内有可能构建出能够看到人们所能看到的字符结构的大部分的算法。<br>标准的基准测试是用于数字识别的MNIST数据集（LeCun,Bottou,Bengio,&amp;Haffner,1998），它涉及将数字图像分类为“0”到“9”的类别。训练集为每个类别提供6,000张图像，总计60,000张训练图像。由于有大量的训练数据可供使用，许多算法都取得了令人满意的性能，包括K最近邻算法（测试误差为5%）、支持向量机（测试误差约为1%）以及卷积神经网络（测试误差低于1%；LeCun等人，1998）。使用深度卷积网络取得的最好结果非常接近人类水平的表现，误差率为0.2%（Ciresan,Meier,&amp;Schmidhuber,2012）。同样，最近将卷积网络应用于更具挑战性的ImageNet物体识别基准测试的结果表明，人类水平的表现也即将在该数据集上实现（Russakovsky等人，2015）。<br>尽管人类和神经网络在MNIST数字识别任务以及其他大规模图像分类任务上的表现可能相当，但这并不意味着它们的学习和思维方式相同。至少存在两个重要差异：人类可以从较少的示例中学习，并且他们学习到的表征更为丰富，这一比较既适用于学习手写字符，也适用于学习更一般的物体类别（图1）。人类可以从单个示例中学会识别新的手写字符（图1A-i），使他们能够区分其他人绘制的新实例和类似但并非同类的非实例（Lake,Salakhutdinov,&amp;Tenenbaum,2015；E.G.Miller,Matsakis,&amp;Viola,2000）。此外，人类学到的不仅仅是如何进行模式识别：他们学到的是一个概念——即一个类别模型，允许他们将所获得的知识灵活地应用于新的方式。除了识别新实例外，人类还可以生成新的实例（图1A-ii），将字符解析为其最重要的部分和关系（图1A-iii；Lake,Salakhutdinov,和Tenenbaum（2012）），以及根据一组相关的字符生成新的字符（图1A-iv）。这些额外的能力是随着对底层概念的掌握而自然获得的。<br>即使是对于这些简单的视觉概念，人类仍然是比字符识别的最佳算法更优秀、更复杂的学习者。人类从更少的示例中学习到更多的东西，将这些人类水平的学习能力引入机器就是字符挑战。我们最近报告了在这一挑战上使用概率程序归纳法所取得的进展（Lake,Salakhutdinov,&amp;Tenenbaum,2015），但人类完整的认知能力的某些方面仍然难以企及。尽管人类和模型都将字符表示为一系列笔画和关系，但人类拥有更丰富的笔画之间结构关系的储备。此外，人类能够高效地整合一个字符的多个示例，以推断哪些元素是可选的，例如“7”中的水平横杠，将同一字符的不同变体合并成一个连贯的单一表示。通过结合深度学习和概率程序归纳法来应对更丰富的字符挑战版本，可能会取得进一步的进展。<br>3.2Frostbite挑战<br>第二个挑战涉及Atari游戏《Frostbite》（图2），这是V.Mnih等人（2015）的DQN（深度Q网络）所解决的控制问题之一。DQN是强化学习领域的一个重大突破，它表明单一算法可以学会玩多种复杂的任务。该网络被训练用于玩49款经典的Atari游戏，这些游戏被提议作为强化学习的测试领域（Bellemare,Naddaf,Veness,&amp;Bowling,2013），令人印象深刻的是，它在其中29款游戏上达到了人类水平或更高的表现。然而，它在《Frostbite》以及其他需要长期规划策略的游戏中却遇到了特别的困难。<br>在《Frostbite》中，玩家控制一个代理（FrostbiteBailey），任务是在时间限制内建造一个冰屋。冰屋是通过代理在水中跳跃冰块来一块一块建造的（图2A-C）。挑战在于，冰块在不断移动（向左或向右），并且只有在冰块处于活跃状态（白色而非蓝色）时，它们才会对冰屋的建造做出贡献。代理还可以通过收集鱼来获得额外的分数，同时避免多种致命的危险（掉入水中、雪鹅、北极熊等）。在这款游戏中取得成功需要一个长期的规划，以确保代理能够完成一个子目标（例如到达一个冰块），然后安全地继续下一个子目标。最终，当冰屋的所有部件都就位后，代理必须进入冰屋，从而在时间耗尽之前完成关卡（图2C）。<br>DQN通过结合强大的模式识别器（深度卷积神经网络）和简单的无模型强化学习算法（Q学习；Watkins&amp;Dayan,1992）来学习玩《Frostbite》和其他Atari游戏。这些组件使网络能够将感官输入（像素帧）映射到一个小动作集合上的策略上，而映射和策略都被训练以优化长期累积奖励（游戏得分）。该网络体现了大多数连接主义模型所具有的强烈经验主义方法：除了卷积网络中固有的关于图像结构的假设外，网络中几乎没有其他内置内容，因此网络必须为每款新游戏基本上从头开始学习一个视觉和概念系统。在V.Mnih等人（2015）的研究中，网络架构和超参数是固定的，但网络是针对每款游戏重新训练的，这意味着视觉系统和策略高度专门化于其训练的游戏。最近的研究已经展示了这些针对特定游戏的网络如何共享视觉特征（Rusu等人，2016）或者被用来训练一个多任务网络（Parisotto,Ba,&amp;Salakhutdinov,2016），在学习玩新游戏时实现了适度的迁移学习效果。<br>尽管DQN在假设很少先验知识的情况下学会以人类水平的表现玩游戏这一事实令人感兴趣，但DQN可能正在以一种与人类截然不同的方式学习玩《Frostbite》和其他游戏。一种检验差异的方法是考虑学习所需的体验量。在V.Mnih等人（2015）的研究中，DQN与一位专业游戏玩家进行了比较，后者在49款Atari游戏上每款大约练习了两个小时（尽管他或她可能对其中一些游戏已经有一定的经验）。DQN在每款游戏上被训练了2亿帧，相当于大约924小时的游戏时间（大约38天），几乎是人类所获得体验的500倍。此外，DQN还采用了体验回放，在学习过程中，这些帧平均还会被回放大约8次。<br>凭借完整的924小时独特体验以及额外的回放，DQN在控制测试环节中仅达到了不到10%的人类水平表现（见图3中的DQN）。DQN的更近期变体已经展示了更优越的表现（Schaul等人，2016；Stadie等人，2016；vanHasselt,Guez,&amp;Silver,2016；Wang等人，2016），通过采用更智能的体验回放（Schaul等人，2016）达到了专业游戏玩家得分的83%，通过使用更智能的回放和更有效的参数共享（Wang等人，2016）达到了96%（见图3中的DQN+和DQN++）。但它们需要大量的体验才能达到这一水平：Schaul等人（2016）提供的学习曲线显示，在231小时后表现约为46%，在116小时后约为19%，而在仅仅2小时后则低于3.5%（这接近随机游戏，大约为1.5%）。人类和机器学习曲线之间的差异表明，它们可能正在学习不同种类的知识，使用不同的学习机制，或者两者兼而有之。<br>如果我们观察学习的最初阶段，这种对比将变得更加戏剧化。尽管原始的DQN和这些更近期的变体都需要数小时的体验才能可靠地优于随机游戏，但即使是非专业的玩家，也可以在玩游戏仅仅几分钟后掌握游戏的基本规则。我们推测，人们通过推断一个通用的框架来描述游戏的目标、物体类型及其相互作用，从而做到这一点，这利用了我们下面描述的那种直觉理论、模型构建能力以及基于模型的规划机制。尽管新手玩家可能会犯一些错误，例如推断鱼是有害的而不是有益的，但他们可以在几分钟内学会比随机游戏表现得更好。如果人类能够先观看专家玩游戏几分钟，他们可以学得更快。在非正式的实验中，两位作者在Javascript模拟器（）上玩《Frostbite》，在YouTube上观看专家游戏视频仅仅两分钟后，我们发现在最多15-20分钟的总练习后，我们能够达到或超过V.Mnih等人（2015）中报告的人类专家的得分。<br>还有其他的行为特征表明，人类与DQN在表征和学习方面存在根本差异。例如，在游戏《冰封王座》中，每到达一个活跃的冰块就会获得递增的奖励，这为DQN提供了完成更大任务（建造一个雪屋）的相关子目标。如果没有这些子目标，DQN将不得不采取随机行动，直到偶然地建造了一个雪屋并因完成整个关卡而获得奖励。相比之下，人们在学习如何玩一款新游戏时，可能不会以同样的方式依赖于递增的得分。在《冰封王座》中，有可能在没有递增反馈的情况下，弄清楚建造雪屋这一更高层次的目标；同样，在其他如《蒙特祖玛的复仇》这样的Atari2600游戏中，稀疏的反馈是一个困难的来源，而人类在这些游戏中明显优于当前的DQN方法。<br>DQN学习到的网络也相当不适应输入和目标的变化：改变物体的颜色或外观，或者改变网络的目标，如果不对网络进行重新训练，将会对其性能产生毁灭性的影响。尽管任何特定的模型必然是简化的，不应该以一般人类智能的标准来衡量，但DQN与人类灵活性之间的对比仍然非常显著。例如，想象一下，你被要求带着以下任何一个新目标去玩《冰封王座》：<br>-获得尽可能低的分数。<br>-获得最接近100、300、1000、3000或任何水平的分数，但不要超过。<br>-击败你旁边正在玩的朋友，但只是刚好，不要太悬殊，以免让他们难堪。<br>-尽可能长时间地存活下去。<br>-尽可能快地死亡。<br>-在温度计时器归零并死亡（即尽可能接近因冻伤而死亡，但又不真正死亡）的最后时刻通过每个关卡。<br>-不顾分数，到达最远的未探索关卡。<br>-看看你是否能找到隐藏的彩蛋。<br>-获得尽可能多的鱼。<br>-触碰屏幕上每一个单独的冰块，且仅触碰一次。<br>-尽可能高效地教你的朋友如何玩。<br>这一系列目标突显了人类智能的一个基本组成部分：人们可以学习模型，并将其用于任意新的任务和目标。虽然神经网络可以使用相同的刺激学习多个映射或任务——根据指定的目标调整其输出——但这些模型需要大量的训练或重新配置才能添加新任务（例如，Collins&amp;Frank,2013;Eliasmithetal.,2012;Rougier,Noelle,Braver,Cohen,&amp;O’Reilly,2005）。相比之下，人们几乎不需要重新训练或重新配置，就能相对轻松地将新任务和目标添加到他们的技能库中。<br>将《冰封王座》的例子与人类游戏进行对比，尤其具有说服力。即使是最好的深度网络，也需要经过数千次游戏过程才能逐渐学习，花费很长时间才能达到良好的性能，并且局限于特定的输入和目标模式。相比之下，人类在玩了几分钟的少量游戏后，就能理解游戏及其目标，其表现甚至超过了深度网络在经过近一千小时的经验后所达到的水平。更令人印象深刻的是，人们能够理解得足够多，从而发明或接受新目标，对输入的变化进行泛化，并向他人解释游戏。为什么人类会有所不同呢？DQN和其他现代机器学习方法可能缺少人类智能的哪些核心要素呢？<br>有人可能会反对说，《冰封王座》和字符挑战将人类学习的速度与神经网络学习的速度进行了不公平的比较。我们在第5节中详细讨论了这一反对意见，但我们觉得在这里也提前说明很重要。引用一位早期稿件的审稿人的话来说，“并不是DQN和人类以不同的方式解决相同的任务。他们可能更好地被视为解决不同的任务。人类学习者——与DQN和许多其他深度学习系统不同——带着丰富的先验经验去解决新问题。人类正在解决一系列多年来的连续问题，这些问题具有丰富的重叠结构。因此，人类通常对这些任务拥有重要的领域特定知识，甚至在他们‘开始’之前就已经有了。DQN则是从零开始。”我们同意这一点，这实际上是我们在这里要表达的观点的另一种说法。人类学习者从根本上承担着与当今神经网络不同的学习任务，如果我们想制造出像人类一样学习和思考的机器，那么我们的机器就需要面对人类学习者所面对的那种任务，而不是回避它们。<br>人类从未真正从零开始，甚至从未接近“从零开始”，这才是他们成功的关键。那么，构建人类学习和思维模型的挑战就变成了：我们如何利用丰富的先验知识来快速学习新任务和解决新问题呢？这种先验知识的形式是什么，它是如何从天生的能力和以往经验的某种组合中构建起来的呢？我们在下一节中提出的这些核心要素为应对这一挑战提供了一种途径。<br>4人类智能的核心要素<br>在引言部分，我们阐述了我们认为的智能的核心要素。在这里，我们将详细探讨这些要素，并将其与当前神经网络建模的现状进行对比。尽管这些并非人类学习和思维所需的唯一要素（参见第5节关于语言的讨论），但它们是大多数当前基于学习的人工智能系统中所缺失的关键构建块——至少没有全部具备——而对这些要素的额外关注可能会特别富有成效。我们相信，将这些要素整合起来，将产生比当前人工智能系统中所见的更强大、更接近人类的学习和思维能力。<br>在详细探讨每个要素之前，重要的是要澄清，我们所说的“核心要素”并不一定意味着这些要素是由基因预先设定的，或者必须“内置”到任何学习算法中。我们希望我们的讨论对这些关键要素的起源保持中立。当一个孩子或成年人开始学习一个新的字符或学习如何玩《冰封王座》时，他们已经具备了深度学习系统所不具备的丰富现实世界经验——这种经验很难在一般意义上被模拟。当然，这些核心要素会因这种经验而得到丰富，有些甚至可能是这种经验的产物。无论这些要素是通过学习获得的、内置的还是被丰富了的，关键主张是，这些要素在产生类似人类的学习和思维方面发挥了积极且重要的作用，而这是当代机器学习尚未捕捉到的。<br>4.1发展初期的启动软件<br>在早期发展中，人类对几个核心领域有着基础性的理解（Spelke,2003;Spelke&amp;Kinzler,2007）。这些领域包括数字（数值和集合运算）、空间（几何和导航）、物理（无生命物体和力学）以及心理学（主体和群体）。这些核心领域在认知的概念节点上划分了认知功能，每个领域都由一组实体以及关联这些实体的抽象原则来组织。其底层的认知表征可以被理解为“直觉理论”，其因果结构类似于科学理论（Carey,2004,2009;Gopniketal.,2004;Gopnik&amp;Meltzoff,1999;Gweon,Tenenbaum,&amp;Schulz,2010;L.Schulz,2012;Wellman&amp;Gelman,1992,1998）。进一步地，“儿童作为科学家”的观点将学习过程本身也视为类似科学家的行为，最近的实验表明，儿童会主动寻找新的数据以区分假设、隔离变量、检验因果假设、利用数据生成过程来得出结论，并有选择地向他人学习（Cook,Goodman,&amp;Schulz,2011;Gweonetal.,2010;L.E.Schulz,Gopnik,&amp;Glymour,2007;Stahl&amp;Feigenson,2015;Tsividis,Gershman,Tenenbaum,&amp;Schulz,2013）。我们将在第4.2节中探讨学习机制的本质。<br>每个核心领域都受到了大量的研究和分析，这些领域被认为在不同文化之间是共有的，并且部分也与非人类动物共享。所有这些领域都可能是当前机器学习的重要补充，尽管在下面的部分中，我们特别关注对物体和主体的早期理解。<br>4.1.1直觉物理学<br>幼儿对直觉物理学有着丰富的知识。无论这些知识是通过学习获得的还是与生俱来的，重要的物理概念在儿童或成人学习玩《冰封王座》的年龄之前就已经存在，这表明这些资源可能被用于解决这一问题以及许多日常与物理相关的任务。早在2个月大甚至更早的时候，婴儿就期望无生命物体遵循持续性、连续性、凝聚性和固体性等原则（Spelke,1990;Spelke,Gutheil,&amp;VandeWalle,1995）。幼儿认为物体应该沿着平滑的路径移动，不会凭空出现或消失，不会相互穿透，也不会在远处产生作用。这些期望指导了婴儿早期的物体分割，出现在基于外观的线索（如颜色、纹理和感知良好性）之前（Spelke,1990）。<br>这些期望还继续指导后续的学习。大约在6个月大时，婴儿已经对刚体、软体和流体形成了不同的期望（Rips&amp;Hespos,2015）。例如，流体被期望能够通过障碍物，而固体物体则不能（Hespos,Ferry,&amp;Rips,2009）。到他们的第一个生日时，婴儿已经经历了几次对基本物理概念（如惯性、支撑、容纳和碰撞）的理解转变（Baillargeon,2004;Baillargeon,Li,Ng,&amp;Yuan,2009;Hespos&amp;Baillargeon,2008）。<br>目前还没有一个被广泛接受的关于这些早期物理原则和概念的计算解释，以前的建议范围从决策树（Baillargeonetal.,2009），到线索，再到规则列表（Siegler&amp;Chen,1998）。一种有前景的近期方法将直觉物理推理视为类似于对物理引擎软件的推理，这种模拟器是现代动画和游戏的动力来源（Bates,Yildirim,Tenenbaum,&amp;Battaglia,2015;Battaglia,Hamrick,&amp;Tenenbaum,2013;Gerstenberg,Goodman,Lagnado,&amp;Tenenbaum,2015;Sanborn,Mansinghka,&amp;Griffiths,2013）。根据这一假设，人们使用物体及其物理相关属性（如质量、弹性、表面摩擦）以及作用于物体的力（如重力、摩擦力或碰撞冲击）的内部表征来重建感知场景。与物理真实情况相比，直觉物理状态表征是近似的、概率性的，并且在许多方面过于简化和不完整。然而，它仍然足够丰富，能够支持心理模拟，以预测物体在不久的将来将如何移动，无论是它们自身的运动还是对我们将要施加的力的响应。<br>这种“直觉物理引擎”方法使得人们能够灵活适应各种日常场景和判断，超越了感知线索。例如（见图4），从《叠叠乐》游戏中重建的木块塔的物理引擎可以用来预测塔是否会倒下（以及如何倒下），与成年人做出这些预测的方式非常接近（Battagliaetal.,2013），也可以用于研究婴儿的更简单的物理预测（Téglásetal.,2011）。基于模拟的模型还可以捕捉人们如何做出假设性或反事实的预测：如果移除某些积木，添加更多积木，或者支撑塔的桌子被摇晃，会发生什么？如果某些积木被粘在一起，或者附着在桌面表面呢？如果积木是由不同的材料制成的（如泡沫塑料、铅、冰）呢？如果一种颜色的积木比其他颜色的积木重得多呢？每一种物理判断可能都需要新的特征或新的训练，才能使基于模式识别的解释达到与基于模型的模拟器相同的水平。<br>将这种直觉物理学嵌入或引入深度学习系统的前景如何呢？心理学中的联结主义模型以前曾被应用于物理推理任务，例如平衡梁规则（McClelland,1988;Shultz,2003）或与运动中距离、速度和时间相关的规则（Buckingham&amp;Shultz,2000），但这些网络并没有尝试处理复杂的场景作为输入，或者像图4中那样广泛的场景和判断。<br>FacebookAI研究人员最近的一篇论文（Lerer,Gross,&amp;Fergus,2016）在这一方向上迈出了令人兴奋的一步。Lerer等人（2016）训练了一个基于深度卷积网络的系统（PhysNet），使其能够从类似于图4A的模拟图像中预测积木塔的稳定性，但这些图像的配置要简单得多，仅为垂直堆叠的两个、三个或四个立方体积木。令人印象深刻的是，PhysNet能够泛化到简单的现实世界中的积木塔图像，在这些图像上的表现与人类相当，同时在合成图像上的表现甚至超过了人类。人类和PhysNet对积木塔的置信度也存在相关性，尽管这种相关性不如Battaglia等人（2013）的近似概率模拟模型和实验那么强。一个局限性在于，PhysNet目前需要大量的训练——大约10万到20万场景——才能学会对单一任务（塔是否会倒下？）在有限的场景范围（两到四个立方体的塔）内进行判断。虽然它已经被证明能够泛化，但这种泛化也是有限的（例如，从两个和三个立方体的塔泛化到四个立方体的塔）。相比之下，人类在执行任何特定任务时需要的经验要少得多，并且能够在无需新的训练的情况下泛化到许多新的判断和复杂场景（尽管他们在与世界更广泛的互动中获得了大量的物理经验）。深度学习系统（如PhysNet）能否在不明确模拟三维空间中物体之间因果互动的情况下捕捉到这种灵活性？我们不确定，但我们希望这是一个它们会接受的挑战。<br>或者，与其试图在不模拟物理的情况下进行预测，神经网络是否可以在给定正确类型和数量的训练数据的情况下被训练成一个通用的物理模拟器，例如儿童所经历的原始输入？这是一个活跃且引人入胜的研究领域，但它也面临着重大挑战。对于训练用于物体分类的网络，更深层通常会对从边缘到纹理、再到形状部件再到完整物体的更高层次特征变得更加敏感（Yosinski,Clune,Bengio,&amp;Lipson,2014;Zeiler&amp;Fergus,2014）。对于在物理相关数据上训练的深度网络，目前还不清楚更高层次是否会编码物体、一般物理属性、力以及近似牛顿力学。一个在动态像素数据上训练的通用网络可能会学到这些概念的隐式表征，但它是否能够像人类更明确的物理概念那样广泛地泛化到训练上下文之外？例如，考虑一个学习预测几个球在一个盒子里反弹的轨迹的网络（Kodratoff&amp;Michalski,2014）。如果这个网络实际上学到了类似牛顿力学的东西，那么它应该能够泛化到有趣的不同场景——至少是不同数量、不同形状的物体，在不同形状、大小和方向（相对于重力）的盒子里反弹，更不用说上述讨论的所有塔任务了，这些任务也属于牛顿力学领域。神经网络研究人员尚未接受这一挑战，但我们希望他们会接受。正如我们在第5节中进一步讨论的那样，尚不清楚是否能够用人类婴儿所拥有的数据类型（以及数量）来学习此类模型。<br>将基于物体和物理的原始概念整合到深度神经网络中可能具有挑战性，但在许多任务的学习速度和性能方面可能会带来巨大的回报。以学习玩《冰封王座》为例。尽管很难确切地弄清楚网络是如何学会解决特定任务的，但DQN可能并没有将《冰封王座》的截图解析为根据直觉物理规则运动的稳定物体或精灵（图2）。然而，整合基于物理引擎的表征可以帮助DQN以更快、更通用的方式学会玩像《冰封王座》这样的游戏，无论物理知识是隐式地包含在神经网络中，还是更明确地包含在模拟器中。除了减少训练数据量并可能提高DQN达到的性能水平外，它还可以消除在物体（例如，鸟、冰块和鱼）的行为、奖励结构或外观发生轻微变化时重新训练《冰封王座》网络的需要。当引入一种新的物体类型（如《冰封王座》后期关卡中的熊，图2D）时，拥有直觉物理的网络也会更容易将这种物体类型纳入其知识体系（添加新物体的挑战也在Marcus,1998,2001中讨论过）。通过这种方式，将直觉物理与深度学习整合可能是迈向更接近人类的学习算法的重要一步，或者被阻塞的主体之前被关联为负面的，或者……<br>对基于线索的解释的一种替代方法是使用行动选择的生成模型，例如贝克尔（Baker）、萨克斯（Saxe）和特南鲍姆（Tenenbaum）（2009）提出的贝叶斯逆向规划（或“贝叶斯心理理论”）模型，或者哈拉-埃廷格（Jara-Ettinger）、格温（Gweon）、特南鲍姆和舒尔茨（Schulz）（2015）提出的“朴素效用演算”模型（还可参见杰恩和肯普（JernandKemp,2015）、陶伯和斯特耶弗斯（TauberandSteyvers,2011），以及基于预测编码的另一种相关替代方法，该方法来自基尔纳（Kilner）、弗里斯顿（Friston）和弗里斯（Frith,2007））。这些模型明确形式化了诸如“目标”“主体”“规划”“成本”“效率”和“信念”等心理主义概念，这些概念被用来描述婴儿期的核心心理推理。它们假设成人和儿童将主体视为近似理性的规划者，选择实现目标的最有效手段。规划计算可以形式化为马尔可夫决策过程（或部分可观测马尔可夫决策过程，POMDPs）的解决方案，输入是定义在主体状态空间上的效用函数和信念函数，以及主体的状态-行动转移函数，输出是主体为最有效地实现目标（或最大化效用）而应执行的一系列行动。通过模拟这些规划过程，人们可以预测主体接下来可能会做什么，或者通过观察一系列行动，使用逆向推理来推断场景中主体的效用和信念。这与使用模拟引擎进行直觉物理推理是直接类比的，可以用来预测场景中接下来会发生什么，或者根据物体的运动来推断它们的动态属性。它产生了类似灵活的推理能力：效用和信念可以根据主体可能为各种新目标和情境采取的行动进行调整。重要的是，与直觉物理不同，直觉心理学中的基于模拟的推理可以递归嵌套，以理解社会互动——我们可以思考主体对其他主体的思考。<br>与直觉物理的情况一样，通用深度网络在捕捉直觉心理推理方面的成功将部分取决于人类所使用的表征。尽管深度网络尚未应用于涉及心理理论和直觉心理学的情境，但它们可能能够学会视觉线索、启发式方法以及涉及主体的场景的总结性统计特征。如果这就是人类心理推理的全部基础，那么基于数据的深度学习方法很可能会在这个领域取得成功。<br>然而，在我们看来，任何关于直觉心理推理的完整形式化解释都需要包括主体性、目标、效率和互惠关系的表征。与物体和力一样，目前尚不清楚是否可以从仅具有预测能力的深度神经网络中产生这些概念（主体、目标等）的完整表征。与直觉物理领域类似，有可能通过在各种情境中大量的训练轨迹，深度学习技术可以在没有学到更一般的有目标或社会导向行为的情况下，近似于婴儿期的推理。但除非这些概念是真实的，否则这也不太可能类似于人类学习、理解和应用直觉心理学的方式。就像在物理相关任务中，如果不了解物体，改变场景的设置或推断的目标可能难以泛化，如果不理解直觉心理学，改变主体的设置或他们的目标和信念也难以进行推理。<br>在介绍《冰封王座》挑战时，我们讨论了人们如何通过观看一位经验丰富的玩家玩几分钟，然后自己玩几轮，就能极其迅速地学会玩这款游戏。直觉心理学为从他人那里高效学习提供了基础，尤其是在以高效传递知识为目标的教学情境中（Shafto,Goodman,&amp;Griffiths,2014）。在观看专家玩《冰封王座》的情况下，无论是否有明确的教学目标，直觉心理学都能让我们推断出经验丰富的玩家的信念、愿望和意图。例如，我们可以通过观察经验丰富的玩家似乎在避开鸟儿，从而了解到鸟儿是要避开的。我们不需要经历一个遇到鸟儿的例子——并看到《冰封王座》中的贝利因为鸟儿而死亡——就能推断出鸟儿可能是危险的。只要看到经验丰富的玩家的回避行为最好被解释为基于这种信念的行为，就足够了。<br>同样，考虑一下在视频游戏中越来越流行的副手角色（sidekickagent）是如何被期望帮助玩家实现目标的。这种角色可以在不同的情境下以不同的方式提供帮助，比如获取物品、清理道路、战斗、防御、治疗和提供信息——所有这些都基于“提供帮助”的一般概念（Macindoe,2013）。一个明确的主体表征可以预测这种角色在新情境下将如何提供帮助，而基于像素的自下而上的表征可能就会陷入困境。<br>有几种方法可以将直觉心理学融入当代深度学习系统。虽然它可以被内置，但直觉心理学也可能以其他方式产生。联结主义者认为，以硬连线皮层回路形式存在的先天约束不太可能（Elman,2005;Elmanetal.,1996），但一个简单的归纳偏差，例如倾向于注意到能够移动其他事物的事物，可以启动对更抽象的主体概念的推理（S.Ullman,Harari,&amp;Dorfman,2012）。同样，大量的有目标导向和社会导向的行为也可以归结为一个简单的效用演算（例如，Jara-Ettingeretal.,2015），这种演算可以与其他认知能力共享。尽管直觉心理学的起源仍然是一个有争议的问题，但很明显，这些能力是早期出现的，并且在人类学习和思维中发挥着重要作用，这在《冰封王座》挑战中得到了体现，也在更广泛地学习新视频游戏时得到了体现。<br>4.2学习作为快速模型构建<br>自诞生以来，神经网络模型就强调了学习的重要性。神经网络有许多学习算法，包括感知器算法（Rosenblatt,1958）、赫布学习（Hebb,1949）、BCM规则（Bienenstock,Cooper,&amp;Munro,1982）、反向传播（Rumelhart,Hinton,&amp;Williams,1986）、醒睡算法（Hinton,Dayan,Frey,&amp;Neal,1995）以及对比散度（Hinton,2002）。无论是监督学习还是无监督学习，这些算法都将学习实现为连接强度的逐步调整过程。对于监督学习，更新通常旨在提高算法的模式识别能力。对于无监督学习，更新则致力于逐渐使模型内部模式的统计特性与输入数据的统计特性相匹配。<br>近年来，机器学习在使用反向传播和大数据集解决复杂的模式识别问题方面取得了特别的成功。尽管这些算法在多个具有挑战性的基准测试中达到了人类水平的性能，但在其他方面，它们仍然远远没有达到人类水平的学习能力。深度神经网络通常需要比人类更多的数据来解决相同类型的问题，无论是学习识别一种新类型的物体，还是学习玩一种新游戏。在学习母语中单词的含义时，儿童能够从非常稀疏的数据中做出有意义的泛化（Carey&amp;Bartlett,1978;Landau,Smith,&amp;Jones,1988;E.M.Markman,1989;Smith,Jones,Landau,Gershkoff-Stowe,&amp;Samuelson,2002;F.Xu&amp;Tenenbaum,2007，尽管Horst和Samuelson在2008年提出了关于记忆限制的问题）。儿童可能只需要看到几个关于发刷、菠萝或光剑的概念的例子，就能大致“理解”，掌握定义每个概念的无限集合与所有可能物体的无限集合之间的边界。儿童在学习新概念方面比成年人更有经验——从开始说话到高中毕业，每天大约学习九到十个新单词（Bloom,2000;Carey,1978）——然而，快速“单次学习”的能力在成年后并没有消失。一个成年人可能只需要看到一张图片或一部关于一种新型两轮车辆的电影，就能推断出这个概念与其他概念之间的边界，使他或她能够区分这个概念的新实例与外观相似但属于不同类型物体（图1B-i）。<br>与人类学习的效率形成对比的是，神经网络由于其作为高度灵活的函数逼近器的通用性，臭名昭著地需要大量数据（偏差&#x2F;方差困境；Geman,Bienenstock,&amp;Doursat,1992）。例如，用于物体识别的ImageNet数据集这样的基准任务为每个类别提供了数百或数千个示例（Krizhevskyetal.,2012;Russakovskyetal.,2015）——1000个发刷、1000个菠萝等。在学习新的手写字符或学习玩《冰封王座》的背景下，MNIST基准数据集包括每个手写数字的6000个示例（LeCunetal.,1998），而V.Mnih等人（2015）的DQN在每个Atari视频游戏中大约进行了924小时的独特训练体验（图3）。在这两种情况下，算法显然没有像学习执行相同任务的人那样高效地使用信息。<br>还有一点需要指出的是，人类学习许多类别的概念的速度要慢得多。在学校学习的概念通常更具挑战性，也更难掌握，包括数学函数、对数、导数、积分、原子、电子、重力、DNA、进化等。也有一些领域，机器学习者的表现优于人类学习者，例如梳理金融或天气数据。但对于大多数认知上自然的概念——儿童学习作为单词含义的那些事物——人类仍然是比机器更好的学习者。本节我们关注的就是这种类型的学习，它更适合于逆向工程并阐述使人类学习成功所需的额外原则。它也为将这些要素融入下一代机器学习和人工智能算法提供了可能性，有望在人类容易和难以掌握的概念学习方面取得进展。<br>即使只有几个例子，人类也能学到非常丰富的概念模型。丰富性的一个指标是这些模型支持的多种功能（A.B.Markman&amp;Ross,2003;Solomon,Medin,&amp;Lynch,1999）。除了分类之外，概念还支持预测（Murphy&amp;Ross,1994;Rips,1975）、行动（Barsalou,1983）、交流（A.B.Markman&amp;Makin,1998）、想象（Jern&amp;Kemp,2013;Ward,1994）、解释（Lombrozo,2009;Williams&amp;Lombrozo,2010）以及组合（Murphy,1988;Osherson&amp;Smith,1981）。这些能力并不是相互独立的；相反，它们相互关联并相互作用（Solomonetal.,1999），随着对底层概念的掌握而自然获得。回到前面提到的新型两轮车辆的例子，一个人可以绘制出一系列新的实例（图1B-ii），将概念分解为其最重要的组成部分（图1B-iii），甚至可以通过组合熟悉的概念来创造一个新的复杂概念（图1B-iv）。同样，正如在《冰封王座》的背景下所讨论的，已经掌握了游戏基础的玩家可以灵活地将其知识应用于无限多的《冰封王座》变体（第3.2节）。获得的知识支持对新任务和新需求的重新配置，例如修改游戏的目标，以在获得尽可能少的分数的情况下生存，或者高效地将规则教给朋友。<br>这种丰富性和灵活性表明，将学习视为模型构建比将学习视为模式识别是一个更好的隐喻。此外，人类的单次学习能力表明，这些模型是基于丰富的领域知识构建的，而不是从一张白纸开始（Mikolov,Joulin,&amp;Baroni,2016;Mitchell,Keller,&amp;Kedar-cabelli,1986）。相比之下，深度学习的许多最新进展都在模式识别问题上，包括物体识别、语音识别和（无模型的）视频游戏学习，这些问题利用了大型数据集和很少的领域知识。</p>
<p>一个相关的案例研究来自我们自己在字符挑战方面的研究（第3.1节；Lake,2014;Lake,Salakhutdinov,&amp;Tenenbaum,2015）。人类和各种机器学习方法在从世界各字母表中学习新的手写字符方面进行了比较。除了评估几种深度学习模型外，我们还开发了一种使用贝叶斯程序学习（BPL）的算法，该算法将概念表示为简单的随机程序——也就是说，当执行时，这些结构化的程序可以生成一个概念的新实例（图5A）。这些程序使模型能够表达关于原始数据是如何形成的因果知识，并且概率语义允许模型处理噪声并执行创造性任务。通过随机原始概念的组合重用，这些原始概念可以以新的方式组合以创造新概念，从而实现跨概念的结构共享。<br>请注意，我们在这里对“模型”一词进行了重载，既指代整个贝叶斯程序学习（BPL）框架（这是一个生成模型），也指代它从图像中推断出的个体概率模型（或概念），用于表示新的手写字符。这里存在一个模型的层级结构：一个更高层次的程序生成不同类型的概念，而这些概念本身也是程序，可以被执行以生成某个概念的实例。在这里，将学习描述为“快速模型构建”指的是BPL构建生成模型（低层次程序），这些模型能够生成某个概念的实例（图5B）。<br>学习这种形式的模型使得BPL能够在具有挑战性的单次分类任务中达到人类水平的表现（图1A-i），并且超越了当前的深度学习模型，例如卷积网络（Koch,Zemel,&amp;Salakhutdinov,2015）。7BPL学到的表征还使其能够以其他更具创造性、更类似人类的方式进行泛化，这一点通过“视觉图灵测试”得到了评估（例如，图5B）。这些任务包括生成新的实例（图1A-ii和图5B）、将物体分解为其基本组成部分（图1A-iii），以及以特定字母表的风格生成新概念（图1A-iv）。以下部分将讨论对这一框架的成功至关重要的三个主要要素——组合性、因果性和学会学习——并且我们认为这些要素对于更广泛地理解人类学习作为快速模型构建非常重要。尽管这些要素自然地适合于BPL或概率程序归纳框架，但它们也可以被整合到深度学习模型和其他类型的机器学习算法中，我们将在下面更详细地讨论这些前景。<br>4.2.1组合性<br>组合性是一个经典的概念，即可以通过组合原始元素来构建新的表征。在计算机编程中，原始函数可以组合在一起以创建新函数，而这些新函数又可以进一步组合以创建更复杂的函数。这种函数层级结构为描述高级函数提供了一种高效的描述方式，就像用于描述复杂物体或场景的部件层级结构一样（Bienenstock,Geman,&amp;Potter,1997）。组合性也是生产力的核心：可以从有限的原始元素集合中构建无限数量的表征，就像人类的思维可以产生无限多的想法、说出或理解无限多的句子，或者从看似无限的可能性空间中学习新概念一样（Fodor,1975;Fodor&amp;Pylyshyn,1988;Marcus,2001;Piantadosi,2011）。<br>组合性在人工智能和认知科学中都产生了广泛的影响，尤其是在与物体识别、概念表征和语言相关的理论中。在这里，我们以物体概念的组合性表征为例进行说明。结构描述模型将视觉概念表示为部件和关系的组合，这为构建新概念的模型提供了强大的归纳偏差（Biederman,1987;Hummel&amp;Biederman,1992;Marr&amp;Nishihara,1978;vandenHengeletal.,2015;Winston,1975）。例如，图1B中的新型两轮车辆可以被表示为两个轮子通过一个平台连接，平台支撑着一个柱子，柱子上装有车把等。部件本身也可以由子部件组成，形成一个“部件整体关系”的层级结构（G.A.Miller&amp;Johnson-Laird,1976;Tversky&amp;Hemenway,1984）。在新型车辆的例子中，部件和关系可以从现有的相关概念（如汽车、滑板车、摩托车和独轮车）中共享和重用。由于部件和关系本身是先前学习的产物，它们促进新模型构建的过程也是学会学习的一个例子——这是我们在下面讨论的另一个要素。尽管组合性和学会学习自然地结合在一起，但也存在一些依赖于先前学习较少的组合性形式，例如霍夫曼和里奇（Hoffman&amp;Richards,1984）提出的自下而上的基于部件的表征。<br>学习新手写字符的模型也可以以类似的方式实现。手写字符本质上是组合性的，其中的部件是笔画，关系描述了这些笔画是如何相互连接的。Lake、Salakhutdinov和Tenenbaum（2015）使用额外的组合性层次来建模这些部件，其中部件是由更简单的子部件运动组合而成的复杂运动。通过以新颖的方式组合部件、子部件和关系，可以构建新的字符（图5）。组合性也是构建字符之外的其他类型符号概念的核心，例如，通过音素的新组合可以创造出新的口语单词（Lake,Lee,Glass,&amp;Tenenbaum,2014），或者通过更原始的身体运动的组合可以创造出新的手势或舞蹈动作。<br>对于《冰封王座》的高效表征也应该具有类似的组合性和生产力。游戏中的一个场景是由各种类型的物体组成的，包括鸟、鱼、冰块、雪屋等（图2）。明确表示这种组合性结构既更经济，也更有助于泛化，正如之前关于面向对象的强化学习的研究所指出的那样（Diuk,Cohen,&amp;Littman,2008）。场景中在不同位置出现了许多相同物体的重复，因此将每个物体表示为具有相同属性的相同物体的实例对于游戏的高效表征和快速学习至关重要。此外，新的关卡可能包含不同数量和组合的物体，此时使用直觉物理和直觉心理学作为“粘合剂”的物体的组合性表征将有助于实现这些关键的泛化（图2D）。<br>深度神经网络至少有一种有限的组合性概念。经过物体识别训练的网络在其更深层中编码类似部件的特征（Zeiler&amp;Fergus,2014），新的物体类型呈现时可以激活特征检测器的新组合。同样，经过《冰封王座》训练的DQN可能学会用相同的特征来表示同一物体的多个副本，这得益于卷积神经网络架构的不变性属性。最近的研究展示了如何使这种类型的组合性更加明确，其中神经网络可以用于在更结构化的生成模型（包括神经网络和三维场景模型）中进行高效推理，这些模型明确表示场景中物体的数量（Eslamietal.,2016）。除了部件、物体和场景固有的组合性之外，组合性在目标和子目标的层面上也很重要。关于分层DQN的最新研究表明，通过为DQN提供明确的物体表征，然后基于到达这些物体来定义子目标，DQN可以通过组合这些子目标来实现更大的目标，从而学会玩奖励稀疏的游戏（如《蒙特祖玛的复仇》）（Kulkarni,Narasimhan,Saeedi,&amp;Tenenbaum,2016）。<br>我们期待看到这些新思想继续发展，可能会在深度神经网络中提供更丰富的组合性概念，从而实现更快、更灵活的学习。为了捕捉人类思维的全部组合性，模型必须包括对物体、身份和关系的明确表征——同时在理解新配置时保持一种“一致性”的概念。一致性与我们接下来要讨论的下一个原则——因果性——有关。<br>4.2.2因果性<br>在概念学习和场景理解中，因果模型表示产生感知观察的假设性现实世界过程。在控制和强化学习中，因果模型表示环境的结构，例如建模状态到状态的转换，或者行动&#x2F;状态到状态的转换。<br>利用因果性的概念学习和视觉模型通常是生成性的（而不是判别性的；见表1中的术语表），但并非所有生成模型也是因果性的。尽管生成模型描述了生成数据的过程，或者至少为可能的数据点分配了一个概率分布，但这一生成过程可能并不类似于数据在现实世界中的产生方式。因果性指的是那些在抽象层面上类似于数据实际产生方式的生成模型的子类。虽然深度信念网络（Hinton,Osindero,&amp;Teh,2006）或变分自编码器（Gregor,Besse,Rezende,Danihelka,&amp;Wierstra,2016;Kingma,Rezende,Mohamed,&amp;Welling,2014）等生成神经网络可能生成引人注目的手写数字，但它们处于“因果性谱”的一端，因为生成过程的步骤与实际书写过程的步骤几乎没有相似之处。相比之下，使用贝叶斯程序学习（BPL）的字符生成模型确实类似于书写的步骤，尽管还可以构建更符合因果性的模型。<br>因果性在感知理论中具有影响力。“通过合成进行分析”的感知理论认为，通过建模生成感知数据的过程，可以更丰富地表示感知数据（Bever&amp;Poeppel,2010;Eden,1962;Halle&amp;Stevens,1962;Neisser,1966）。将数据与其因果来源联系起来，为感知和学习提供了强大的先验知识，也为以新的方式和新的任务进行泛化提供了更丰富的基础。这种方法的典型例子是语音和视觉感知。例如，Liberman,Cooper,Shankweiler和Studdert-Kennedy（1967）认为，语音感知的丰富性最好通过反转声道运动层面的生成计划来解释，以解释大量的声学变异性以及相邻音素之间线索的融合。正如我们所讨论的，因果性并不一定要像语音的运动理论所提出的那样，是实际生成机制的字面反转。对于学习手写字符的BPL来说，因果性是通过将概念视为运动程序，或者生成概念实例的抽象因果描述，而不是具体肌肉的具体配置来实现的（图5A）。因果性是该模型在仅看到一个新概念的单个实例后成功分类和生成新实例的重要因素（Lake,Salakhutdinov,&amp;Tenenbaum,2015）（图5B）。<br>因果知识也被证明会影响人们如何学习新概念；向学习者提供不同类型的因果知识会改变他们的学习和泛化方式。例如，一个类别的特征所基于的因果网络结构影响人们如何对新实例进行分类（Rehder,2003;Rehder&amp;Hastie,2001）。同样，与字符挑战相关的是，人们学习书写一个新手写字符的方式会影响后续的感知和分类（Freyd,1983,1987）。<br>为了说明因果性在学习中的作用，概念表征被比作直觉理论或解释，提供了让核心特征粘合在一起的“粘合剂”，而其他同样适用的特征则被忽略（Murphy&amp;Medin,1985）。以Murphy和Medin（1985）的例子为例，由于概念的底层因果作用，特征“可燃”与木材的联系比与货币的联系更紧密，尽管这一特征对两者同样适用；这些因果作用源于物体的功能。因果性也可以通过将一些特征与更深层次的共同原因联系起来，将它们粘合在一起，解释为什么某些特征（如“能飞”“有翅膀”和“有羽毛”）会在物体之间共同出现，而其他特征则不会。<br>除了概念学习之外，人们还通过构建因果模型来理解场景。人类水平的场景理解涉及构建一个解释感知观察的故事，利用并整合直觉物理、直觉心理学和组合性的要素。如果没有这些要素，以及将它们联系在一起的因果“粘合剂”，感知可能会导致揭示性的错误。考虑由深度神经网络生成的图像标题（图6；Karpathy&amp;Fei-Fei,2015）。在许多情况下，网络正确识别了场景中的关键物体，但未能理解起作用的物理力量、人的心理状态或物体之间的因果关系——换句话说，它没有构建数据的正确因果模型。<br>在深度神经网络及相关方法学习因果模型方面已经取得了一些进展。Lopez-Paz,Muandet,Schölkopf和Tolstikhin（2015）引入了一个判别性的、数据驱动的框架，用于从示例中区分因果方向。尽管它在各种因果预测任务中优于现有方法，但尚不清楚如何将这种方法应用于推断丰富的潜在因果变量层级结构，这是《冰封王座》挑战和（尤其是）字符挑战所需要的。Graves（2014）使用循环神经网络学习连笔书写的生成模型，该网络在书写数据上进行训练。尽管它以各种风格合成了令人印象深刻的书写示例，但它需要大量的训练语料库，并且尚未应用于其他任务。DRAW网络使用带有注意力窗口的循环神经网络进行手写数字的识别和生成，每次生成图像的一个有限的圆形区域（Gregor等人，2015）。DRAW的一个更近期的变体被应用于仅从一个训练示例生成新手写字符的示例（Rezende等人，2016）。尽管该模型展示了令人印象深刻的泛化能力，能够超越训练示例进行合理推测，但在其他情况下，它的泛化范围过于广泛，且并不特别像人类。目前还不清楚它是否能够通过Lake,Salakhutdinov和Tenenbaum（2015）中的任何“视觉图灵测试”（图5B），尽管我们希望DRAW风格的网络能够继续扩展和丰富，并能够通过这些测试。<br>将因果性纳入其中可能会极大地改进这些深度学习模型；这些模型是在没有关于字符实际产生方式的因果数据的情况下进行训练的，并且没有任何激励去学习真实的因果过程。注意力窗口只是用笔绘制的真实因果过程的一个粗糙近似，而在Rezende等人（2016）的研究中，注意力窗口根本不像笔，尽管可以纳入一个更准确的笔模型。我们预计，通过纳入额外的因果性、组合性和层级结构（并继续利用接下来描述的学会学习），这些顺序生成神经网络能够进行更敏锐的单次推断——以应对完整的字符挑战为目标——这可能会导致一种更计算高效且更符合神经科学基础的手写字符BPL模型的变体（图5）。<br>《冰封王座》的因果模型将不得不更加复杂，将物体表征整合在一起，并用直觉物理和直觉心理学来解释它们之间的相互作用，就像生成游戏动态并最终生成像素图像帧的游戏引擎一样。推理是反转这种因果生成模型的过程，将原始像素解释为物体及其相互作用，例如主体踏上冰块使其失效，或者螃蟹将主体推入水中（图2）。深度神经网络可以在两个方面发挥作用：作为自下而上的提议者，使结构化生成模型中的概率推理更加可行（第4.3.1节），或者如果具备正确的要素集合，也可以作为因果生成模型本身。<br>4.2.3学会学习<br>当人类或机器做出的推断远远超出数据本身时，强大的先验知识（或归纳偏差或约束）一定在弥补这种差距（Gemanetal.,1992;Griffiths,Chater,Kemp,Perfors,&amp;Tenenbaum,2010;Tenenbaum,Kemp,Griffiths,&amp;Goodman,2011）。人们获取这种先验知识的一种方式是通过“学会学习”，这一术语由哈罗（Harlow,1949）引入，与机器学习中的“迁移学习”“多任务学习”或“表征学习”密切相关。这些术语指的是通过先前或同时学习其他相关任务（或其他相关概念），加速学习新任务（或新概念）的方法。学习特定任务所需的强大先验、约束或归纳偏差通常在一定程度上与其他相关任务共享。人们已经开发出一系列机制，以适应学习者在学习具体任务时的归纳偏差，并将这些归纳偏差应用于新任务。</p>
<p>尽管迁移学习和多任务学习已经是人工智能（尤其是深度学习）中的重要主题，但它们尚未导致能够像人类一样快速且灵活地学习新任务的系统。在深度网络和其他机器学习方法中捕捉更接近人类的学会学习动态，可能会促进更强大的新任务和新问题的迁移。然而，为了获得人类从学会学习中得到的全部好处，人工智能系统可能首先需要采用我们上面主张的更具组合性（或更像语言，见第5节）和因果性的表征形式。<br>我们可以在两个挑战问题中看到这种潜力。在Lake、Salakhutdinov和Tenenbaum（2015）提出的字符挑战中，所有可行的模型都使用“预训练”，在背景字母表集中对许多字符概念进行预训练，以调整它们用于在测试字母表集中学习新字符概念的表征。但要表现良好，当前的神经网络方法需要比人类或我们的贝叶斯程序学习方法更多的预训练，而且它们仍然远远没有解决字符挑战。<br>我们不能确定人们在这个领域是如何获得他们所拥有的知识的，但我们确实理解在贝叶斯程序学习（BPL）中这是如何工作的，我们认为人类可能也是类似的。BPL可以轻松地转移到新概念，因为它学会了关于物体部件、子部件和关系的知识，捕捉了关于每个概念是什么样的以及概念总体上是什么样的学习。学会学习在分层生成过程的多个层次上发生至关重要。以前学到的原始动作和更大的生成片段可以被重用和重新组合，以定义新字符的新生成模型（图5A）。通过学习典型生成模型内的典型变异性水平，进一步发生知识迁移；这提供了关于在看到一个新字符的单个实例时，应该在多大程度以及以何种方式泛化的知识，而单个实例本身不可能携带任何关于变异性的信息。BPL也可以从比目前更深层次的学会学习中受益：它利用的一些重要结构被内置到先验中，而不是从背景预训练中学习的，而人类可能会学习这些知识，最终一个类似人类的机器学习系统也应该如此。<br>在视觉和认知中学习许多新的物体模型时，人类也会发生类似的学会学习：考虑图1B中的新型两轮车辆，学会学习可以通过转移以前学到的部件和关系（子概念，如轮子、马达、车把、连接、由……驱动等）来运作，这些部件和关系组合性地重新配置以创建新概念的模型。如果深度神经网络能够采用类似组合性、分层和因果性的表征，我们预计它们可能会从学会学习中受益更多。<br>在《冰封王座》挑战中，以及在视频游戏更广泛的情境中，表征的形式和学会学习的有效性之间存在着类似的相互依赖。人们似乎在多个层次上转移知识，从低层次的感知到高层次的策略，在所有层次上利用组合性。最基本的，他们立即将游戏环境解析为物体、物体类型以及它们之间的因果关系。人们还理解，像这样的视频游戏有目标，这些目标通常涉及根据物体类型接近或避开物体。无论是孩子还是经验丰富的游戏玩家，似乎都很清楚，与鸟和鱼的互动将以某种方式改变游戏状态，要么是好的，要么是坏的，因为视频游戏通常会对这些类型的互动产生成本或奖励（例如，死亡或得分）。这些类型的假设可能相当具体，并依赖于先验知识：当北极熊首次出现在高级关卡中并追踪代理的位置时（图2D），一个细心的学习者肯定会避开它。根据关卡的不同，冰块之间的距离可能相隔较远（图2A-C）或较近（图2D），这表明代理可能能够跨越某些间隔，但不能跨越其他间隔。通过这种方式，一般世界知识和以前的视频游戏可能有助于在新情境中指导探索和泛化，帮助人们从一次错误中尽可能多地学习，或者完全避免错误。<br>在玩Atari游戏的深度强化学习系统中，迁移学习已经取得了一些令人印象深刻的成果，但它们仍然没有接近人类学习新游戏的速度。例如，Parisotto等人（2016）提出了“演员模仿”算法，该算法首先通过观看专家网络玩游戏并尝试模仿专家网络的动作选择和&#x2F;或内部状态来学习13款Atari游戏（每款游戏大约有四百万帧的经验，或每款游戏18.5小时）。然后，该算法可以比随机初始化的DQN更快地学习新游戏：可能需要四到五百万帧的学习才能达到的分数，现在可能在一到两百万帧的练习后就能达到。但从经验来看，我们发现人类仍然可以在几分钟的练习后达到这些分数，所需的体验远远少于DQN。<br>总之，表征与先前经验之间的相互作用可能是构建学习速度与人类相当的机器的关键。在许多视频游戏上训练的深度学习系统本身可能不足以像人类一样快速地学习新游戏。然而，如果这样的系统旨在学习每个游戏的组合结构化的因果模型——建立在直觉物理和心理学的基础之上——它就可以更高效地转移知识，从而更快速地学习新游戏。<br>4.3快速思考<br>前一节关注了如何从稀疏数据中学习丰富的模型，并提出了实现这种类似人类学习能力的要素。当考虑到感知和思考的速度——理解一个场景、产生一个想法或选择一个动作所需的时间时，这些认知能力显得更加惊人。一般来说，更丰富、更有结构的模型需要更复杂的（也更慢的）推理算法——类似于复杂模型需要更多数据一样——这使得感知和思考的速度更加引人注目。<br>丰富的模型与高效的推理相结合，暗示了心理学和神经科学可以为人工智能提供有用的信息的另一种方式。它还表明了可以利用深度学习的成功之处的另一种方法，其中高效的推理和可扩展的学习是这种方法的重要优势。本节讨论了解决快速推理与结构化表征之间冲突的可能途径，包括生成模型中的赫尔姆霍兹机器风格的近似推理（Dayan,Hinton,Neal,&amp;Zemel,1995;Hintonetal.,1995）以及无模型和基于模型的强化学习系统之间的协作。<br>4.3.1结构化模型中的近似推理<br>分层贝叶斯模型在概率程序上运行（Goodmanetal.,2008;Lake,Salakhutdinov,&amp;Tenenbaum,2015;Tenenbaumetal.,2011），能够处理类似理论的结构和丰富的因果表征，然而，高效的推理面临着巨大的算法挑战。在整个程序空间上计算概率分布通常是不可行的，而且往往即使是找到一个高概率的程序也构成了一个不可行的搜索问题。相比之下，尽管在深度神经网络中表示直觉理论和结构化因果模型并不自然，但最近的进展展示了基于梯度的学习在高维参数空间中的惊人有效性。对学习和推理的完整解释必须说明大脑是如何在有限的计算资源下完成如此多的任务的（Gershman,Horvitz,&amp;Tenenbaum,2015;Vul,Goodman,Griffiths,&amp;Tenenbaum,2014）。</p>
<p>尽管蒙特卡洛方法强大且具有渐近保证，但将其应用于像程序归纳和理论学习这样的复杂问题是具有挑战性的。当假设空间庞大且只有少数假设与数据一致时，如何在不进行穷举搜索的情况下发现好的模型呢？在至少一些领域中，人们可能并没有特别巧妙的解决方案来解决这个问题，而是与理论学习的全部组合复杂性作斗争（T.D.Ullmanetal.,2012）。发现新理论可能是缓慢且艰难的，认知发展的长期性以及以跳跃式（而非渐进适应）的方式进行学习是人类智力的特征，包括在发展过程中的发现和洞察（L.Schulz,2012）、解决问题（Sternberg&amp;Davidson,1995）以及科学研究中的划时代发现（Langley,Bradshaw,Simon,&amp;Zytkow,1987）。发现新理论也可能发生得更快——一个学习《冰封王座》规则的人可能会经历一系列相对松散的“啊哈！”时刻：他们会发现跳到冰块上会使冰块变色，变色的冰块会一块一块地建造雪屋，鸟会让你失去分数，鱼会让你获得分数，你可以通过牺牲一个雪屋部件来改变冰块的方向，等等。这些“冰封王座理论”的小片段被组装起来，形成了对游戏的因果理解，这一过程相对迅速，更像是一个有指导的过程，而不是蒙特卡洛推理方案中的任意提议。同样，正如在字符挑战中所描述的，人们可以通过类似的有指导的过程快速推断出绘制新字符的运动程序。<br>在程序或理论学习发生得很快的领域，人们可能不仅使用归纳偏差来评估假设，还用来指导假设的选择。L.Schulz（2012）曾提出，问题的抽象结构属性包含了关于其解决方案的抽象形式的信息。即使不知道“太平洋最深处在哪里？”的答案，人们仍然知道答案必须是地图上的一个位置。“林肯出生在哪一年？”的答案是“20英寸”，即使不知道正确答案，也可以先验地排除这个答案。在最近的实验中，Tsividis,Tenenbaum和Schulz（2015）发现，儿童可以利用一个领域的高级抽象特征来指导假设选择，通过推理分布属性（如种子与花朵的比例）和动态属性（如因果之间的周期性或单调关系）（另见Magid,Sheskin,&amp;Schulz,2015）。<br>高效地从问题映射到可能答案的子集如何被学习呢？最近在人工智能领域的研究跨越了深度学习和图形模型，试图通过将概率推理计算“摊销”到一个高效的前馈映射中来应对这一挑战（Eslami,Tarlow,Kohli,&amp;Winn,2014;Heess,Tarlow,&amp;Winn,2013;A.Mnih&amp;Gregor,2014;Stuhlmüller,Taylor,&amp;Goodman,2013）。我们也可以将其视为“学习进行推理”，这与前一节讨论的作为模型构建的学习是独立的。这些前馈映射可以通过各种方式学习，例如使用配对的生成&#x2F;识别网络（Dayanetal.,1995;Hintonetal.,1995）和变分优化（Gregoretal.,2015;A.Mnih&amp;Gregor,2014;Rezende,Mohamed,&amp;Wierstra,2014）或最近邻密度估计（Kulkarni,Kohli,Tenenbaum,&amp;Mansinghka,2015;Stuhlmülleretal.,2013）。摊销的一个含义是，由于摊销计算的共享，不同问题的解决方案将变得相关；Gershman和Goodman（2014）报告了人类推理相关性的证据。这种趋势是深度学习模型与概率模型和概率编程潜在整合的一个途径：训练神经网络以帮助在生成模型或概率程序中进行概率推理（Eslamietal.,2016;Kulkarni,Whitney,Kohli,&amp;Tenenbaum,2015;Yildirim,Kulkarni,Freiwald,&amp;Te,2015）。另一种潜在整合的途径是通过可微编程（Dalrmple,2016）——通过确保程序化的假设是可微的，从而可以通过梯度下降进行学习——这一可能性在总结部分（第6.1节）进行了讨论。<br>4.3.2基于模型和无模型的强化学习<br>V.Mnih等人（2015）引入的DQN使用了一种简单的无模型强化学习形式，这种形式在深度神经网络中允许快速选择动作。确实有大量证据表明，大脑在简单的联想学习或辨别学习任务中使用类似的无模型学习算法（见Niv,2009的综述）。特别是，中脑多巴胺能神经元的阶段性放电在定性（Schultz,Dayan,&amp;Montague,1997）和定量（Bayer&amp;Glimcher,2005）上与驱动无模型价值估计更新的奖励预测误差是一致的。<br>然而，无模型学习并不是全部。有相当多的证据表明，大脑也有一个基于模型的学习系统，负责构建环境的“认知地图”，并利用它为更复杂的任务规划动作序列（Daw,Niv,&amp;Dayan,2005;Dolan&amp;Dayan,2013）。基于模型的规划是人类智能的一个重要组成部分，它使人们能够灵活地适应新任务和目标；这是前面各节讨论的所有丰富模型构建能力作为行动指南的价值所在。正如我们在对《冰封王座》的讨论中所论证的，可以设计出许多这种简单视频游戏的变体，这些变体除了奖励函数外完全相同——也就是说，由相同的状态-动作依赖转换的环境模型所控制。我们推测，一个熟练的《冰封王座》玩家可以轻松地根据情况调整行为，几乎不需要额外的学习，很难想象除了基于模型的规划方法之外，还有其他方法可以做到这一点，这种方法允许环境模型可以模块化地与任意新的奖励函数组合，然后立即用于规划。这种灵活性的一个边界条件是，随着常规应用，技能变得“习惯化”，可能反映了从基于模型的控制向无模型控制的转变。这种转变可能源于学习系统之间的理性仲裁，以平衡灵活性和速度之间的权衡（Daw等人，2005；Keramati,Dezfouli,&amp;Piray,2011）。<br>类似于概率计算可以通过摊销来提高效率（见前一节），计划也可以通过允许基于模型的系统为无模型系统模拟训练数据而摊销到缓存值中（Sutton,1990）。这个过程可能在离线状态下发生（例如，在做梦或安静的清醒状态下），暗示了强化学习中的一种巩固形式（Gershman,Markman,&amp;Otto,2014）。与学习系统之间合作的想法一致，最近的一项实验表明，基于模型的行为会在训练过程中变得自动化（Economides,Kurth-Nelson,Lübbert,Guitart-Masip,&amp;Dolan,2015）。因此，如果我们以人类强化学习系统为指导，或许可以实现灵活性和效率的结合。<br>内在动机也在人类学习和行为中发挥着重要作用（Berlyne,1966;Deci&amp;Ryan,1975;Harlow,1950）。尽管前面的讨论大多假设行为的标准观点是寻求最大化奖励和最小化惩罚，但所有外部提供的奖励都会根据代理的“内部价值”重新解释，这可能取决于当前的目标和心理状态。也可能存在一种内在的驱动力，以减少不确定性并构建环境模型（Edelman,2015;Schmidhuber,2015），这与学会学习和多任务学习密切相关。深度强化学习才刚刚开始涉及内在动机的学习（Kulkarni等人，2016；Mohamed&amp;Rezende,2015）。<br>5对常见问题的回应<br>在与同事讨论本文中的论点时，出现了三条常见的质疑或批评意见。我们认为直接回应这些观点是有帮助的，以便最大程度地推进共同的研究进展。<br>1.比较人类和神经网络在特定任务上的学习速度是没有意义的，因为人类拥有丰富的先验经验。<br>将神经网络和人类在完成某项任务所需的训练经验量上进行比较，例如学习玩新的Atari游戏或学习新的手写字符，似乎并不公平，因为人类拥有这些网络未曾受益的丰富先验经验。人们花费了许多小时玩其他游戏，也有过阅读或书写许多其他手写字符的经验，更不用说在各种更松散相关的任务中的经验了。如果神经网络能够用同样的经验进行“预训练”，那么按照这种说法，它们在接触新任务时可能会像人类一样进行泛化。<br>这一直是多任务学习或迁移学习的逻辑，这种策略有着悠久的历史，并且最近在深度网络中已经显示出一些有希望的结果（例如，Donahue等人，2013；Luong,Le,Sutskever,Vinyals,&amp;Kaiser,2015；Parisotto等人，2016）。此外，一些深度学习的支持者认为，人类的大脑通过进化有效地受益于更多的经验。如果深度学习研究者将自己视为试图捕捉人类集体进化经验的等价物，那么这将相当于一个真正巨大的“预训练”阶段。<br>我们同意，人类在学习大多数新任务（包括学习一个新概念或玩一个新的视频游戏）时，起点比神经网络丰富得多。这正是我们所说的“发展初期的启动软件”以及其他构建块的关键所在，我们认为这些是创造这个更丰富起点的关键。我们对这些要素起源的具体说法（包括遗传程序和经验驱动的发展机制在早期婴儿期构建这些组成部分的相对作用）并不那么执着。无论如何，我们都将它们视为促进从稀疏数据中快速学习的基本构建块。<br>跨多个任务的学会学习可能是获取这些要素的一种途径，但仅仅在许多相关任务上训练传统的神经网络可能不足以以类似人类的方式对新任务进行泛化。正如我们在第4.2.3节中所论证的，成功的学会学习——或者至少是人类水平的迁移学习——是通过拥有具有正确表征结构的模型来实现的，包括本文讨论的其他构建块。学会学习是一个强大的要素，但当它在捕捉环境底层因果结构的组合性表征上运作时，同时基于直觉物理和心理学，它可以更强大。<br>最后，我们认识到，一些研究者仍然希望，如果他们能够获得足够大的训练数据集、足够丰富的任务以及足够的计算能力——远远超出迄今为止尝试过的范围——那么深度学习方法可能就足以学习到与进化和学习为人类提供的等价的表征。我们可以理解这种希望，并认为它值得进一步探索，尽管我们不确定它是否现实。<br>从原则上我们理解进化如何能够构建一个具有我们在这里讨论的认知要素的大脑。随机爬山算法是缓慢的——它可能需要在数百万年中进行大规模并行探索，经历无数的死胡同——但如果愿意等待足够长的时间，它可以构建具有复杂功能的复杂结构。相比之下，尝试使用反向传播、深度Q学习或任何基于随机梯度下降的权重更新规则，在固定的网络架构中从头开始构建这些表征，可能无论有多少训练数据都是不可行的。从头开始构建这些表征可能需要探索网络架构的基本结构变化，而基于权重空间的梯度学习并没有准备好去做这件事。尽管深度学习研究者确实探索了许多这样的架构变化，并且最近设计了越来越巧妙和强大的架构，但正是研究者在推动和指导这个过程。在神经网络架构空间中的探索和创造性创新尚未被算法化。也许可以使用遗传编程方法（Koza,1992）或其他结构搜索算法（Yamins等人，2014）来实现。我们认为这是一个非常有趣且有前景的方向，但可能需要比机器学习研究者通常对他们的算法表现出的更多的耐心：结构搜索的动态可能更像是进化的缓慢随机爬山，而不是随机梯度下降的平稳、有条不紊的进步。另一种策略是将适当的类似婴儿的知识表征和核心要素作为我们基于学习的人工智能系统的起点，或者构建具有强大归纳偏差的学习系统，引导它们朝着这个方向发展。<br>无论人工智能开发者选择哪种方式，我们的主要观点都与这种反对意见无关。有一组人类学习和思维的核心认知要素。深度学习模型可以通过某种组合的额外结构和可能的额外学习机制来整合这些要素，但到目前为止大部分还没有做到。任何基于深度学习的人类类似人工智能的方法，或者任何其他方法，都可能从整合这些要素中获益。<br>2.生物学合理性表明智能理论应该从神经网络开始。<br>我们专注于如何通过认知科学来激励和指导构建类似人类的人工智能的努力，这与一些深度神经网络的支持者引用神经科学作为灵感来源形成了对比。我们的方法受到一种实用主义观点的指导，即理解“软件”比理解“硬件”更清晰地通向人类智能的形式化。在本文中，我们在前面的部分提出了这种软件的关键要素。<br>然而，对智能的认知方法不应忽视我们对大脑的了解。神经科学可以为认知模型和人工智能研究者提供宝贵的启发：我们在“快速思考”（第4.3节）中提出的神经网络和无模型强化学习的核心地位就是很好的例子。神经科学也可以在原则上对认知理论施加约束，无论是在细胞层面还是系统层面。如果深度学习体现了类似大脑的计算机制，而这些机制与某种认知理论不兼容，那么这就是反对该认知理论并支持深度学习的论据。不幸的是，我们对大脑的“了解”并不那么明确。许多关于神经计算的看似被广泛接受的观点实际上在生物学上是值得怀疑的，或者最多是不确定的——因此不应因这些观点而排除对在该方法内实现具有挑战性的认知要素。<br>例如，大多数神经网络使用某种基于梯度（例如反向传播）或赫布式学习的形式。然而，长期以来一直有观点认为反向传播在生物学上是不可信的；正如克里克（Crick,1989）著名地指出的那样，反向传播似乎需要信息沿着轴突向后传输，这与现实的神经元功能模型不符（尽管最近的一些模型以各种方式绕过了这个问题，例如Liao,Leibo,&amp;Poggio,2015;Lillicrap,Cownden,Tweed,&amp;Akerman,2014;Scellier&amp;Bengio,2016）。这并没有阻止反向传播在连接主义认知模型或构建人工智能的深度神经网络中得到很好的应用。神经网络研究者必须认为，在这种情况下，生物学合理性方面的担忧并没有阻碍对这种特定学习算法方法的研究是一件非常好的事情。我们强烈同意：尽管神经科学家尚未发现大脑中实现反向传播的任何机制，但他们也没有提出反对它的决定性证据。现有的数据在任何一方都几乎没有提供什么约束，而反向传播显然在构建当今最好的模式识别系统方面具有巨大价值。<br>赫布学习是另一个例子。以长时程增强（LTP）和尖峰时间依赖性可塑性（STDP）的形式，赫布学习机制通常被认为是生物学上有支持的（Bi&amp;Poo,2001）。然而，任何基于生物学的赫布学习形式的认知意义尚不清楚。加利斯泰尔（Gallistel）和马特泽尔（Matzel,2013）有说服力地论证了LTP的关键刺激间隔比大多数学习形式中行为相关的间隔小几个数量级。实际上，同时操纵刺激间隔和试验间隔的实验表明，不存在关键间隔。行为可以持续数周甚至数月，而LTP在几天内就会衰减到基线水平（Power,Thompson,Moyer,&amp;Disterhoft,1997）。在消退后，学到的行为可以迅速重新获得（Bouton,2004），但LTP并没有观察到这种促进作用（deJonge&amp;Racine,1985）。对于我们关注的重点来说，最相关的是，尝试使用纯粹的赫布机制来实现本文描述的要素将特别具有挑战性。<br>关于生物学合理或不合理性的说法通常基于对大脑的相当程式化的假设，这些假设在许多细节上是错误的。此外，这些说法通常涉及细胞和突触层面，很少与系统神经科学和皮层下脑组织联系起来（Edelman,2015）。理解哪些细节重要，哪些不重要需要一个计算理论（Marr,1982）。此外，在缺乏神经科学的强有力约束的情况下，我们可以将生物学论证反过来：也许如果一个假设性的生物学机制在认知上是不可信的，那么它就应该受到怀疑。从长远来看，我们乐观地认为神经科学最终会对智能理论施加更多的约束。目前，我们相信认知合理性提供了一个更可靠的基础。<br>3.语言是人类智能的核心。为什么在这里没有更突出？<br>在本文中，我们几乎没有提到人类使用自然语言进行沟通和思考的能力，这是人类独有的认知能力，而机器在这方面的能力远远落后于人类。当然，有人可能会认为，语言应该被列在人类智能的关键要素清单中：例如，Mikolov等人（2016）在其最近的论文中提出了挑战性问题和人工智能的发展路线图，其中语言被突出强调。此外，尽管自然语言处理是深度学习的一个活跃研究领域（例如，Bahdanau,Cho,&amp;Bengio,2015;Mikolov,Sutskever,&amp;Chen,2013;K.Xu等人，2015），但人们普遍认为神经网络远远没有实现人类的语言能力。问题是，我们如何开发出具有更丰富语言能力的机器？<br>我们自己认为，理解语言及其在智能中的作用与理解本文讨论的构建块是相辅相成的。语言确实建立在直觉物理、直觉心理学以及我们所关注的组合性、因果性模型的快速学习能力之上。这些能力在儿童掌握语言之前就已经具备，并且它们为语言的意义和语言习得提供了构建块（Carey,2009;Jackendoff,2003;Kemp,2007;O’Donnell,2015;Pinker,2007;F.Xu&amp;Tenenbaum,2007）。我们希望通过对这些早期要素的更好理解以及如何在计算上实现和整合它们，我们将更有能力从计算角度理解语言的意义和习得，并探索使人类语言成为可能的其他要素。<br>为了获得语言，我们还需要在这些核心要素的基础上添加什么？许多研究者推测了人类认知的关键特征，这些特征促成了语言和其他独特的人类思维方式：是递归，还是某种新的递归结构构建能力（Berwick&amp;Chomsky,2016;Hauser,Chomsky,&amp;Fitch,2002）？是通过名称重用符号的能力（Deacon,1998）？是理解他人的意图并建立共享意图的能力（Bloom,2000;Frank,Goodman,&amp;Tenenbaum,2009;Tomasello,2010）？是这些事物的某种新版本，还是仅仅是婴儿已经具备的这些能力的更多方面？这些问题对未来的研究具有重要意义，有可能扩展关键要素的清单；我们并不打算让我们的清单完整。<br>最后，我们应该记住，语言的习得扩展和丰富了我们在本文中关注的认知要素。婴儿的直觉物理和心理学可能仅限于对其直接空间和时间范围内的物体和主体进行推理，以及它们最简单的属性和状态。但有了语言，年长的儿童能够推理更广泛的物理和心理情境（Carey,2009）。语言还有助于更强大的学会学习和组合性（Mikolov等人，2016），使人们能够通过将新概念和思想与现有概念联系起来，更快速、更灵活地学习（Lupyan&amp;Bergen,2016;Lupyan&amp;Clark,2015）。最终，构建像人类一样学习和思考的机器的完整项目必须以语言为核心。<br>6展望未来<br>在过去的几十年中，人工智能和机器学习取得了令人瞩目的进步：计算机程序击败了国际象棋大师；人工智能系统战胜了《危险边缘》（Jeopardy）的冠军；应用程序能够识别你朋友的照片；机器在大规模物体识别方面与人类相媲美；智能手机能够识别（并且在一定程度上理解）语音。未来几年将带来更多令人兴奋的人工智能应用，涵盖自动驾驶汽车、医学、遗传学、药物设计和机器人技术等众多领域。作为一个领域，人工智能应该为这些成就感到自豪，它们帮助将研究从学术期刊推进到改善我们日常生活的系统中。<br>我们也应该意识到人工智能已经取得的成就和尚未取得的成就。尽管进步的速度令人印象深刻，但自然智能仍然是智能的最佳范例。机器在特定任务上的表现可能与人类表现相当甚至超过人类表现，算法可能从神经科学或心理学的某些方面获得启发，但这并不意味着该算法像人类一样学习或思考。这是一个值得追求的更高标准，它不仅可以导致更强大的算法，还有助于解开人类思维的奥秘。<br>当比较人类和当前人工智能及机器学习中最佳算法时，人类从更少的数据中学习，并以更丰富、更灵活的方式进行泛化。即使是相对简单的概念，如手写字符，人们只需要看到一个或几个新概念的示例，就能够识别新示例、生成新示例，并基于相关概念生成新概念（图1A）。到目前为止，即使是字符识别领域最先进的深度神经网络（Ciresan等人，2012）也未能实现这些能力，这些网络是在每个概念的许多示例上进行训练的，并且无法灵活地泛化到新任务上。我们认为，人类推理的相对强大和灵活性来自于其表征的因果性和组合性。<br>我们相信，如果深度学习和其他学习范式能够整合本文概述的心理学要素，它们将更接近人类的学习和思考方式。在结束之前，我们讨论了一些最近的趋势，我们认为这些趋势是深度学习中最富有前景的发展方向，我们希望这些趋势能够持续下去并带来更重要的进步。<br>6.1深度学习中的有前景的方向<br>近期，人们开始关注将心理学要素与深度神经网络相结合，尤其是选择性注意（Bahdanau等人，2015；V.Mnih,Heess,Graves,&amp;Kavukcuoglu,2014；K.Xu等人，2015）、增强的工作记忆（Graves等人，2014,2016；Grefenstette等人，2015；Sukhbaatar等人，2015；Weston等人，2015）以及经验回放（McClelland,McNaughton,&amp;O’Reilly,1995；V.Mnih等人，2015）。这些要素比本文讨论的关键认知要素更底层，但它们表明了一个有前景的趋势，即利用认知心理学的见解来改进深度学习，这一趋势可以通过整合更高级的认知要素而进一步推进。<br>与人类的感知器官类似，选择性注意迫使深度学习模型将原始感知数据作为一系列高分辨率的“中央凹一瞥”进行处理，而不是一次性处理所有数据。有些令人惊讶的是，注意力的引入在多个领域带来了显著的性能提升，包括机器翻译（Bahdanau等人，2015）、物体识别（V.Mnih等人，2014）和图像标题生成（K.Xu等人，2015）。注意力可能在几个方面帮助这些模型。它通过只关注输入的特定方面来协调复杂的（通常是顺序的）输出，使模型能够专注于较小的子任务，而不是一次性解决整个问题。例如，在标题生成过程中，注意力窗口已被证明会跟踪标题中提到的物体，当生成类似“一个男孩扔了一个飞盘”的标题时，网络可能会先关注男孩，然后是飞盘（K.Xu等人，2015）。注意力还允许在不要求每个模型参数影响每个输出或动作的情况下训练更大的模型。在生成神经网络模型中，注意力被用于专注于生成图像的特定区域，而不是一次性生成整个图像（Gregor等人，2015）。这可能是构建更因果性的生成模型的一步，例如可以应用于解决字符挑战（第3.1节）的贝叶斯程序学习模型的神经版本。<br>研究人员还在开发具有“工作记忆”的神经网络，这些工作记忆增强了由单元激活提供的短期记忆和由连接权重提供的长期记忆（Graves等人，2014,2016；Grefenstette等人，2015；Reed&amp;deFreitas,2016；Sukhbaatar等人，2015；Weston等人，2015）。这些发展也是更广泛趋势的一部分，即“可微编程”，即将经典数据结构如随机存取存储器、栈和队列纳入基于梯度的学习系统（Dalrmple,2016）。例如，神经图灵机（NTM；Graves等人，2014）及其后继者可微神经计算机（DNC；Graves等人，2016）是带有随机存取外部存储器的神经网络，该存储器具有读写操作并保持端到端的可微性。NTM已被训练执行序列到序列的预测任务，如序列复制和排序，而DNC已被应用于解决方块拼图和在图中找到节点之间路径的问题（在记忆图之后）。此外，神经程序解释器通过观察输入输出对（与NTM和DNC类似）以及执行轨迹，从较少的示例中学习表示和执行算法，如加法和排序（Reed&amp;deFreitas,2016）。每个模型似乎都从示例中学习真正的程序，尽管其表示更像汇编语言而不是高级编程语言。<br>尽管这一代新的神经网络尚未解决本文中介绍的挑战性问题，但可微编程提出了将程序归纳和深度学习最佳之处相结合的有趣可能性。本文讨论的结构化表征和模型构建要素——物体、力、主体、因果性和组合性——有助于解释人类学习和思考的重要方面，但它们也为执行高效推理带来了挑战（第4.3.1节）。深度学习系统尚未显示出它们能够处理这些表征，但它们已经展示了在具有高维参数空间的大型模型中梯度下降的惊人有效性。将这些方法结合起来，能够在丰富地模拟婴儿在世界中看到的因果结构的程序上执行高效推理，将是构建类似人类的人工智能的一个重大进步。<br>将模式识别和基于模型的搜索结合起来的另一个例子来自最近对围棋的人工智能研究。围棋对人工智能来说比国际象棋困难得多，直到最近，一个计算机程序——阿尔法狗（AlphaGo）——才首次击败了一流选手（Chouard,2016），它结合了深度卷积神经网络（convnets）和蒙特卡洛树搜索（Silver等人，2016）。这些组成部分各自都对人工和真正的围棋选手取得了进步（Gelly&amp;Silver,2008,2011;Silver等人，2016;Tian&amp;Zhu,2016），而将模式识别和基于模型的搜索结合起来的想法在围棋和其他游戏中已经有几十年的历史了。证明这些方法可以被整合起来击败人类围棋冠军是一个重要的人工智能成就（见图7）。然而，同样重要的是，它为构建真正类似人类的人工智能的长期项目开辟了新的问题和方向。<br>一个值得追求的目标是构建一个能够以人类冠军所接受的训练量和训练种类击败一流选手的人工智能系统——而不是用谷歌规模的计算资源压倒他们。阿尔法狗最初是在16万名人类专家玩的2840万种位置和移动上进行训练的；然后它通过强化学习改进，与自己对弈3000万场游戏。在Silver等人（2016）发表论文和与世界冠军李世石对战之前，阿尔法狗以这种方式进行了多次迭代训练；基本系统总是从3000万场游戏中学习，但它与自己越来越强大的版本对战，总共有效地从1亿场或更多场比赛中学习（Silver,2016）。相比之下，李在其一生中可能只玩了大约5万场比赛。看到像这样的数字，李能够与阿尔法狗竞争本身就令人印象深刻。要构建一个只从5万场比赛中学习的职业级围棋人工智能需要什么？也许将阿尔法狗的进展与我们在这里主张的一些互补的智能要素结合起来，将是一条通往这一目标的道路。<br>人工智能也可以通过尝试匹配普通人类围棋选手的学习速度和灵活性而获益良多。人们需要很长时间才能精通围棋，但正如冰封王座和字符挑战（第3.1节和第3.2节）一样，人类可以通过明确的指导、观察他人和经验的结合，迅速掌握游戏的基础。仅仅玩几场比赛就能让人类足以击败那些刚刚学到规则但从未玩过的人。阿尔法狗能否模拟这些真实人类学习曲线的最初阶段？人类围棋选手还可以将他们所学到的东西适应无数的游戏变体。维基百科页面“围棋变体”描述了如在更大或更小的棋盘上玩（从9×9到38×38，而不仅仅是通常的19×19棋盘）的版本，或者在不同形状和连接结构的棋盘上玩（矩形、三角形、六边形，甚至是英国城市米尔顿凯恩斯的地图）。棋盘可以是一个环面、莫比乌斯带、立方体或三维中的钻石晶格。可以在棋盘上切割出规则或不规则的孔。规则可以被改编为所谓的先捕获围棋（第一个捕获棋子的玩家获胜）、无围棋（避免捕获任何敌方棋子的玩家获胜）或时间就是金钱围棋（玩家从固定的时间开始，在游戏结束时，每个玩家时钟上剩余的秒数加到他们的分数上）。玩家可能会因为创造某些棋子图案或在某些地标附近捕获领土而获得奖励。可以有四个或更多的玩家，单独竞争或组队竞争。在这些变体中的每一个中，有效的玩法都需要从基础游戏发生变化，但熟练的玩家可以适应，并不是简单地从头开始重新学习游戏。阿尔法狗能做到吗？虽然在不同棋盘大小上处理可变大小输入的convnets技术可能有助于在不同棋盘大小上玩（Sermanet等人，2014），但阿尔法狗学到的价值函数和策略似乎不太可能像人们那样灵活和自动地泛化。上述许多变体都需要由编写阿尔法狗的聪明人类进行大量的重新编程和重新训练，而不是由系统本身进行。尽管阿尔法狗在击败世界上最好的标准游戏选手方面令人印象深刻——它确实非常令人印象深刻——但它甚至无法想象这些变体，更不用说自主适应它们了，这表明它不像人类那样理解游戏。人类选手能够理解这些变体并适应它们，因为他们明确地将围棋表示为一个游戏，目标是击败一个正在努力实现与他们相同目标的对手，由关于棋子如何放置在棋盘上以及棋盘位置如何评分的规则所约束。人类将他们的策略表示为对这些约束的回应，因此如果游戏发生变化，他们可以开始相应地调整他们的策略。<br>总之，围棋为人工智能提供了超越匹配世界级人类表现<br>6.2对实际人工智能问题的未来应用<br>在本文中，我们提出了一些构建具有更类似人类学习和思考能力的计算模型的要素。这些原则是在字符挑战和冰封王座挑战的背景下解释的，特别强调减少所需的训练数据量并促进向新颖但相关任务的迁移。我们也看到了这些要素如何推动具有实际应用的核心人工智能问题的进步。在这里，我们提供一些关于这些应用的推测性想法。<br>1.场景理解。深度学习正在超越物体识别，迈向场景理解，这从最近大量关于为图像生成自然语言标题的工作中可以看出（Karpathy&amp;Fei-Fei,2015;Vinyals等人，2014;K.Xu等人，2015）。然而，当前的算法在识别物体方面仍然比理解场景更擅长，通常能够正确识别关键物体，但它们之间的因果关系却搞错了（图6）。我们认为组合性、因果性、直觉物理和直觉心理学在实现真正的场景理解中将发挥越来越重要的作用。例如，想象一个杂乱的车库工作室，墙上挂着螺丝刀和锤子，工作台上危险地堆叠着木块和工具，架子和箱子构成了场景的框架。为了让自主代理在这个环境中有效地导航和执行任务，它需要直觉物理来正确推理稳定性和支撑。一个整体的场景模型需要将各个物体模型组合在一起，通过关系将它们粘合在一起。最后，因果性有助于将现有工具的识别（或新工具的学习）与对它们用途的理解结合起来，帮助以正确的方式连接不同的物体模型（例如，将钉子钉入墙中，或者使用锯马支撑被锯子切割的梁）。如果场景中包含人的行动或互动，那么在不考虑他们的想法，尤其是他们对其他物体和他们认为存在的主体的目标和意图的情况下，几乎不可能理解他们的行为。<br>2.自主代理和智能设备。机器人和个人助理（如手机）不能预先训练所有可能遇到的概念。像孩子学习新单词的含义一样，一个智能且适应性强的系统应该能够从少量示例中学习新概念，这些示例自然地出现在环境中。常见的概念类型包括新的口语单词（如“潘基文”或“科菲·安南”）、新的手势（秘密握手或“碰拳”）和新的活动，类似人类的系统能够从少量示例中学习识别和生成新实例。与手写字符类似，系统可能能够通过从预先存在的原始动作构建新概念，快速学习新概念，这些原始动作受到对底层因果过程和学会学习的知识的指导。<br>3.自动驾驶。完美的自动驾驶需要直觉心理学。除了检测和避开行人之外，自动驾驶汽车可以通过推断心理状态，包括他们的信念（例如，他们认为过马路安全吗？他们在注意吗？）和愿望（例如，他们想去哪里？他们想穿过马路吗？他们在寻找丢失在街上的球吗？），更准确地预测行人的行为。同样，道路上的其他司机也有类似复杂的心理状态，这些心理状态支配着他们的行为（例如，他们想换车道吗？超车吗？他们在躲避隐藏的危险吗？他们分心了吗？）。这种类型的心理推理，以及其他类型的基于模型的因果和物理推理，在训练数据很少的具有挑战性和新颖的驾驶情况下（例如，导航不寻常的建筑区域、自然灾害等）可能特别有价值。<br>4.创意设计。创造力通常被认为是人类智能的巅峰：厨师设计新菜肴，音乐家创作新歌曲，建筑师设计新建筑，企业家创办新企业。尽管我们离开发能够应对这些任务的人工智能系统还很远，但我们认为组合性和因果性是实现这一目标的核心。许多常见的创造性行为是组合性的，意味着它们是熟悉的概念或想法的意外组合（Boden,1998;Ward,1994）。如图1-iv所示，可以通过组合现有车辆的部件来创造新型车辆，同样，也可以从风格相似的字符的部件中构建新字符，或者以新颖的风格重新构思熟悉的字符（Rehling,2001）。在每种情况下，部件的自由组合本身是不够的：虽然组合性和学会学习可以为新想法提供部件，但因果性提供了使它们具有连贯性和目的性的粘合剂。<br>6.3朝着更像人类的学习和思考机器迈进<br>自20世纪50年代人工智能诞生以来，人们一直渴望制造出像人类一样学习和思考的机器。我们希望人工智能、机器学习和认知科学领域的研究者接受我们提出的挑战性问题，将其作为衡量进步的试验场。我们建议，深度学习和其他计算范式的目标不应仅仅是构建能够识别手写字符或玩冰封王座或围棋的系统，作为渐进过程的最终结果，而应致力于使用与人类所需一样少的训练数据来解决这些任务，并且在模型所训练的任务之外，用一系列类似人类的泛化能力来评估模型。我们希望本文概述的要素将有助于实现这一目标：看到物体和主体而非特征，构建因果模型而不仅仅是识别模式，无需重新训练即可重新组合表征，以及学会学习而非从零开始。<br>原文链接：https :&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1604.00289<br>阅读最新前沿科技趋势报告，请访问欧米伽研究所的“未来知识库”<br>https :&#x2F;&#x2F;wx.zsxq.com&#x2F;group&#x2F;454854145828<br>未来知识库是“欧米伽未来研究所”建立的在线知识库平台，收藏的资料范围包括人工智能、脑科学、互联网、超级智能，数智大脑、能源、军事、经济、人类风险等等领域的前沿进展与未来趋势。目前拥有超过8000篇重要资料。每周更新不少于100篇世界范围最新研究资料。欢迎扫描二维码或访问https :&#x2F;&#x2F;wx.zsxq.com&#x2F;group&#x2F;454854145828进入。<br>截止到2月28日”未来知识库”精选的100部前沿科技趋势报告<br>《核聚变，确保21世纪美国的主导地位的关键技术》<br>《世界知识产权组织：2025WIPO技术趋势报告：交通运输的未来（145页）》<br>《世界知识产权组织（WIPO）：2024年世界知识产权指标报告（194页）》<br>《联合国环境规划署：2024年保护地球报告（81页）》<br>《联合国工发组织：2024清洁技术创新能力建设框架研究报告（51页）》<br>《凯捷：ApplyingTechnoVision2025：未来科技趋势及应用愿景（17页）》<br>《谷歌：2025年AIAgent白皮书：AI智能体时代来临（42页）》<br>《富而德律师事务所：2024年国际仲裁趋势年度回顾报告（41页）》<br>《邓白氏：2024年全球企业破产报告（27页）》<br>《LLM时代小模型的应用潜力与挑战》（50页）<br>《斯坦福2025斯坦福新兴技术评论十项关键技术及其政策影响分析报告》（英文版191页）<br>《英伟达：2025NVIDIA自动驾驶安全报告（26页）》<br>《微软MICROSOFT(MSFT)2024年影响力摘要报告（23页）》<br>《高德地图：2024年中国主要城市交通分析报告（29页）》<br>《德勤&amp;CAS：2025锂离子电池回收行业报告-面向绿色未来的市场及创新趋势（36页）》<br>《ABIResearch：2025生成式人工智能在语义和实时通信中的应用研究报告（20页）》<br>《2025年3D打印技术发展趋势、产业链及相关标的分析报告（45页）》<br>《生成式基础模型的可信度——指南、评估与展望》（231页）<br>《量子信息科学与技术对国家安全的影响》（118页）<br>《中国科学技术信息研究所：2024科技期刊世界影响力指数（WJCI）报告（68页）》<br>《思略特（Strategy&amp;）：2025汽车行业的人工智能（AI）机遇研究报告（12页）》<br>《赛默飞：2024年中国生物科技行业调研报告：资本寒冬中生物科技企业的生产之道（18页）》<br>《清华大学：2025年DeepSeek与AI幻觉报告（38页）》<br>《美国企业研究所（AEI）：2025创新未来电力系统研究报告：从愿景迈向行动（71页）》<br>《超材料的智能设计研究进展》<br>《Ember：2030年全球可再生能源装机容量目标研究报告（29页）》<br>《量子信息科学与技术对国家安全的影响》<br>《英国人工智能安全研究所：2025年国际人工智能安全报告-执行摘要（22页）》<br>《世界海事大学：2024海事数字化与脱碳研究报告：可持续未来（250页）》<br>《艾睿铂（AlixPartners）：2024回溯过往锚定未来：大型科技公司如何推进人工智能愿景研究报告（18页）》<br>《Wavestone：2025数据与AI雷达：掌握数据与人工智能转型的10大挑战研究报告（30页）》<br>《CSIS：2024中美学术的再联结研究报告：在激烈竞争的时代增进相互理解（120页）》<br>《MSC：2025全球国防创新就绪度差距系列报告：突破制约国防创新的六大隐性障碍（第四版）（32页）》<br>《2025年AI编程发展前景及国内外AI编程应用发展现状分析报告（22页）》<br>《中国核电-公司深度报告：世界核电看中国-250218（22页）》<br>《医药生物行业：医疗器械行业全景图发展趋势及投资机会展望-250216（28页）》<br>《皮尤研究中心：2024美国社交媒体使用情况研究报告（英文版）（30页）》<br>《科睿唯安：2025基因编辑领域的领先创新者洞察报告-改变药物发现和开发范式的八大创新者（47页）》<br>《经合组织（OECD）：2025年全球脆弱性报告（218页）》<br>《计算机行业年度策略：AI应用元年看好Agent、豆包链及推理算力三大主线-250218（38页）》<br>《国金证券研究所：从理想走向现实，全球人型机器人研究报告》<br>《深度解读DeepSeek原理与效应（附PPT下载）》<br>《兰德公司（RAND）：2025借鉴危机经验构建城市水安全韧性研究报告：五城案例分析（62页）》<br>《凯捷（Capgemini）：2025行业创新洞察：电气化飞机推进系统研究报告（27页）》<br>《国际能源署（IEA）：2025全球电力市场报告：至2027年的分析与预测（200页）》<br>《Zenith：2025年国际消费电子展（CES）趋势报告：AI对消费科技、消费行为及传媒营销的变革性影响（17页）》<br>《RBC财富管理：全球透视2025年展望报告（33页）》<br>《美国国防部和国家安全领域的十大新兴技术》（96页）<br>《代理型人工智能全面指南》（45页ppt）<br>《麦肯锡2025人类工作中的超级代理。赋能人类解锁AI的全部潜力》（英文版47页）<br>《仲量联行（JLL）：2025美国制造业的复兴全面分析报告：未来制造业增长及工业需求前瞻（26页）》<br>《未来的太空领域：影响美国战略优势的领域》<br>《Luminate：2024年年终美国影视行业报告：数据及趋势洞察（40页）》<br>《Anthropic：2025年AI经济影响报告：AI如何融入现代经济的各类实际任务（38页）》<br>【ICLR2025】《LLMS能否识别您的偏好？评估LLMS中的个性化偏好遵循能力》<br>《改进单智能体和多智能体深度强化学习方法》（219页）<br>《美国安全与新兴技术中心：2025中国学界对大语言模型的批判性思考通用人工智能AGI的多元路径探索研究报告》（英文版29页）<br>《世界经济论坛&amp;麦肯锡：2025以人才为核心：制造业持续变革的当务之急研究报告（40页）》<br>《超越ChatGPT的AI智能体》（82页ppt）<br>《HarrisPoll：2024年汽车技术预测报告：消费者对先进汽车技术与功能的洞察（14页）》<br>【新书】《人工智能智能体的应用》（527页）<br>《哥伦比亚大学：超越Chatgpt的AIagent综述》<br>《欧盟标准组织-体验式网络智能（ENI）-基于人工智能代理的下一代网络切片研究》<br>《中国科学院：2024开放地球引擎（OGE）研究进展与应用报告（55页）》<br>《中国工程院：2024农业机器人现状与展望报告（70页）》<br>《美国安全与新兴技术中心：2025中国学界对大语言模型的批判性思考：通用人工智能(AGI)的多元路径探索研究报告（29页）》<br>《罗兰贝格：2050年全球趋势纲要报告之趋势五：技术与创新（2025年版）（72页）》<br>《理特咨询（ADL）：2025解锁聚变能源：驾驭聚变能商业化的机遇与挑战研究报告（20页）》<br>《埃森哲：技术展望2025—AI自主宣言：可能无限信任惟先-摘要（12页）》<br>《怡安（AON）：2025年气候和自然灾难洞察报告（109页）》<br>《美国安全与新兴技术中心：2025AI翻车事故（AIincident）：强制性报告制度的关键要素研究报告（32页）》<br>《牛津经济研究院2025确保英国充分释放量子计算的经济潜力研究报告》（英文版64页）<br>《欧洲创新委员会（EIC）：2024年科技报告（65页）》<br>《大模型基础完整版》<br>《国际人工智能安全报告》（300页）<br>《怡安（AON）：2025年全球医疗趋势报告（19页）》<br>《前瞻：2025年脑机接口产业蓝皮书——未来将至打造人机交互新范式（57页）》<br>《联合国（UnitedNations）：2024技术与统计报告：从业者投资法指南（67页）》<br>《经济学人智库（EIU）：2025全球展望报告：特朗普再次当选美国总统的全球影响（16页）》<br>《大规模视觉-语言模型的基准、评估、应用与挑战》<br>《大规模安全：大模型安全的全面综述》<br>《Emplifi：2024年Q4全球电商行业基准报告-社交媒体趋势洞察（37页）》<br>《DeepMind：2025生成式魂灵：预测人工智能来世的益处和风险研究报告（23页）》<br>【AI4Science】《利用大型语言模型变革科学：关于人工智能辅助科学发现、实验、内容生成与评估的调研》<br>《世界银行：2025极端天气高昂代价：气候变化背景下的马拉维金融韧性构建研究报告（76页）》<br>《北京理工大学：2025年中国能源经济指数研究及展望报告》<br>《SpaceCapital：2024年第四季度太空投资报告（22页）》<br>《NetDocuments：2025年法律科技趋势报告（32页）》<br>《CBInsights：2024年度全球企业风险投资（CVC）状况报告：私募市场交易、投融资数据及分析（130页）》<br>《Artlist：2025年全球内容与创意趋势报告（59页）》<br>《IBM商业价值研究院：2024投资人工智能伦理和治理必要性研究报告：AI伦理前线五位高管的真实故事（24页）》<br>《世界基准联盟（WBA）：2025塑造未来：对可持续发展目标（SDGs）影响最大的2000家公司研究报告（46页）》<br>《清华大学：2025年DeepSeek从入门到精通（104页）》<br>《麦肯锡：2025工作场所中的超级代理(Superagency)：赋能人类解锁人工智能的全部潜力（47页）》<br>《凯捷（Capgemini）：科技愿景2025：关键新兴科技趋势探索（54页）》<br>《硅谷银行（SVB）：2025年上半年全球创新经济展望报告（39页）》<br>《BCG：2025工业运营前沿技术：AI智能体(AIAgents)的崛起白皮书（26页）》<br>《DrakeStar：2024年全球游戏与电竞行业报告（26页）》<br>《理特咨询（ADL）：2025人工智能驱动的研究、开发与创新突破的新时代研究报告（80页）》<br>《互联网安全中心（CIS）：2024年网络安全冬季报告：回顾与展望（30页）》<br>《方舟投资（ARKInvest）：BigIdeas2025-年度投研报告（148页）》<br>《DeepSeek：2024年DeepSeek-V2模型技术报告：经济、高效的混合专家语言模型（52页）》<br>《CBInsights：2024年度全球风险投资状况回顾报告：私募市场交易、投融资和退出数据及分析（273页）》<br>《全国智标委：2025城市生命线数字化标准体系研究报告（105页）》<br>《经合组织（OECD）：2024年全球政府创新趋势报告：促进以人为本的公共服务（46页）》<br>《DeepSeek_R1技术报告》<br>《摩根斯坦利报告—DeepSeek对于科技和更广义经济的含义是什么？》<br>《李飞飞最新S1模型的论文：s1Simpletest-timescaling》<br>《世界经济论坛-《全球经济未来：2030年的生产力》报告》<br>《2035年技术融合估计：量子互联网、人机接口、机器学习系统、隐形机器人、增材制造》<br>《百页大语言模型新书》（209页pdf）<br>《量子技术和网络安全：技术、治理和政策挑战》（107页）<br>《大语言模型中的对齐伪造》（137页）<br>《2035年技术融合估计：量子互联网、人机接口、机器学习系统、隐形机器人、增材制造》（美陆军232页）<br>《美国防部CDAO：人工智能模型的测试与评估》（66页slides）<br>《自动驾驶的世界模型综述》<br>《Questel2024深度学习领域专利全景报告》（英文版34页）<br>《深度解析Palantir》（20250122_204934.pdf）<br>上下滑动查看更多</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/03/25/1000003051-2650031860-2/">https://zejuncao.github.io/2025/03/25/1000003051-2650031860-2/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                                    <span class="chip bg-color">人工智能学家</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/03/25/1000003051-2650031860-4/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000003051_2650031860_4.jpg" class="responsive-img" alt="人工智能竞争力报告：中国论文数全球第二，北大蝉联高校第一">
                        
                        <span class="card-title">人工智能竞争力报告：中国论文数全球第二，北大蝉联高校第一</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                        <span class="chip bg-color">人工智能学家</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/03/25/1000001752-2247533730-1/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000001752_2247533730_1.jpg" class="responsive-img" alt="“TRIPLE BAM”!!! 哪些统计学的书让你相见恨晚？">
                        
                        <span class="card-title">“TRIPLE BAM”!!! 哪些统计学的书让你相见恨晚？</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/pythonic%E7%94%9F%E7%89%A9%E4%BA%BA/">
                        <span class="chip bg-color">pythonic生物人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/Garfusion/posts" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/Garfusion/posts" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
